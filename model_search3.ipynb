{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import * #probably do not need to import everything\n",
    "# import findspark\n",
    "# findspark.init()\n",
    "# import pyspark [TODO]\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import statistics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "utteranceID                              object\n",
       "Group                                    object\n",
       "CPS_CONST_SharesU_Situation             float64\n",
       "CPS_CONST_SharesU_CorrectSolutions      float64\n",
       "CPS_CONST_SharesU_IncorrectSolutions    float64\n",
       "                                         ...   \n",
       "bert_507                                float64\n",
       "bert_508                                float64\n",
       "bert_509                                float64\n",
       "bert_510                                float64\n",
       "bert_511                                float64\n",
       "Length: 533, dtype: object"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "def read_ini(file_path):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(file_path)\n",
    "    dataset_csv = config[\"hyperopt\"][\"dataset_csv\"]\n",
    "    X_column_range = config[\"hyperopt\"][\"X_column_range\"]\n",
    "    Y_column_names = config[\"hyperopt\"][\"Y_column_names\"].split(\" \")\n",
    "    utteranceID = config[\"hyperopt\"][\"utteranceID\"]\n",
    "    Group = config[\"hyperopt\"][\"Group_column\"]\n",
    "    output_name = config[\"hyperopt\"][\"output_name\"]\n",
    "    resultsDir = config[\"hyperopt\"][\"resultsDir\"]\n",
    "    guide_metric_name = config[\"hyperopt\"][\"guide_metric\"]\n",
    "    return dataset_csv, X_column_range, Y_column_names,\\\n",
    "        utteranceID, Group, output_name, resultsDir, guide_metric_name\n",
    " \n",
    "dataset_csv, X_column_range, Y_column_names, \\\n",
    "utteranceID, Group, output_name, resultsDir, guide_metric_name  = read_ini(\"config_3.ini\")\n",
    "df_dataset = pd.read_csv(dataset_csv)\n",
    "df_dataset.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utteranceID</th>\n",
       "      <th>Group</th>\n",
       "      <th>CPS_CONST_SharesU_Situation</th>\n",
       "      <th>CPS_CONST_SharesU_CorrectSolutions</th>\n",
       "      <th>CPS_CONST_SharesU_IncorrectSolutions</th>\n",
       "      <th>CPS_CONST_EstablishesCG_Confirms</th>\n",
       "      <th>CPS_CONST_EstablishesCG_Interrupts</th>\n",
       "      <th>CPS_NEG_Responds_Reasons</th>\n",
       "      <th>CPS_NEG_Responds_QuestionsOthers</th>\n",
       "      <th>CPS_NEG_Responds_Responds</th>\n",
       "      <th>CPS_NEG_MonitorsE_Results</th>\n",
       "      <th>CPS_NEG_MonitorsE_Strategizes</th>\n",
       "      <th>CPS_NEG_MonitorsE_Save</th>\n",
       "      <th>CPS_NEG_MonitorsE_GivingUp</th>\n",
       "      <th>CPS_MAINTAIN_Initiative_Suggestions</th>\n",
       "      <th>CPS_MAINTAIN_Initiative_Compliments</th>\n",
       "      <th>CPS_MAINTAIN_Initiative_Criticizes</th>\n",
       "      <th>CPS_MAINTAIN_FulfillsR_Support</th>\n",
       "      <th>CPS_MAINTAIN_FulfillsR_Apologizes</th>\n",
       "      <th>CPS_MAINTAIN_FulfillsR_InitiatesOffTopic</th>\n",
       "      <th>CPS_MAINTAIN_FulfillsR_JoinsOffTopic</th>\n",
       "      <th>bert_0</th>\n",
       "      <th>bert_1</th>\n",
       "      <th>bert_2</th>\n",
       "      <th>bert_3</th>\n",
       "      <th>bert_4</th>\n",
       "      <th>bert_5</th>\n",
       "      <th>bert_6</th>\n",
       "      <th>bert_7</th>\n",
       "      <th>bert_8</th>\n",
       "      <th>bert_9</th>\n",
       "      <th>bert_10</th>\n",
       "      <th>bert_11</th>\n",
       "      <th>bert_12</th>\n",
       "      <th>bert_13</th>\n",
       "      <th>bert_14</th>\n",
       "      <th>bert_15</th>\n",
       "      <th>bert_16</th>\n",
       "      <th>bert_17</th>\n",
       "      <th>bert_18</th>\n",
       "      <th>bert_19</th>\n",
       "      <th>bert_20</th>\n",
       "      <th>bert_21</th>\n",
       "      <th>bert_22</th>\n",
       "      <th>bert_23</th>\n",
       "      <th>bert_24</th>\n",
       "      <th>bert_25</th>\n",
       "      <th>bert_26</th>\n",
       "      <th>bert_27</th>\n",
       "      <th>bert_28</th>\n",
       "      <th>bert_29</th>\n",
       "      <th>bert_30</th>\n",
       "      <th>bert_31</th>\n",
       "      <th>bert_32</th>\n",
       "      <th>bert_33</th>\n",
       "      <th>bert_34</th>\n",
       "      <th>bert_35</th>\n",
       "      <th>bert_36</th>\n",
       "      <th>bert_37</th>\n",
       "      <th>bert_38</th>\n",
       "      <th>bert_39</th>\n",
       "      <th>bert_40</th>\n",
       "      <th>bert_41</th>\n",
       "      <th>bert_42</th>\n",
       "      <th>bert_43</th>\n",
       "      <th>bert_44</th>\n",
       "      <th>bert_45</th>\n",
       "      <th>bert_46</th>\n",
       "      <th>bert_47</th>\n",
       "      <th>bert_48</th>\n",
       "      <th>bert_49</th>\n",
       "      <th>bert_50</th>\n",
       "      <th>bert_51</th>\n",
       "      <th>bert_52</th>\n",
       "      <th>bert_53</th>\n",
       "      <th>bert_54</th>\n",
       "      <th>bert_55</th>\n",
       "      <th>bert_56</th>\n",
       "      <th>bert_57</th>\n",
       "      <th>bert_58</th>\n",
       "      <th>bert_59</th>\n",
       "      <th>bert_60</th>\n",
       "      <th>bert_61</th>\n",
       "      <th>bert_62</th>\n",
       "      <th>bert_63</th>\n",
       "      <th>bert_64</th>\n",
       "      <th>bert_65</th>\n",
       "      <th>bert_66</th>\n",
       "      <th>bert_67</th>\n",
       "      <th>bert_68</th>\n",
       "      <th>bert_69</th>\n",
       "      <th>bert_70</th>\n",
       "      <th>bert_71</th>\n",
       "      <th>bert_72</th>\n",
       "      <th>bert_73</th>\n",
       "      <th>bert_74</th>\n",
       "      <th>bert_75</th>\n",
       "      <th>bert_76</th>\n",
       "      <th>bert_77</th>\n",
       "      <th>bert_78</th>\n",
       "      <th>bert_79</th>\n",
       "      <th>bert_80</th>\n",
       "      <th>bert_81</th>\n",
       "      <th>bert_82</th>\n",
       "      <th>bert_83</th>\n",
       "      <th>bert_84</th>\n",
       "      <th>bert_85</th>\n",
       "      <th>bert_86</th>\n",
       "      <th>bert_87</th>\n",
       "      <th>bert_88</th>\n",
       "      <th>bert_89</th>\n",
       "      <th>bert_90</th>\n",
       "      <th>bert_91</th>\n",
       "      <th>bert_92</th>\n",
       "      <th>bert_93</th>\n",
       "      <th>bert_94</th>\n",
       "      <th>bert_95</th>\n",
       "      <th>bert_96</th>\n",
       "      <th>bert_97</th>\n",
       "      <th>bert_98</th>\n",
       "      <th>bert_99</th>\n",
       "      <th>bert_100</th>\n",
       "      <th>bert_101</th>\n",
       "      <th>bert_102</th>\n",
       "      <th>bert_103</th>\n",
       "      <th>bert_104</th>\n",
       "      <th>bert_105</th>\n",
       "      <th>bert_106</th>\n",
       "      <th>bert_107</th>\n",
       "      <th>bert_108</th>\n",
       "      <th>bert_109</th>\n",
       "      <th>bert_110</th>\n",
       "      <th>bert_111</th>\n",
       "      <th>bert_112</th>\n",
       "      <th>bert_113</th>\n",
       "      <th>bert_114</th>\n",
       "      <th>bert_115</th>\n",
       "      <th>bert_116</th>\n",
       "      <th>bert_117</th>\n",
       "      <th>bert_118</th>\n",
       "      <th>bert_119</th>\n",
       "      <th>bert_120</th>\n",
       "      <th>bert_121</th>\n",
       "      <th>bert_122</th>\n",
       "      <th>bert_123</th>\n",
       "      <th>bert_124</th>\n",
       "      <th>bert_125</th>\n",
       "      <th>bert_126</th>\n",
       "      <th>bert_127</th>\n",
       "      <th>bert_128</th>\n",
       "      <th>bert_129</th>\n",
       "      <th>bert_130</th>\n",
       "      <th>bert_131</th>\n",
       "      <th>bert_132</th>\n",
       "      <th>bert_133</th>\n",
       "      <th>bert_134</th>\n",
       "      <th>bert_135</th>\n",
       "      <th>bert_136</th>\n",
       "      <th>bert_137</th>\n",
       "      <th>bert_138</th>\n",
       "      <th>bert_139</th>\n",
       "      <th>bert_140</th>\n",
       "      <th>bert_141</th>\n",
       "      <th>bert_142</th>\n",
       "      <th>bert_143</th>\n",
       "      <th>bert_144</th>\n",
       "      <th>bert_145</th>\n",
       "      <th>bert_146</th>\n",
       "      <th>bert_147</th>\n",
       "      <th>bert_148</th>\n",
       "      <th>bert_149</th>\n",
       "      <th>bert_150</th>\n",
       "      <th>bert_151</th>\n",
       "      <th>bert_152</th>\n",
       "      <th>bert_153</th>\n",
       "      <th>bert_154</th>\n",
       "      <th>bert_155</th>\n",
       "      <th>bert_156</th>\n",
       "      <th>bert_157</th>\n",
       "      <th>bert_158</th>\n",
       "      <th>bert_159</th>\n",
       "      <th>bert_160</th>\n",
       "      <th>bert_161</th>\n",
       "      <th>bert_162</th>\n",
       "      <th>bert_163</th>\n",
       "      <th>bert_164</th>\n",
       "      <th>bert_165</th>\n",
       "      <th>bert_166</th>\n",
       "      <th>bert_167</th>\n",
       "      <th>bert_168</th>\n",
       "      <th>bert_169</th>\n",
       "      <th>bert_170</th>\n",
       "      <th>bert_171</th>\n",
       "      <th>bert_172</th>\n",
       "      <th>bert_173</th>\n",
       "      <th>bert_174</th>\n",
       "      <th>bert_175</th>\n",
       "      <th>bert_176</th>\n",
       "      <th>bert_177</th>\n",
       "      <th>bert_178</th>\n",
       "      <th>bert_179</th>\n",
       "      <th>bert_180</th>\n",
       "      <th>bert_181</th>\n",
       "      <th>bert_182</th>\n",
       "      <th>bert_183</th>\n",
       "      <th>bert_184</th>\n",
       "      <th>bert_185</th>\n",
       "      <th>bert_186</th>\n",
       "      <th>bert_187</th>\n",
       "      <th>bert_188</th>\n",
       "      <th>bert_189</th>\n",
       "      <th>bert_190</th>\n",
       "      <th>bert_191</th>\n",
       "      <th>bert_192</th>\n",
       "      <th>bert_193</th>\n",
       "      <th>bert_194</th>\n",
       "      <th>bert_195</th>\n",
       "      <th>bert_196</th>\n",
       "      <th>bert_197</th>\n",
       "      <th>bert_198</th>\n",
       "      <th>bert_199</th>\n",
       "      <th>bert_200</th>\n",
       "      <th>bert_201</th>\n",
       "      <th>bert_202</th>\n",
       "      <th>bert_203</th>\n",
       "      <th>bert_204</th>\n",
       "      <th>bert_205</th>\n",
       "      <th>bert_206</th>\n",
       "      <th>bert_207</th>\n",
       "      <th>bert_208</th>\n",
       "      <th>bert_209</th>\n",
       "      <th>bert_210</th>\n",
       "      <th>bert_211</th>\n",
       "      <th>bert_212</th>\n",
       "      <th>bert_213</th>\n",
       "      <th>bert_214</th>\n",
       "      <th>bert_215</th>\n",
       "      <th>bert_216</th>\n",
       "      <th>bert_217</th>\n",
       "      <th>bert_218</th>\n",
       "      <th>bert_219</th>\n",
       "      <th>bert_220</th>\n",
       "      <th>bert_221</th>\n",
       "      <th>bert_222</th>\n",
       "      <th>bert_223</th>\n",
       "      <th>bert_224</th>\n",
       "      <th>bert_225</th>\n",
       "      <th>bert_226</th>\n",
       "      <th>bert_227</th>\n",
       "      <th>bert_228</th>\n",
       "      <th>bert_229</th>\n",
       "      <th>bert_230</th>\n",
       "      <th>bert_231</th>\n",
       "      <th>bert_232</th>\n",
       "      <th>bert_233</th>\n",
       "      <th>bert_234</th>\n",
       "      <th>bert_235</th>\n",
       "      <th>bert_236</th>\n",
       "      <th>bert_237</th>\n",
       "      <th>bert_238</th>\n",
       "      <th>bert_239</th>\n",
       "      <th>bert_240</th>\n",
       "      <th>bert_241</th>\n",
       "      <th>bert_242</th>\n",
       "      <th>bert_243</th>\n",
       "      <th>bert_244</th>\n",
       "      <th>bert_245</th>\n",
       "      <th>bert_246</th>\n",
       "      <th>bert_247</th>\n",
       "      <th>bert_248</th>\n",
       "      <th>bert_249</th>\n",
       "      <th>bert_250</th>\n",
       "      <th>bert_251</th>\n",
       "      <th>bert_252</th>\n",
       "      <th>bert_253</th>\n",
       "      <th>bert_254</th>\n",
       "      <th>bert_255</th>\n",
       "      <th>bert_256</th>\n",
       "      <th>bert_257</th>\n",
       "      <th>bert_258</th>\n",
       "      <th>bert_259</th>\n",
       "      <th>bert_260</th>\n",
       "      <th>bert_261</th>\n",
       "      <th>bert_262</th>\n",
       "      <th>bert_263</th>\n",
       "      <th>bert_264</th>\n",
       "      <th>bert_265</th>\n",
       "      <th>bert_266</th>\n",
       "      <th>bert_267</th>\n",
       "      <th>bert_268</th>\n",
       "      <th>bert_269</th>\n",
       "      <th>bert_270</th>\n",
       "      <th>bert_271</th>\n",
       "      <th>bert_272</th>\n",
       "      <th>bert_273</th>\n",
       "      <th>bert_274</th>\n",
       "      <th>bert_275</th>\n",
       "      <th>bert_276</th>\n",
       "      <th>bert_277</th>\n",
       "      <th>bert_278</th>\n",
       "      <th>bert_279</th>\n",
       "      <th>bert_280</th>\n",
       "      <th>bert_281</th>\n",
       "      <th>bert_282</th>\n",
       "      <th>bert_283</th>\n",
       "      <th>bert_284</th>\n",
       "      <th>bert_285</th>\n",
       "      <th>bert_286</th>\n",
       "      <th>bert_287</th>\n",
       "      <th>bert_288</th>\n",
       "      <th>bert_289</th>\n",
       "      <th>bert_290</th>\n",
       "      <th>bert_291</th>\n",
       "      <th>bert_292</th>\n",
       "      <th>bert_293</th>\n",
       "      <th>bert_294</th>\n",
       "      <th>bert_295</th>\n",
       "      <th>bert_296</th>\n",
       "      <th>bert_297</th>\n",
       "      <th>bert_298</th>\n",
       "      <th>bert_299</th>\n",
       "      <th>bert_300</th>\n",
       "      <th>bert_301</th>\n",
       "      <th>bert_302</th>\n",
       "      <th>bert_303</th>\n",
       "      <th>bert_304</th>\n",
       "      <th>bert_305</th>\n",
       "      <th>bert_306</th>\n",
       "      <th>bert_307</th>\n",
       "      <th>bert_308</th>\n",
       "      <th>bert_309</th>\n",
       "      <th>bert_310</th>\n",
       "      <th>bert_311</th>\n",
       "      <th>bert_312</th>\n",
       "      <th>bert_313</th>\n",
       "      <th>bert_314</th>\n",
       "      <th>bert_315</th>\n",
       "      <th>bert_316</th>\n",
       "      <th>bert_317</th>\n",
       "      <th>bert_318</th>\n",
       "      <th>bert_319</th>\n",
       "      <th>bert_320</th>\n",
       "      <th>bert_321</th>\n",
       "      <th>bert_322</th>\n",
       "      <th>bert_323</th>\n",
       "      <th>bert_324</th>\n",
       "      <th>bert_325</th>\n",
       "      <th>bert_326</th>\n",
       "      <th>bert_327</th>\n",
       "      <th>bert_328</th>\n",
       "      <th>bert_329</th>\n",
       "      <th>bert_330</th>\n",
       "      <th>bert_331</th>\n",
       "      <th>bert_332</th>\n",
       "      <th>bert_333</th>\n",
       "      <th>bert_334</th>\n",
       "      <th>bert_335</th>\n",
       "      <th>bert_336</th>\n",
       "      <th>bert_337</th>\n",
       "      <th>bert_338</th>\n",
       "      <th>bert_339</th>\n",
       "      <th>bert_340</th>\n",
       "      <th>bert_341</th>\n",
       "      <th>bert_342</th>\n",
       "      <th>bert_343</th>\n",
       "      <th>bert_344</th>\n",
       "      <th>bert_345</th>\n",
       "      <th>bert_346</th>\n",
       "      <th>bert_347</th>\n",
       "      <th>bert_348</th>\n",
       "      <th>bert_349</th>\n",
       "      <th>bert_350</th>\n",
       "      <th>bert_351</th>\n",
       "      <th>bert_352</th>\n",
       "      <th>bert_353</th>\n",
       "      <th>bert_354</th>\n",
       "      <th>bert_355</th>\n",
       "      <th>bert_356</th>\n",
       "      <th>bert_357</th>\n",
       "      <th>bert_358</th>\n",
       "      <th>bert_359</th>\n",
       "      <th>bert_360</th>\n",
       "      <th>bert_361</th>\n",
       "      <th>bert_362</th>\n",
       "      <th>bert_363</th>\n",
       "      <th>bert_364</th>\n",
       "      <th>bert_365</th>\n",
       "      <th>bert_366</th>\n",
       "      <th>bert_367</th>\n",
       "      <th>bert_368</th>\n",
       "      <th>bert_369</th>\n",
       "      <th>bert_370</th>\n",
       "      <th>bert_371</th>\n",
       "      <th>bert_372</th>\n",
       "      <th>bert_373</th>\n",
       "      <th>bert_374</th>\n",
       "      <th>bert_375</th>\n",
       "      <th>bert_376</th>\n",
       "      <th>bert_377</th>\n",
       "      <th>bert_378</th>\n",
       "      <th>bert_379</th>\n",
       "      <th>bert_380</th>\n",
       "      <th>bert_381</th>\n",
       "      <th>bert_382</th>\n",
       "      <th>bert_383</th>\n",
       "      <th>bert_384</th>\n",
       "      <th>bert_385</th>\n",
       "      <th>bert_386</th>\n",
       "      <th>bert_387</th>\n",
       "      <th>bert_388</th>\n",
       "      <th>bert_389</th>\n",
       "      <th>bert_390</th>\n",
       "      <th>bert_391</th>\n",
       "      <th>bert_392</th>\n",
       "      <th>bert_393</th>\n",
       "      <th>bert_394</th>\n",
       "      <th>bert_395</th>\n",
       "      <th>bert_396</th>\n",
       "      <th>bert_397</th>\n",
       "      <th>bert_398</th>\n",
       "      <th>bert_399</th>\n",
       "      <th>bert_400</th>\n",
       "      <th>bert_401</th>\n",
       "      <th>bert_402</th>\n",
       "      <th>bert_403</th>\n",
       "      <th>bert_404</th>\n",
       "      <th>bert_405</th>\n",
       "      <th>bert_406</th>\n",
       "      <th>bert_407</th>\n",
       "      <th>bert_408</th>\n",
       "      <th>bert_409</th>\n",
       "      <th>bert_410</th>\n",
       "      <th>bert_411</th>\n",
       "      <th>bert_412</th>\n",
       "      <th>bert_413</th>\n",
       "      <th>bert_414</th>\n",
       "      <th>bert_415</th>\n",
       "      <th>bert_416</th>\n",
       "      <th>bert_417</th>\n",
       "      <th>bert_418</th>\n",
       "      <th>bert_419</th>\n",
       "      <th>bert_420</th>\n",
       "      <th>bert_421</th>\n",
       "      <th>bert_422</th>\n",
       "      <th>bert_423</th>\n",
       "      <th>bert_424</th>\n",
       "      <th>bert_425</th>\n",
       "      <th>bert_426</th>\n",
       "      <th>bert_427</th>\n",
       "      <th>bert_428</th>\n",
       "      <th>bert_429</th>\n",
       "      <th>bert_430</th>\n",
       "      <th>bert_431</th>\n",
       "      <th>bert_432</th>\n",
       "      <th>bert_433</th>\n",
       "      <th>bert_434</th>\n",
       "      <th>bert_435</th>\n",
       "      <th>bert_436</th>\n",
       "      <th>bert_437</th>\n",
       "      <th>bert_438</th>\n",
       "      <th>bert_439</th>\n",
       "      <th>bert_440</th>\n",
       "      <th>bert_441</th>\n",
       "      <th>bert_442</th>\n",
       "      <th>bert_443</th>\n",
       "      <th>bert_444</th>\n",
       "      <th>bert_445</th>\n",
       "      <th>bert_446</th>\n",
       "      <th>bert_447</th>\n",
       "      <th>bert_448</th>\n",
       "      <th>bert_449</th>\n",
       "      <th>bert_450</th>\n",
       "      <th>bert_451</th>\n",
       "      <th>bert_452</th>\n",
       "      <th>bert_453</th>\n",
       "      <th>bert_454</th>\n",
       "      <th>bert_455</th>\n",
       "      <th>bert_456</th>\n",
       "      <th>bert_457</th>\n",
       "      <th>bert_458</th>\n",
       "      <th>bert_459</th>\n",
       "      <th>bert_460</th>\n",
       "      <th>bert_461</th>\n",
       "      <th>bert_462</th>\n",
       "      <th>bert_463</th>\n",
       "      <th>bert_464</th>\n",
       "      <th>bert_465</th>\n",
       "      <th>bert_466</th>\n",
       "      <th>bert_467</th>\n",
       "      <th>bert_468</th>\n",
       "      <th>bert_469</th>\n",
       "      <th>bert_470</th>\n",
       "      <th>bert_471</th>\n",
       "      <th>bert_472</th>\n",
       "      <th>bert_473</th>\n",
       "      <th>bert_474</th>\n",
       "      <th>bert_475</th>\n",
       "      <th>bert_476</th>\n",
       "      <th>bert_477</th>\n",
       "      <th>bert_478</th>\n",
       "      <th>bert_479</th>\n",
       "      <th>bert_480</th>\n",
       "      <th>bert_481</th>\n",
       "      <th>bert_482</th>\n",
       "      <th>bert_483</th>\n",
       "      <th>bert_484</th>\n",
       "      <th>bert_485</th>\n",
       "      <th>bert_486</th>\n",
       "      <th>bert_487</th>\n",
       "      <th>bert_488</th>\n",
       "      <th>bert_489</th>\n",
       "      <th>bert_490</th>\n",
       "      <th>bert_491</th>\n",
       "      <th>bert_492</th>\n",
       "      <th>bert_493</th>\n",
       "      <th>bert_494</th>\n",
       "      <th>bert_495</th>\n",
       "      <th>bert_496</th>\n",
       "      <th>bert_497</th>\n",
       "      <th>bert_498</th>\n",
       "      <th>bert_499</th>\n",
       "      <th>bert_500</th>\n",
       "      <th>bert_501</th>\n",
       "      <th>bert_502</th>\n",
       "      <th>bert_503</th>\n",
       "      <th>bert_504</th>\n",
       "      <th>bert_505</th>\n",
       "      <th>bert_506</th>\n",
       "      <th>bert_507</th>\n",
       "      <th>bert_508</th>\n",
       "      <th>bert_509</th>\n",
       "      <th>bert_510</th>\n",
       "      <th>bert_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Group_01_0</td>\n",
       "      <td>Group_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993518</td>\n",
       "      <td>0.365759</td>\n",
       "      <td>-0.108810</td>\n",
       "      <td>0.422874</td>\n",
       "      <td>0.451778</td>\n",
       "      <td>0.961461</td>\n",
       "      <td>0.710460</td>\n",
       "      <td>-0.999845</td>\n",
       "      <td>-0.267417</td>\n",
       "      <td>-0.999266</td>\n",
       "      <td>0.270915</td>\n",
       "      <td>-0.997165</td>\n",
       "      <td>-0.973942</td>\n",
       "      <td>-0.998901</td>\n",
       "      <td>0.051721</td>\n",
       "      <td>0.175755</td>\n",
       "      <td>-0.139673</td>\n",
       "      <td>0.104318</td>\n",
       "      <td>-0.272146</td>\n",
       "      <td>0.394232</td>\n",
       "      <td>-0.152230</td>\n",
       "      <td>-0.302303</td>\n",
       "      <td>0.799073</td>\n",
       "      <td>0.944860</td>\n",
       "      <td>0.993572</td>\n",
       "      <td>0.998466</td>\n",
       "      <td>0.061202</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.302294</td>\n",
       "      <td>0.534748</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.147512</td>\n",
       "      <td>0.389890</td>\n",
       "      <td>0.041206</td>\n",
       "      <td>-0.996541</td>\n",
       "      <td>0.532553</td>\n",
       "      <td>0.011078</td>\n",
       "      <td>-0.091283</td>\n",
       "      <td>0.984499</td>\n",
       "      <td>0.367115</td>\n",
       "      <td>0.044604</td>\n",
       "      <td>0.076422</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>-0.999874</td>\n",
       "      <td>0.139501</td>\n",
       "      <td>0.069888</td>\n",
       "      <td>-0.896454</td>\n",
       "      <td>0.300547</td>\n",
       "      <td>0.390984</td>\n",
       "      <td>-0.150038</td>\n",
       "      <td>0.977756</td>\n",
       "      <td>-0.266266</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.006934</td>\n",
       "      <td>0.485656</td>\n",
       "      <td>0.362324</td>\n",
       "      <td>0.187488</td>\n",
       "      <td>0.141071</td>\n",
       "      <td>-0.999607</td>\n",
       "      <td>-0.987854</td>\n",
       "      <td>0.112721</td>\n",
       "      <td>-0.516108</td>\n",
       "      <td>0.996057</td>\n",
       "      <td>-0.025922</td>\n",
       "      <td>0.009192</td>\n",
       "      <td>-0.973916</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.910910</td>\n",
       "      <td>-0.237158</td>\n",
       "      <td>-0.162820</td>\n",
       "      <td>0.980844</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>-0.930536</td>\n",
       "      <td>-0.761945</td>\n",
       "      <td>-0.956196</td>\n",
       "      <td>-0.127413</td>\n",
       "      <td>-0.054906</td>\n",
       "      <td>0.988883</td>\n",
       "      <td>0.268531</td>\n",
       "      <td>-0.136805</td>\n",
       "      <td>-0.999541</td>\n",
       "      <td>0.226200</td>\n",
       "      <td>0.996731</td>\n",
       "      <td>-0.699441</td>\n",
       "      <td>0.990424</td>\n",
       "      <td>-0.999233</td>\n",
       "      <td>0.085551</td>\n",
       "      <td>0.185651</td>\n",
       "      <td>-0.295660</td>\n",
       "      <td>-0.306530</td>\n",
       "      <td>-0.989447</td>\n",
       "      <td>-0.117240</td>\n",
       "      <td>-0.025444</td>\n",
       "      <td>-0.998039</td>\n",
       "      <td>-0.448954</td>\n",
       "      <td>0.784459</td>\n",
       "      <td>0.995247</td>\n",
       "      <td>0.338093</td>\n",
       "      <td>-0.999861</td>\n",
       "      <td>-0.182477</td>\n",
       "      <td>-0.961148</td>\n",
       "      <td>-0.894223</td>\n",
       "      <td>-0.994171</td>\n",
       "      <td>0.108406</td>\n",
       "      <td>-0.163455</td>\n",
       "      <td>-0.057791</td>\n",
       "      <td>0.991676</td>\n",
       "      <td>-0.226500</td>\n",
       "      <td>-0.332793</td>\n",
       "      <td>-0.978470</td>\n",
       "      <td>0.323056</td>\n",
       "      <td>-0.688976</td>\n",
       "      <td>0.998172</td>\n",
       "      <td>-0.994303</td>\n",
       "      <td>0.195427</td>\n",
       "      <td>-0.023967</td>\n",
       "      <td>-0.987200</td>\n",
       "      <td>-0.103923</td>\n",
       "      <td>0.103828</td>\n",
       "      <td>0.994514</td>\n",
       "      <td>-0.859864</td>\n",
       "      <td>0.134679</td>\n",
       "      <td>-0.998463</td>\n",
       "      <td>-0.953276</td>\n",
       "      <td>-0.044310</td>\n",
       "      <td>-0.025508</td>\n",
       "      <td>-0.532861</td>\n",
       "      <td>-0.384716</td>\n",
       "      <td>-0.163408</td>\n",
       "      <td>0.240638</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>0.190070</td>\n",
       "      <td>0.998588</td>\n",
       "      <td>-0.126664</td>\n",
       "      <td>0.495204</td>\n",
       "      <td>-0.936047</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>-0.999296</td>\n",
       "      <td>-0.999930</td>\n",
       "      <td>-0.064550</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>0.131687</td>\n",
       "      <td>0.233106</td>\n",
       "      <td>0.995198</td>\n",
       "      <td>0.103147</td>\n",
       "      <td>0.999794</td>\n",
       "      <td>-0.987756</td>\n",
       "      <td>0.999856</td>\n",
       "      <td>-0.982450</td>\n",
       "      <td>-0.153721</td>\n",
       "      <td>0.053282</td>\n",
       "      <td>-0.158230</td>\n",
       "      <td>0.997394</td>\n",
       "      <td>0.110863</td>\n",
       "      <td>-0.015773</td>\n",
       "      <td>0.065952</td>\n",
       "      <td>0.388155</td>\n",
       "      <td>0.063206</td>\n",
       "      <td>0.470285</td>\n",
       "      <td>-0.018017</td>\n",
       "      <td>-0.388176</td>\n",
       "      <td>0.060075</td>\n",
       "      <td>-0.456877</td>\n",
       "      <td>0.141881</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>-0.390667</td>\n",
       "      <td>-0.247091</td>\n",
       "      <td>-0.323712</td>\n",
       "      <td>0.999905</td>\n",
       "      <td>0.991694</td>\n",
       "      <td>-0.096647</td>\n",
       "      <td>-0.937747</td>\n",
       "      <td>-0.994561</td>\n",
       "      <td>-0.240205</td>\n",
       "      <td>0.120738</td>\n",
       "      <td>0.242119</td>\n",
       "      <td>0.546910</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>0.999731</td>\n",
       "      <td>0.830225</td>\n",
       "      <td>0.871223</td>\n",
       "      <td>0.040535</td>\n",
       "      <td>0.992771</td>\n",
       "      <td>-0.169057</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>-0.963128</td>\n",
       "      <td>-0.999420</td>\n",
       "      <td>-0.829070</td>\n",
       "      <td>0.398747</td>\n",
       "      <td>0.999377</td>\n",
       "      <td>0.998754</td>\n",
       "      <td>-0.663970</td>\n",
       "      <td>-0.846856</td>\n",
       "      <td>-0.147407</td>\n",
       "      <td>0.995585</td>\n",
       "      <td>-0.185271</td>\n",
       "      <td>-0.997134</td>\n",
       "      <td>-0.996027</td>\n",
       "      <td>0.422330</td>\n",
       "      <td>-0.190198</td>\n",
       "      <td>-0.347406</td>\n",
       "      <td>-0.495388</td>\n",
       "      <td>-0.971927</td>\n",
       "      <td>-0.280146</td>\n",
       "      <td>-0.063150</td>\n",
       "      <td>0.964428</td>\n",
       "      <td>-0.335161</td>\n",
       "      <td>0.999681</td>\n",
       "      <td>0.998341</td>\n",
       "      <td>0.013911</td>\n",
       "      <td>-0.814345</td>\n",
       "      <td>-0.586523</td>\n",
       "      <td>-0.208074</td>\n",
       "      <td>-0.223687</td>\n",
       "      <td>0.986227</td>\n",
       "      <td>-0.874348</td>\n",
       "      <td>-0.688999</td>\n",
       "      <td>0.983429</td>\n",
       "      <td>0.888864</td>\n",
       "      <td>0.258210</td>\n",
       "      <td>-0.999492</td>\n",
       "      <td>0.299267</td>\n",
       "      <td>0.149031</td>\n",
       "      <td>0.268726</td>\n",
       "      <td>-0.930555</td>\n",
       "      <td>-0.989398</td>\n",
       "      <td>-0.998085</td>\n",
       "      <td>-0.454995</td>\n",
       "      <td>-0.913763</td>\n",
       "      <td>0.444294</td>\n",
       "      <td>-0.143297</td>\n",
       "      <td>0.095703</td>\n",
       "      <td>-0.193915</td>\n",
       "      <td>0.167189</td>\n",
       "      <td>0.998244</td>\n",
       "      <td>0.112099</td>\n",
       "      <td>-0.816726</td>\n",
       "      <td>0.272809</td>\n",
       "      <td>0.060892</td>\n",
       "      <td>-0.063746</td>\n",
       "      <td>-0.686249</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>-0.814935</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>0.083189</td>\n",
       "      <td>0.349218</td>\n",
       "      <td>0.999678</td>\n",
       "      <td>-0.305613</td>\n",
       "      <td>0.988084</td>\n",
       "      <td>-0.129852</td>\n",
       "      <td>0.058127</td>\n",
       "      <td>0.379818</td>\n",
       "      <td>-0.319978</td>\n",
       "      <td>-0.072744</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.315953</td>\n",
       "      <td>-0.139727</td>\n",
       "      <td>-0.483264</td>\n",
       "      <td>-0.631395</td>\n",
       "      <td>0.902325</td>\n",
       "      <td>-0.246594</td>\n",
       "      <td>-0.999511</td>\n",
       "      <td>0.086733</td>\n",
       "      <td>-0.777795</td>\n",
       "      <td>-0.067256</td>\n",
       "      <td>0.997084</td>\n",
       "      <td>0.998849</td>\n",
       "      <td>-0.757679</td>\n",
       "      <td>0.379327</td>\n",
       "      <td>0.047055</td>\n",
       "      <td>0.997867</td>\n",
       "      <td>-0.017929</td>\n",
       "      <td>-0.992369</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>-0.382769</td>\n",
       "      <td>-0.803451</td>\n",
       "      <td>0.991455</td>\n",
       "      <td>0.132520</td>\n",
       "      <td>0.608287</td>\n",
       "      <td>0.247420</td>\n",
       "      <td>0.156043</td>\n",
       "      <td>-0.998999</td>\n",
       "      <td>0.851507</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>-0.678790</td>\n",
       "      <td>0.068183</td>\n",
       "      <td>-0.107639</td>\n",
       "      <td>0.026917</td>\n",
       "      <td>-0.999776</td>\n",
       "      <td>-0.998124</td>\n",
       "      <td>-0.880143</td>\n",
       "      <td>0.383719</td>\n",
       "      <td>-0.107090</td>\n",
       "      <td>0.994365</td>\n",
       "      <td>0.999410</td>\n",
       "      <td>-0.989632</td>\n",
       "      <td>0.152308</td>\n",
       "      <td>0.958914</td>\n",
       "      <td>0.154982</td>\n",
       "      <td>0.997206</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>-0.997493</td>\n",
       "      <td>-0.573020</td>\n",
       "      <td>0.999320</td>\n",
       "      <td>-0.374868</td>\n",
       "      <td>-0.204477</td>\n",
       "      <td>0.099023</td>\n",
       "      <td>0.996594</td>\n",
       "      <td>0.948357</td>\n",
       "      <td>-0.112678</td>\n",
       "      <td>0.241461</td>\n",
       "      <td>-0.997445</td>\n",
       "      <td>-0.397005</td>\n",
       "      <td>0.998168</td>\n",
       "      <td>0.995064</td>\n",
       "      <td>-0.221232</td>\n",
       "      <td>0.035435</td>\n",
       "      <td>-0.092964</td>\n",
       "      <td>0.151324</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.852312</td>\n",
       "      <td>-0.177322</td>\n",
       "      <td>-0.839064</td>\n",
       "      <td>-0.211912</td>\n",
       "      <td>0.086590</td>\n",
       "      <td>-0.810184</td>\n",
       "      <td>-0.293656</td>\n",
       "      <td>-0.988491</td>\n",
       "      <td>0.591749</td>\n",
       "      <td>0.997119</td>\n",
       "      <td>-0.115562</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>-0.125006</td>\n",
       "      <td>-0.016574</td>\n",
       "      <td>-0.230939</td>\n",
       "      <td>0.234504</td>\n",
       "      <td>-0.870815</td>\n",
       "      <td>-0.430600</td>\n",
       "      <td>0.154531</td>\n",
       "      <td>0.998935</td>\n",
       "      <td>0.189843</td>\n",
       "      <td>-0.150902</td>\n",
       "      <td>0.938789</td>\n",
       "      <td>-0.971393</td>\n",
       "      <td>0.890742</td>\n",
       "      <td>0.797298</td>\n",
       "      <td>0.998961</td>\n",
       "      <td>0.149505</td>\n",
       "      <td>0.513899</td>\n",
       "      <td>-0.065345</td>\n",
       "      <td>0.300547</td>\n",
       "      <td>0.540359</td>\n",
       "      <td>0.040423</td>\n",
       "      <td>0.842397</td>\n",
       "      <td>0.124134</td>\n",
       "      <td>-0.540130</td>\n",
       "      <td>-0.312522</td>\n",
       "      <td>-0.192270</td>\n",
       "      <td>-0.018904</td>\n",
       "      <td>-0.998515</td>\n",
       "      <td>-0.553115</td>\n",
       "      <td>-0.449038</td>\n",
       "      <td>0.101221</td>\n",
       "      <td>0.410227</td>\n",
       "      <td>-0.944593</td>\n",
       "      <td>-0.707188</td>\n",
       "      <td>0.450232</td>\n",
       "      <td>-0.161911</td>\n",
       "      <td>0.400318</td>\n",
       "      <td>0.132915</td>\n",
       "      <td>0.985735</td>\n",
       "      <td>-0.344011</td>\n",
       "      <td>-0.124004</td>\n",
       "      <td>0.876522</td>\n",
       "      <td>-0.995762</td>\n",
       "      <td>-0.098554</td>\n",
       "      <td>-0.417082</td>\n",
       "      <td>-0.104742</td>\n",
       "      <td>0.070615</td>\n",
       "      <td>0.987843</td>\n",
       "      <td>0.170681</td>\n",
       "      <td>-0.608041</td>\n",
       "      <td>0.512824</td>\n",
       "      <td>0.999660</td>\n",
       "      <td>-0.896135</td>\n",
       "      <td>0.472787</td>\n",
       "      <td>-0.269124</td>\n",
       "      <td>-0.035230</td>\n",
       "      <td>-0.266306</td>\n",
       "      <td>-0.172978</td>\n",
       "      <td>0.991066</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.186850</td>\n",
       "      <td>-0.060723</td>\n",
       "      <td>0.217371</td>\n",
       "      <td>0.241739</td>\n",
       "      <td>-0.195661</td>\n",
       "      <td>0.996623</td>\n",
       "      <td>0.010318</td>\n",
       "      <td>-0.064743</td>\n",
       "      <td>-0.907280</td>\n",
       "      <td>-0.835072</td>\n",
       "      <td>-0.026326</td>\n",
       "      <td>0.999393</td>\n",
       "      <td>-0.591054</td>\n",
       "      <td>0.124279</td>\n",
       "      <td>0.157127</td>\n",
       "      <td>0.341234</td>\n",
       "      <td>-0.996674</td>\n",
       "      <td>0.778285</td>\n",
       "      <td>-0.033876</td>\n",
       "      <td>-0.998908</td>\n",
       "      <td>0.016428</td>\n",
       "      <td>-0.992073</td>\n",
       "      <td>-0.218593</td>\n",
       "      <td>0.247950</td>\n",
       "      <td>-0.812904</td>\n",
       "      <td>-0.308834</td>\n",
       "      <td>-0.999918</td>\n",
       "      <td>-0.174223</td>\n",
       "      <td>0.961026</td>\n",
       "      <td>0.048123</td>\n",
       "      <td>0.987628</td>\n",
       "      <td>-0.192336</td>\n",
       "      <td>-0.005580</td>\n",
       "      <td>-0.283624</td>\n",
       "      <td>-0.056144</td>\n",
       "      <td>-0.078043</td>\n",
       "      <td>-0.279447</td>\n",
       "      <td>0.137867</td>\n",
       "      <td>-0.889680</td>\n",
       "      <td>0.999811</td>\n",
       "      <td>-0.999953</td>\n",
       "      <td>-0.753577</td>\n",
       "      <td>0.223173</td>\n",
       "      <td>-0.971910</td>\n",
       "      <td>-0.841393</td>\n",
       "      <td>-0.004325</td>\n",
       "      <td>0.384237</td>\n",
       "      <td>-0.036246</td>\n",
       "      <td>-0.998808</td>\n",
       "      <td>-0.907765</td>\n",
       "      <td>-0.213256</td>\n",
       "      <td>-0.998089</td>\n",
       "      <td>-0.997144</td>\n",
       "      <td>-0.421826</td>\n",
       "      <td>-0.040656</td>\n",
       "      <td>-0.370235</td>\n",
       "      <td>-0.155066</td>\n",
       "      <td>-0.061990</td>\n",
       "      <td>0.400699</td>\n",
       "      <td>0.152021</td>\n",
       "      <td>0.996901</td>\n",
       "      <td>-0.017035</td>\n",
       "      <td>0.495728</td>\n",
       "      <td>-0.283716</td>\n",
       "      <td>-0.129142</td>\n",
       "      <td>-0.475284</td>\n",
       "      <td>0.982396</td>\n",
       "      <td>0.629266</td>\n",
       "      <td>-0.080522</td>\n",
       "      <td>-0.999854</td>\n",
       "      <td>0.434384</td>\n",
       "      <td>0.988834</td>\n",
       "      <td>0.998342</td>\n",
       "      <td>0.963029</td>\n",
       "      <td>0.498420</td>\n",
       "      <td>-0.995366</td>\n",
       "      <td>-0.244770</td>\n",
       "      <td>0.473261</td>\n",
       "      <td>-0.491911</td>\n",
       "      <td>0.403359</td>\n",
       "      <td>-0.067090</td>\n",
       "      <td>0.131189</td>\n",
       "      <td>-0.999956</td>\n",
       "      <td>-0.990382</td>\n",
       "      <td>-0.170253</td>\n",
       "      <td>-0.982404</td>\n",
       "      <td>0.998999</td>\n",
       "      <td>-0.086391</td>\n",
       "      <td>0.298036</td>\n",
       "      <td>0.188611</td>\n",
       "      <td>0.245520</td>\n",
       "      <td>-0.112471</td>\n",
       "      <td>-0.993676</td>\n",
       "      <td>-0.999007</td>\n",
       "      <td>-0.036317</td>\n",
       "      <td>-0.095883</td>\n",
       "      <td>-0.597524</td>\n",
       "      <td>-0.213376</td>\n",
       "      <td>-0.999985</td>\n",
       "      <td>0.687367</td>\n",
       "      <td>-0.523864</td>\n",
       "      <td>-0.308346</td>\n",
       "      <td>-0.090320</td>\n",
       "      <td>-0.303900</td>\n",
       "      <td>0.476349</td>\n",
       "      <td>-0.998545</td>\n",
       "      <td>0.994271</td>\n",
       "      <td>-0.328554</td>\n",
       "      <td>0.147006</td>\n",
       "      <td>-0.317300</td>\n",
       "      <td>-0.098805</td>\n",
       "      <td>-0.224524</td>\n",
       "      <td>-0.883997</td>\n",
       "      <td>0.993772</td>\n",
       "      <td>-0.982530</td>\n",
       "      <td>-0.243203</td>\n",
       "      <td>0.382119</td>\n",
       "      <td>-0.313331</td>\n",
       "      <td>-0.974009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Group_01_1</td>\n",
       "      <td>Group_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992203</td>\n",
       "      <td>-0.195000</td>\n",
       "      <td>-0.025400</td>\n",
       "      <td>0.008844</td>\n",
       "      <td>-0.044000</td>\n",
       "      <td>0.991036</td>\n",
       "      <td>0.992010</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>-0.208000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.237743</td>\n",
       "      <td>-0.960000</td>\n",
       "      <td>-0.981000</td>\n",
       "      <td>-0.984000</td>\n",
       "      <td>0.431453</td>\n",
       "      <td>0.012080</td>\n",
       "      <td>0.112708</td>\n",
       "      <td>-0.346000</td>\n",
       "      <td>0.021867</td>\n",
       "      <td>0.296921</td>\n",
       "      <td>0.024934</td>\n",
       "      <td>-0.378000</td>\n",
       "      <td>0.021184</td>\n",
       "      <td>0.985416</td>\n",
       "      <td>0.994567</td>\n",
       "      <td>0.998374</td>\n",
       "      <td>-0.254000</td>\n",
       "      <td>-0.190000</td>\n",
       "      <td>0.275593</td>\n",
       "      <td>-0.170000</td>\n",
       "      <td>0.996735</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>0.354280</td>\n",
       "      <td>0.248492</td>\n",
       "      <td>-0.952000</td>\n",
       "      <td>-0.225000</td>\n",
       "      <td>-0.060400</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>0.977625</td>\n",
       "      <td>0.337965</td>\n",
       "      <td>-0.102000</td>\n",
       "      <td>-0.054500</td>\n",
       "      <td>-0.187000</td>\n",
       "      <td>-0.991000</td>\n",
       "      <td>-0.354000</td>\n",
       "      <td>-0.620000</td>\n",
       "      <td>-0.988000</td>\n",
       "      <td>-0.407000</td>\n",
       "      <td>-0.444000</td>\n",
       "      <td>-0.493000</td>\n",
       "      <td>0.998378</td>\n",
       "      <td>-0.190000</td>\n",
       "      <td>0.999699</td>\n",
       "      <td>-0.293000</td>\n",
       "      <td>-0.133000</td>\n",
       "      <td>0.190672</td>\n",
       "      <td>0.272142</td>\n",
       "      <td>-0.361000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.229848</td>\n",
       "      <td>0.308777</td>\n",
       "      <td>0.989184</td>\n",
       "      <td>0.080059</td>\n",
       "      <td>0.342320</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>0.999421</td>\n",
       "      <td>0.671315</td>\n",
       "      <td>-0.386000</td>\n",
       "      <td>0.945902</td>\n",
       "      <td>0.999461</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>-0.388000</td>\n",
       "      <td>-0.856000</td>\n",
       "      <td>-0.879000</td>\n",
       "      <td>0.085517</td>\n",
       "      <td>0.411025</td>\n",
       "      <td>0.983853</td>\n",
       "      <td>-0.341000</td>\n",
       "      <td>-0.013800</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.186000</td>\n",
       "      <td>0.953507</td>\n",
       "      <td>-0.249000</td>\n",
       "      <td>0.985975</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.181870</td>\n",
       "      <td>0.249904</td>\n",
       "      <td>-0.025600</td>\n",
       "      <td>0.153448</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>-0.148000</td>\n",
       "      <td>0.465504</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>-0.964000</td>\n",
       "      <td>0.460726</td>\n",
       "      <td>0.991903</td>\n",
       "      <td>0.150491</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-0.438000</td>\n",
       "      <td>-0.922000</td>\n",
       "      <td>-0.989000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.054668</td>\n",
       "      <td>-0.236000</td>\n",
       "      <td>-0.070600</td>\n",
       "      <td>0.982736</td>\n",
       "      <td>0.233068</td>\n",
       "      <td>-0.225000</td>\n",
       "      <td>-0.967000</td>\n",
       "      <td>-0.498000</td>\n",
       "      <td>0.170076</td>\n",
       "      <td>0.998986</td>\n",
       "      <td>-0.990000</td>\n",
       "      <td>-0.278000</td>\n",
       "      <td>0.451641</td>\n",
       "      <td>-0.368000</td>\n",
       "      <td>0.828351</td>\n",
       "      <td>-0.079000</td>\n",
       "      <td>0.998146</td>\n",
       "      <td>-0.974000</td>\n",
       "      <td>-0.060100</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.979000</td>\n",
       "      <td>-0.137000</td>\n",
       "      <td>-0.310000</td>\n",
       "      <td>-0.761000</td>\n",
       "      <td>-0.312000</td>\n",
       "      <td>-0.317000</td>\n",
       "      <td>0.124763</td>\n",
       "      <td>0.985110</td>\n",
       "      <td>0.961786</td>\n",
       "      <td>0.997659</td>\n",
       "      <td>-0.233000</td>\n",
       "      <td>0.461310</td>\n",
       "      <td>-0.950000</td>\n",
       "      <td>0.999834</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.130054</td>\n",
       "      <td>0.999395</td>\n",
       "      <td>0.016705</td>\n",
       "      <td>-0.541000</td>\n",
       "      <td>0.824489</td>\n",
       "      <td>0.142941</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>-0.834000</td>\n",
       "      <td>0.997545</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>0.012214</td>\n",
       "      <td>-0.654000</td>\n",
       "      <td>0.248004</td>\n",
       "      <td>0.992716</td>\n",
       "      <td>-0.185000</td>\n",
       "      <td>0.373863</td>\n",
       "      <td>-0.477000</td>\n",
       "      <td>0.957066</td>\n",
       "      <td>0.489266</td>\n",
       "      <td>-0.037000</td>\n",
       "      <td>-0.195000</td>\n",
       "      <td>-0.094900</td>\n",
       "      <td>-0.193000</td>\n",
       "      <td>-0.337000</td>\n",
       "      <td>-0.035600</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.138639</td>\n",
       "      <td>-0.653000</td>\n",
       "      <td>-0.028800</td>\n",
       "      <td>0.998052</td>\n",
       "      <td>0.997043</td>\n",
       "      <td>0.405457</td>\n",
       "      <td>-0.878000</td>\n",
       "      <td>-0.769000</td>\n",
       "      <td>0.609645</td>\n",
       "      <td>0.696417</td>\n",
       "      <td>0.564661</td>\n",
       "      <td>-0.017700</td>\n",
       "      <td>-0.145000</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>0.886281</td>\n",
       "      <td>0.771532</td>\n",
       "      <td>-0.071500</td>\n",
       "      <td>0.992598</td>\n",
       "      <td>0.170551</td>\n",
       "      <td>0.942658</td>\n",
       "      <td>-0.957000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.946000</td>\n",
       "      <td>0.504705</td>\n",
       "      <td>0.933801</td>\n",
       "      <td>0.984782</td>\n",
       "      <td>-0.905000</td>\n",
       "      <td>0.505902</td>\n",
       "      <td>-0.469000</td>\n",
       "      <td>0.994556</td>\n",
       "      <td>-0.123000</td>\n",
       "      <td>-0.824000</td>\n",
       "      <td>-0.985000</td>\n",
       "      <td>0.890216</td>\n",
       "      <td>0.089982</td>\n",
       "      <td>-0.366000</td>\n",
       "      <td>-0.011700</td>\n",
       "      <td>-0.965000</td>\n",
       "      <td>0.154911</td>\n",
       "      <td>-0.371000</td>\n",
       "      <td>0.998081</td>\n",
       "      <td>-0.378000</td>\n",
       "      <td>0.996804</td>\n",
       "      <td>0.999004</td>\n",
       "      <td>0.197746</td>\n",
       "      <td>0.945838</td>\n",
       "      <td>0.917937</td>\n",
       "      <td>-0.102000</td>\n",
       "      <td>-0.240000</td>\n",
       "      <td>0.983375</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.895000</td>\n",
       "      <td>0.923222</td>\n",
       "      <td>0.759845</td>\n",
       "      <td>0.031928</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.314000</td>\n",
       "      <td>-0.606000</td>\n",
       "      <td>0.208250</td>\n",
       "      <td>-0.856000</td>\n",
       "      <td>-0.543000</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>-0.041500</td>\n",
       "      <td>-0.721000</td>\n",
       "      <td>0.996308</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0.332726</td>\n",
       "      <td>0.114710</td>\n",
       "      <td>0.090718</td>\n",
       "      <td>0.997523</td>\n",
       "      <td>-0.416000</td>\n",
       "      <td>-0.165000</td>\n",
       "      <td>-0.504000</td>\n",
       "      <td>0.281646</td>\n",
       "      <td>-0.338000</td>\n",
       "      <td>-0.025700</td>\n",
       "      <td>0.999914</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>-0.597000</td>\n",
       "      <td>-0.168000</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.234174</td>\n",
       "      <td>0.992798</td>\n",
       "      <td>-0.137000</td>\n",
       "      <td>-0.282000</td>\n",
       "      <td>-0.099400</td>\n",
       "      <td>0.082188</td>\n",
       "      <td>0.422520</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>0.026241</td>\n",
       "      <td>-0.077000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.624846</td>\n",
       "      <td>0.691106</td>\n",
       "      <td>-0.334000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.395000</td>\n",
       "      <td>-0.075000</td>\n",
       "      <td>-0.188000</td>\n",
       "      <td>0.924990</td>\n",
       "      <td>0.999238</td>\n",
       "      <td>-0.283000</td>\n",
       "      <td>0.317798</td>\n",
       "      <td>-0.045800</td>\n",
       "      <td>0.999637</td>\n",
       "      <td>0.219680</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>-0.173000</td>\n",
       "      <td>-0.956000</td>\n",
       "      <td>0.511480</td>\n",
       "      <td>0.194148</td>\n",
       "      <td>-0.983000</td>\n",
       "      <td>-0.460000</td>\n",
       "      <td>-0.330000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.888024</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.470900</td>\n",
       "      <td>-0.451000</td>\n",
       "      <td>0.100027</td>\n",
       "      <td>0.180963</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>-0.381000</td>\n",
       "      <td>0.744640</td>\n",
       "      <td>0.192876</td>\n",
       "      <td>0.998887</td>\n",
       "      <td>0.998605</td>\n",
       "      <td>-0.984000</td>\n",
       "      <td>-0.187000</td>\n",
       "      <td>0.856523</td>\n",
       "      <td>-0.567000</td>\n",
       "      <td>0.999678</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>-0.991000</td>\n",
       "      <td>-0.145000</td>\n",
       "      <td>0.999723</td>\n",
       "      <td>-0.415000</td>\n",
       "      <td>0.272462</td>\n",
       "      <td>0.035769</td>\n",
       "      <td>0.988414</td>\n",
       "      <td>-0.539000</td>\n",
       "      <td>0.431718</td>\n",
       "      <td>0.234432</td>\n",
       "      <td>-0.977000</td>\n",
       "      <td>-0.358000</td>\n",
       "      <td>-0.096900</td>\n",
       "      <td>0.997075</td>\n",
       "      <td>0.404281</td>\n",
       "      <td>0.465322</td>\n",
       "      <td>-0.157000</td>\n",
       "      <td>-0.034400</td>\n",
       "      <td>0.998150</td>\n",
       "      <td>0.336056</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>-0.346000</td>\n",
       "      <td>-0.923000</td>\n",
       "      <td>0.076270</td>\n",
       "      <td>0.287246</td>\n",
       "      <td>-0.745000</td>\n",
       "      <td>0.657670</td>\n",
       "      <td>-0.969000</td>\n",
       "      <td>0.720943</td>\n",
       "      <td>0.956508</td>\n",
       "      <td>-0.133000</td>\n",
       "      <td>-0.020800</td>\n",
       "      <td>0.880393</td>\n",
       "      <td>0.162702</td>\n",
       "      <td>0.147762</td>\n",
       "      <td>0.235067</td>\n",
       "      <td>0.023444</td>\n",
       "      <td>0.077684</td>\n",
       "      <td>-0.238000</td>\n",
       "      <td>0.985406</td>\n",
       "      <td>-0.365000</td>\n",
       "      <td>0.246289</td>\n",
       "      <td>0.995883</td>\n",
       "      <td>-0.970000</td>\n",
       "      <td>0.870434</td>\n",
       "      <td>0.435602</td>\n",
       "      <td>0.936799</td>\n",
       "      <td>-0.208000</td>\n",
       "      <td>0.998394</td>\n",
       "      <td>-0.164000</td>\n",
       "      <td>0.075216</td>\n",
       "      <td>-0.661000</td>\n",
       "      <td>0.342232</td>\n",
       "      <td>0.493600</td>\n",
       "      <td>0.368686</td>\n",
       "      <td>-0.890000</td>\n",
       "      <td>-0.363000</td>\n",
       "      <td>0.211839</td>\n",
       "      <td>-0.275000</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>-0.170000</td>\n",
       "      <td>0.138964</td>\n",
       "      <td>-0.409000</td>\n",
       "      <td>-0.929000</td>\n",
       "      <td>-0.165000</td>\n",
       "      <td>0.185008</td>\n",
       "      <td>0.150503</td>\n",
       "      <td>0.675143</td>\n",
       "      <td>-0.205000</td>\n",
       "      <td>0.844854</td>\n",
       "      <td>-0.534000</td>\n",
       "      <td>-0.094600</td>\n",
       "      <td>0.955684</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.173560</td>\n",
       "      <td>-0.228000</td>\n",
       "      <td>-0.448000</td>\n",
       "      <td>-0.034600</td>\n",
       "      <td>0.725003</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>-0.969000</td>\n",
       "      <td>-0.141000</td>\n",
       "      <td>0.997981</td>\n",
       "      <td>-0.759000</td>\n",
       "      <td>-0.079900</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>0.301462</td>\n",
       "      <td>0.347660</td>\n",
       "      <td>0.036429</td>\n",
       "      <td>0.933821</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.045149</td>\n",
       "      <td>0.190278</td>\n",
       "      <td>-0.356000</td>\n",
       "      <td>-0.668000</td>\n",
       "      <td>0.139946</td>\n",
       "      <td>0.992478</td>\n",
       "      <td>-0.528000</td>\n",
       "      <td>0.109165</td>\n",
       "      <td>-0.744000</td>\n",
       "      <td>-0.987000</td>\n",
       "      <td>-0.044800</td>\n",
       "      <td>0.999789</td>\n",
       "      <td>0.989561</td>\n",
       "      <td>0.874783</td>\n",
       "      <td>0.444602</td>\n",
       "      <td>-0.086700</td>\n",
       "      <td>-0.971000</td>\n",
       "      <td>0.982121</td>\n",
       "      <td>0.720672</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.219000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.301769</td>\n",
       "      <td>0.359827</td>\n",
       "      <td>-0.735000</td>\n",
       "      <td>-0.467000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.450000</td>\n",
       "      <td>0.932233</td>\n",
       "      <td>-0.494000</td>\n",
       "      <td>0.969037</td>\n",
       "      <td>0.477581</td>\n",
       "      <td>-0.801000</td>\n",
       "      <td>-0.227000</td>\n",
       "      <td>-0.147000</td>\n",
       "      <td>-0.206000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.191000</td>\n",
       "      <td>0.987950</td>\n",
       "      <td>0.999710</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.952000</td>\n",
       "      <td>0.099232</td>\n",
       "      <td>-0.981000</td>\n",
       "      <td>-0.218000</td>\n",
       "      <td>0.385699</td>\n",
       "      <td>-0.138000</td>\n",
       "      <td>-0.368000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.033560</td>\n",
       "      <td>0.132350</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.894000</td>\n",
       "      <td>-0.821000</td>\n",
       "      <td>0.497162</td>\n",
       "      <td>-0.202000</td>\n",
       "      <td>-0.293000</td>\n",
       "      <td>-0.440000</td>\n",
       "      <td>0.242348</td>\n",
       "      <td>0.164634</td>\n",
       "      <td>0.992304</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.998284</td>\n",
       "      <td>-0.236000</td>\n",
       "      <td>0.167181</td>\n",
       "      <td>-0.144000</td>\n",
       "      <td>0.998881</td>\n",
       "      <td>0.942642</td>\n",
       "      <td>0.165502</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.098290</td>\n",
       "      <td>0.982202</td>\n",
       "      <td>0.997373</td>\n",
       "      <td>0.963495</td>\n",
       "      <td>0.998369</td>\n",
       "      <td>-0.951000</td>\n",
       "      <td>0.109453</td>\n",
       "      <td>0.159157</td>\n",
       "      <td>-0.896000</td>\n",
       "      <td>0.050089</td>\n",
       "      <td>-0.161000</td>\n",
       "      <td>0.355124</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>-0.158000</td>\n",
       "      <td>-0.975000</td>\n",
       "      <td>0.827316</td>\n",
       "      <td>0.247723</td>\n",
       "      <td>0.181496</td>\n",
       "      <td>0.300091</td>\n",
       "      <td>0.017353</td>\n",
       "      <td>0.082390</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.007749</td>\n",
       "      <td>-0.588000</td>\n",
       "      <td>0.205214</td>\n",
       "      <td>-0.029100</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.966000</td>\n",
       "      <td>0.983397</td>\n",
       "      <td>0.071726</td>\n",
       "      <td>-0.394000</td>\n",
       "      <td>-0.103000</td>\n",
       "      <td>0.401782</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.997540</td>\n",
       "      <td>-0.349000</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>-0.619000</td>\n",
       "      <td>0.537897</td>\n",
       "      <td>0.342348</td>\n",
       "      <td>0.167375</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>0.306038</td>\n",
       "      <td>0.426094</td>\n",
       "      <td>-0.471000</td>\n",
       "      <td>-0.592000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Group_01_10</td>\n",
       "      <td>Group_01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990013</td>\n",
       "      <td>0.750048</td>\n",
       "      <td>-0.134000</td>\n",
       "      <td>0.130585</td>\n",
       "      <td>0.618464</td>\n",
       "      <td>0.944665</td>\n",
       "      <td>0.338610</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.020900</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>0.040928</td>\n",
       "      <td>-0.988000</td>\n",
       "      <td>0.375986</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>-0.391000</td>\n",
       "      <td>0.015971</td>\n",
       "      <td>-0.273000</td>\n",
       "      <td>0.543410</td>\n",
       "      <td>-0.631000</td>\n",
       "      <td>-0.198000</td>\n",
       "      <td>0.263983</td>\n",
       "      <td>-0.381000</td>\n",
       "      <td>-0.232000</td>\n",
       "      <td>0.517442</td>\n",
       "      <td>0.999072</td>\n",
       "      <td>0.976915</td>\n",
       "      <td>-0.173000</td>\n",
       "      <td>-0.012100</td>\n",
       "      <td>0.351231</td>\n",
       "      <td>0.745242</td>\n",
       "      <td>0.998227</td>\n",
       "      <td>0.103937</td>\n",
       "      <td>0.075398</td>\n",
       "      <td>0.270600</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.296710</td>\n",
       "      <td>0.091600</td>\n",
       "      <td>-0.386000</td>\n",
       "      <td>0.920225</td>\n",
       "      <td>0.036674</td>\n",
       "      <td>0.256350</td>\n",
       "      <td>0.224223</td>\n",
       "      <td>0.099948</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.041984</td>\n",
       "      <td>0.582943</td>\n",
       "      <td>-0.979000</td>\n",
       "      <td>0.264309</td>\n",
       "      <td>0.093355</td>\n",
       "      <td>0.125059</td>\n",
       "      <td>0.986786</td>\n",
       "      <td>-0.032100</td>\n",
       "      <td>0.989188</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.177000</td>\n",
       "      <td>-0.022700</td>\n",
       "      <td>-0.393000</td>\n",
       "      <td>0.350795</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.090400</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.988602</td>\n",
       "      <td>0.316577</td>\n",
       "      <td>-0.130000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.989132</td>\n",
       "      <td>0.732761</td>\n",
       "      <td>-0.263000</td>\n",
       "      <td>-0.849000</td>\n",
       "      <td>0.978371</td>\n",
       "      <td>0.999881</td>\n",
       "      <td>-0.949000</td>\n",
       "      <td>-0.661000</td>\n",
       "      <td>-0.797000</td>\n",
       "      <td>-0.352000</td>\n",
       "      <td>-0.220000</td>\n",
       "      <td>0.998991</td>\n",
       "      <td>0.008501</td>\n",
       "      <td>0.249850</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.238930</td>\n",
       "      <td>0.996669</td>\n",
       "      <td>0.129989</td>\n",
       "      <td>0.979419</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.038700</td>\n",
       "      <td>0.275069</td>\n",
       "      <td>-0.079500</td>\n",
       "      <td>-0.296000</td>\n",
       "      <td>-0.985000</td>\n",
       "      <td>0.032675</td>\n",
       "      <td>0.181985</td>\n",
       "      <td>-0.985000</td>\n",
       "      <td>-0.660000</td>\n",
       "      <td>-0.832000</td>\n",
       "      <td>0.995754</td>\n",
       "      <td>0.157598</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>0.114108</td>\n",
       "      <td>-0.705000</td>\n",
       "      <td>-0.976000</td>\n",
       "      <td>-0.981000</td>\n",
       "      <td>0.140159</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.121000</td>\n",
       "      <td>0.869535</td>\n",
       "      <td>0.317020</td>\n",
       "      <td>-0.261000</td>\n",
       "      <td>-0.976000</td>\n",
       "      <td>-0.122000</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>0.993566</td>\n",
       "      <td>-0.989000</td>\n",
       "      <td>0.130981</td>\n",
       "      <td>0.271772</td>\n",
       "      <td>-0.952000</td>\n",
       "      <td>-0.139000</td>\n",
       "      <td>-0.021800</td>\n",
       "      <td>0.995086</td>\n",
       "      <td>-0.846000</td>\n",
       "      <td>-0.068900</td>\n",
       "      <td>-0.978000</td>\n",
       "      <td>0.083944</td>\n",
       "      <td>0.305471</td>\n",
       "      <td>-0.342000</td>\n",
       "      <td>-0.494000</td>\n",
       "      <td>0.100076</td>\n",
       "      <td>-0.339000</td>\n",
       "      <td>-0.185000</td>\n",
       "      <td>0.903439</td>\n",
       "      <td>0.646815</td>\n",
       "      <td>0.988795</td>\n",
       "      <td>-0.182000</td>\n",
       "      <td>0.126245</td>\n",
       "      <td>-0.521000</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.981000</td>\n",
       "      <td>0.251484</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>-0.037500</td>\n",
       "      <td>0.049766</td>\n",
       "      <td>0.837111</td>\n",
       "      <td>-0.214000</td>\n",
       "      <td>0.996144</td>\n",
       "      <td>-0.843000</td>\n",
       "      <td>0.999474</td>\n",
       "      <td>-0.922000</td>\n",
       "      <td>0.107709</td>\n",
       "      <td>-0.192000</td>\n",
       "      <td>-0.282000</td>\n",
       "      <td>0.970726</td>\n",
       "      <td>0.312049</td>\n",
       "      <td>-0.129000</td>\n",
       "      <td>0.381809</td>\n",
       "      <td>-0.399000</td>\n",
       "      <td>0.366038</td>\n",
       "      <td>-0.020400</td>\n",
       "      <td>-0.055100</td>\n",
       "      <td>-0.070900</td>\n",
       "      <td>0.017522</td>\n",
       "      <td>-0.143000</td>\n",
       "      <td>0.027316</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>-0.129000</td>\n",
       "      <td>0.192006</td>\n",
       "      <td>-0.476000</td>\n",
       "      <td>0.998942</td>\n",
       "      <td>0.963639</td>\n",
       "      <td>-0.219000</td>\n",
       "      <td>-0.464000</td>\n",
       "      <td>-0.884000</td>\n",
       "      <td>-0.670000</td>\n",
       "      <td>0.181567</td>\n",
       "      <td>0.146198</td>\n",
       "      <td>-0.473000</td>\n",
       "      <td>0.030433</td>\n",
       "      <td>0.998868</td>\n",
       "      <td>0.753553</td>\n",
       "      <td>0.682994</td>\n",
       "      <td>0.194283</td>\n",
       "      <td>0.994441</td>\n",
       "      <td>-0.867000</td>\n",
       "      <td>-0.207000</td>\n",
       "      <td>-0.966000</td>\n",
       "      <td>-0.966000</td>\n",
       "      <td>-0.323000</td>\n",
       "      <td>0.016843</td>\n",
       "      <td>0.996583</td>\n",
       "      <td>0.969245</td>\n",
       "      <td>-0.985000</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.344000</td>\n",
       "      <td>0.993916</td>\n",
       "      <td>0.226423</td>\n",
       "      <td>-0.971000</td>\n",
       "      <td>-0.988000</td>\n",
       "      <td>0.365620</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>0.254417</td>\n",
       "      <td>-0.362000</td>\n",
       "      <td>-0.893000</td>\n",
       "      <td>-0.377000</td>\n",
       "      <td>0.159259</td>\n",
       "      <td>0.753790</td>\n",
       "      <td>-0.302000</td>\n",
       "      <td>0.999589</td>\n",
       "      <td>0.992928</td>\n",
       "      <td>-0.245000</td>\n",
       "      <td>-0.804000</td>\n",
       "      <td>-0.497000</td>\n",
       "      <td>0.129984</td>\n",
       "      <td>-0.008330</td>\n",
       "      <td>0.984743</td>\n",
       "      <td>-0.983000</td>\n",
       "      <td>0.724334</td>\n",
       "      <td>0.992088</td>\n",
       "      <td>0.879922</td>\n",
       "      <td>-0.122000</td>\n",
       "      <td>-0.980000</td>\n",
       "      <td>0.267830</td>\n",
       "      <td>-0.616000</td>\n",
       "      <td>0.394264</td>\n",
       "      <td>0.219160</td>\n",
       "      <td>-0.986000</td>\n",
       "      <td>-0.985000</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>-0.861000</td>\n",
       "      <td>-0.061000</td>\n",
       "      <td>0.152341</td>\n",
       "      <td>-0.069100</td>\n",
       "      <td>-0.407000</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>0.968031</td>\n",
       "      <td>0.033380</td>\n",
       "      <td>-0.973000</td>\n",
       "      <td>0.031390</td>\n",
       "      <td>0.116557</td>\n",
       "      <td>-0.011000</td>\n",
       "      <td>0.571601</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.629000</td>\n",
       "      <td>0.995906</td>\n",
       "      <td>0.615156</td>\n",
       "      <td>0.155956</td>\n",
       "      <td>0.999515</td>\n",
       "      <td>-0.167000</td>\n",
       "      <td>0.974963</td>\n",
       "      <td>-0.292000</td>\n",
       "      <td>0.140689</td>\n",
       "      <td>0.427767</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>-0.089400</td>\n",
       "      <td>0.999846</td>\n",
       "      <td>0.090744</td>\n",
       "      <td>0.110101</td>\n",
       "      <td>-0.828000</td>\n",
       "      <td>-0.541000</td>\n",
       "      <td>0.933814</td>\n",
       "      <td>-0.196000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.074826</td>\n",
       "      <td>-0.943000</td>\n",
       "      <td>0.074229</td>\n",
       "      <td>0.984524</td>\n",
       "      <td>0.986345</td>\n",
       "      <td>-0.893000</td>\n",
       "      <td>0.367183</td>\n",
       "      <td>0.030727</td>\n",
       "      <td>0.999232</td>\n",
       "      <td>0.105616</td>\n",
       "      <td>-0.960000</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>-0.357000</td>\n",
       "      <td>-0.934000</td>\n",
       "      <td>0.967844</td>\n",
       "      <td>-0.203000</td>\n",
       "      <td>0.948408</td>\n",
       "      <td>0.491955</td>\n",
       "      <td>0.175758</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>0.924632</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>-0.477000</td>\n",
       "      <td>0.206851</td>\n",
       "      <td>-0.089600</td>\n",
       "      <td>-0.019200</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.526000</td>\n",
       "      <td>-0.226000</td>\n",
       "      <td>0.121709</td>\n",
       "      <td>0.932784</td>\n",
       "      <td>0.999713</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-0.060300</td>\n",
       "      <td>0.673281</td>\n",
       "      <td>-0.127000</td>\n",
       "      <td>0.994465</td>\n",
       "      <td>0.999585</td>\n",
       "      <td>-0.447000</td>\n",
       "      <td>-0.544000</td>\n",
       "      <td>0.994414</td>\n",
       "      <td>-0.126000</td>\n",
       "      <td>-0.281000</td>\n",
       "      <td>-0.318000</td>\n",
       "      <td>0.996715</td>\n",
       "      <td>0.620176</td>\n",
       "      <td>-0.044600</td>\n",
       "      <td>0.408722</td>\n",
       "      <td>-0.847000</td>\n",
       "      <td>0.070309</td>\n",
       "      <td>0.998687</td>\n",
       "      <td>0.978490</td>\n",
       "      <td>0.129572</td>\n",
       "      <td>-0.040700</td>\n",
       "      <td>-0.151000</td>\n",
       "      <td>0.320149</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>-0.248000</td>\n",
       "      <td>0.837871</td>\n",
       "      <td>-0.087400</td>\n",
       "      <td>-0.781000</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>0.148104</td>\n",
       "      <td>-0.860000</td>\n",
       "      <td>-0.159000</td>\n",
       "      <td>-0.974000</td>\n",
       "      <td>-0.509000</td>\n",
       "      <td>0.995315</td>\n",
       "      <td>-0.185000</td>\n",
       "      <td>-0.000523</td>\n",
       "      <td>-0.610000</td>\n",
       "      <td>-0.149000</td>\n",
       "      <td>0.064591</td>\n",
       "      <td>0.211459</td>\n",
       "      <td>0.173628</td>\n",
       "      <td>-0.740000</td>\n",
       "      <td>0.014987</td>\n",
       "      <td>0.939468</td>\n",
       "      <td>0.138112</td>\n",
       "      <td>-0.192000</td>\n",
       "      <td>0.974841</td>\n",
       "      <td>-0.828000</td>\n",
       "      <td>-0.103000</td>\n",
       "      <td>0.844080</td>\n",
       "      <td>0.999859</td>\n",
       "      <td>-0.105000</td>\n",
       "      <td>0.349439</td>\n",
       "      <td>0.073988</td>\n",
       "      <td>0.241605</td>\n",
       "      <td>0.832350</td>\n",
       "      <td>0.115179</td>\n",
       "      <td>0.848428</td>\n",
       "      <td>-0.262000</td>\n",
       "      <td>-0.237000</td>\n",
       "      <td>0.041896</td>\n",
       "      <td>-0.431000</td>\n",
       "      <td>0.232535</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.713000</td>\n",
       "      <td>0.089098</td>\n",
       "      <td>-0.176000</td>\n",
       "      <td>0.271497</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.792000</td>\n",
       "      <td>0.454449</td>\n",
       "      <td>-0.156000</td>\n",
       "      <td>-0.314000</td>\n",
       "      <td>0.015544</td>\n",
       "      <td>0.998459</td>\n",
       "      <td>-0.165000</td>\n",
       "      <td>0.414404</td>\n",
       "      <td>0.702676</td>\n",
       "      <td>-0.966000</td>\n",
       "      <td>-0.199000</td>\n",
       "      <td>0.061105</td>\n",
       "      <td>0.203874</td>\n",
       "      <td>-0.316000</td>\n",
       "      <td>0.968342</td>\n",
       "      <td>-0.034400</td>\n",
       "      <td>-0.949000</td>\n",
       "      <td>0.047889</td>\n",
       "      <td>0.999705</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.310279</td>\n",
       "      <td>-0.070200</td>\n",
       "      <td>0.868310</td>\n",
       "      <td>-0.494000</td>\n",
       "      <td>-0.442000</td>\n",
       "      <td>0.997342</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.237000</td>\n",
       "      <td>-0.254000</td>\n",
       "      <td>0.286875</td>\n",
       "      <td>-0.109000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.995162</td>\n",
       "      <td>-0.021300</td>\n",
       "      <td>-0.123000</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>0.076182</td>\n",
       "      <td>0.119006</td>\n",
       "      <td>0.999074</td>\n",
       "      <td>-0.987000</td>\n",
       "      <td>-0.527000</td>\n",
       "      <td>-0.046500</td>\n",
       "      <td>0.178304</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.648460</td>\n",
       "      <td>-0.589000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.182710</td>\n",
       "      <td>-0.854000</td>\n",
       "      <td>0.377037</td>\n",
       "      <td>-0.243000</td>\n",
       "      <td>-0.326000</td>\n",
       "      <td>0.158662</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.101460</td>\n",
       "      <td>0.891874</td>\n",
       "      <td>-0.253000</td>\n",
       "      <td>0.994883</td>\n",
       "      <td>0.196857</td>\n",
       "      <td>-0.939000</td>\n",
       "      <td>-0.180000</td>\n",
       "      <td>0.368143</td>\n",
       "      <td>0.154687</td>\n",
       "      <td>-0.452000</td>\n",
       "      <td>0.029026</td>\n",
       "      <td>-0.987000</td>\n",
       "      <td>0.965877</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.891000</td>\n",
       "      <td>0.029939</td>\n",
       "      <td>-0.771000</td>\n",
       "      <td>-0.708000</td>\n",
       "      <td>-0.098400</td>\n",
       "      <td>0.364890</td>\n",
       "      <td>-0.131000</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-0.770000</td>\n",
       "      <td>0.217463</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.929000</td>\n",
       "      <td>-0.262000</td>\n",
       "      <td>-0.084600</td>\n",
       "      <td>0.061747</td>\n",
       "      <td>0.090182</td>\n",
       "      <td>0.363796</td>\n",
       "      <td>0.175524</td>\n",
       "      <td>0.995217</td>\n",
       "      <td>-0.119000</td>\n",
       "      <td>0.103468</td>\n",
       "      <td>0.068616</td>\n",
       "      <td>-0.002490</td>\n",
       "      <td>-0.086600</td>\n",
       "      <td>0.979897</td>\n",
       "      <td>0.148795</td>\n",
       "      <td>-0.014700</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.044716</td>\n",
       "      <td>0.977056</td>\n",
       "      <td>0.999615</td>\n",
       "      <td>0.983061</td>\n",
       "      <td>0.097360</td>\n",
       "      <td>-0.929000</td>\n",
       "      <td>-0.084000</td>\n",
       "      <td>0.232363</td>\n",
       "      <td>0.661124</td>\n",
       "      <td>0.662587</td>\n",
       "      <td>0.267431</td>\n",
       "      <td>0.068088</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-0.022500</td>\n",
       "      <td>-0.939000</td>\n",
       "      <td>0.999585</td>\n",
       "      <td>0.108051</td>\n",
       "      <td>0.160533</td>\n",
       "      <td>-0.419000</td>\n",
       "      <td>0.164893</td>\n",
       "      <td>0.020401</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.050600</td>\n",
       "      <td>0.203212</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.087100</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.483000</td>\n",
       "      <td>-0.752000</td>\n",
       "      <td>-0.169000</td>\n",
       "      <td>0.108694</td>\n",
       "      <td>-0.101000</td>\n",
       "      <td>0.192364</td>\n",
       "      <td>-0.974000</td>\n",
       "      <td>0.996948</td>\n",
       "      <td>-0.980000</td>\n",
       "      <td>0.179926</td>\n",
       "      <td>0.045391</td>\n",
       "      <td>-0.522000</td>\n",
       "      <td>-0.347000</td>\n",
       "      <td>-0.891000</td>\n",
       "      <td>0.957757</td>\n",
       "      <td>-0.817000</td>\n",
       "      <td>-0.148000</td>\n",
       "      <td>0.309138</td>\n",
       "      <td>-0.133000</td>\n",
       "      <td>-0.914000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Group_01_100</td>\n",
       "      <td>Group_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996965</td>\n",
       "      <td>-0.983000</td>\n",
       "      <td>-0.458000</td>\n",
       "      <td>-0.137000</td>\n",
       "      <td>-0.737000</td>\n",
       "      <td>0.980881</td>\n",
       "      <td>0.999139</td>\n",
       "      <td>-0.937000</td>\n",
       "      <td>-0.389000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.034400</td>\n",
       "      <td>-0.990000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.679000</td>\n",
       "      <td>-0.284000</td>\n",
       "      <td>-0.231000</td>\n",
       "      <td>0.105658</td>\n",
       "      <td>0.381090</td>\n",
       "      <td>-0.580000</td>\n",
       "      <td>0.431569</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>-0.455000</td>\n",
       "      <td>0.555593</td>\n",
       "      <td>0.957810</td>\n",
       "      <td>0.988089</td>\n",
       "      <td>0.977598</td>\n",
       "      <td>-0.045200</td>\n",
       "      <td>-0.305000</td>\n",
       "      <td>0.696800</td>\n",
       "      <td>-0.645000</td>\n",
       "      <td>0.997460</td>\n",
       "      <td>0.080209</td>\n",
       "      <td>0.236457</td>\n",
       "      <td>0.154092</td>\n",
       "      <td>-0.986000</td>\n",
       "      <td>0.168325</td>\n",
       "      <td>0.122909</td>\n",
       "      <td>-0.017600</td>\n",
       "      <td>0.999633</td>\n",
       "      <td>-0.353000</td>\n",
       "      <td>-0.328000</td>\n",
       "      <td>0.205288</td>\n",
       "      <td>0.112366</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.058500</td>\n",
       "      <td>-0.387000</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>-0.329000</td>\n",
       "      <td>-0.211000</td>\n",
       "      <td>-0.192000</td>\n",
       "      <td>0.993463</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.999516</td>\n",
       "      <td>-0.204000</td>\n",
       "      <td>-0.671000</td>\n",
       "      <td>0.425997</td>\n",
       "      <td>0.068917</td>\n",
       "      <td>-0.555000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.985000</td>\n",
       "      <td>-0.316000</td>\n",
       "      <td>-0.115000</td>\n",
       "      <td>0.791934</td>\n",
       "      <td>0.333388</td>\n",
       "      <td>0.185355</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.999400</td>\n",
       "      <td>0.284351</td>\n",
       "      <td>-0.577000</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.998764</td>\n",
       "      <td>0.999493</td>\n",
       "      <td>-0.589000</td>\n",
       "      <td>-0.712000</td>\n",
       "      <td>-0.959000</td>\n",
       "      <td>0.180407</td>\n",
       "      <td>0.472433</td>\n",
       "      <td>0.971119</td>\n",
       "      <td>0.170162</td>\n",
       "      <td>-0.154000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.041200</td>\n",
       "      <td>0.986258</td>\n",
       "      <td>0.027472</td>\n",
       "      <td>0.927011</td>\n",
       "      <td>-0.894000</td>\n",
       "      <td>0.183809</td>\n",
       "      <td>0.019951</td>\n",
       "      <td>-0.474000</td>\n",
       "      <td>0.046255</td>\n",
       "      <td>-0.989000</td>\n",
       "      <td>0.408095</td>\n",
       "      <td>0.713163</td>\n",
       "      <td>-0.979000</td>\n",
       "      <td>-0.990000</td>\n",
       "      <td>0.982813</td>\n",
       "      <td>0.959628</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>-0.040300</td>\n",
       "      <td>-0.978000</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>-0.048900</td>\n",
       "      <td>-0.072000</td>\n",
       "      <td>-0.441000</td>\n",
       "      <td>0.981805</td>\n",
       "      <td>-0.036700</td>\n",
       "      <td>-0.362000</td>\n",
       "      <td>-0.966000</td>\n",
       "      <td>-0.596000</td>\n",
       "      <td>-0.611000</td>\n",
       "      <td>0.967405</td>\n",
       "      <td>-0.989000</td>\n",
       "      <td>0.098778</td>\n",
       "      <td>0.383866</td>\n",
       "      <td>-0.852000</td>\n",
       "      <td>0.999215</td>\n",
       "      <td>-0.103000</td>\n",
       "      <td>0.994441</td>\n",
       "      <td>-0.966000</td>\n",
       "      <td>-0.308000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.575902</td>\n",
       "      <td>-0.073700</td>\n",
       "      <td>-0.311000</td>\n",
       "      <td>-0.901000</td>\n",
       "      <td>-0.296000</td>\n",
       "      <td>-0.177000</td>\n",
       "      <td>-0.001050</td>\n",
       "      <td>0.997983</td>\n",
       "      <td>0.844818</td>\n",
       "      <td>0.996208</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>0.369340</td>\n",
       "      <td>-0.922000</td>\n",
       "      <td>0.999177</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.991000</td>\n",
       "      <td>0.350612</td>\n",
       "      <td>0.999837</td>\n",
       "      <td>0.179926</td>\n",
       "      <td>-0.446000</td>\n",
       "      <td>0.828365</td>\n",
       "      <td>-0.064700</td>\n",
       "      <td>0.994384</td>\n",
       "      <td>-0.920000</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.255000</td>\n",
       "      <td>-0.662000</td>\n",
       "      <td>0.015664</td>\n",
       "      <td>0.996735</td>\n",
       "      <td>-0.427000</td>\n",
       "      <td>0.542020</td>\n",
       "      <td>0.126793</td>\n",
       "      <td>0.976722</td>\n",
       "      <td>0.311476</td>\n",
       "      <td>0.154330</td>\n",
       "      <td>0.041014</td>\n",
       "      <td>-0.043500</td>\n",
       "      <td>-0.121000</td>\n",
       "      <td>-0.132000</td>\n",
       "      <td>-0.720000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>-0.155000</td>\n",
       "      <td>-0.629000</td>\n",
       "      <td>-0.328000</td>\n",
       "      <td>0.943368</td>\n",
       "      <td>0.988999</td>\n",
       "      <td>0.409009</td>\n",
       "      <td>-0.928000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.868686</td>\n",
       "      <td>0.612045</td>\n",
       "      <td>0.602473</td>\n",
       "      <td>-0.651000</td>\n",
       "      <td>-0.215000</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>0.989176</td>\n",
       "      <td>0.995800</td>\n",
       "      <td>-0.063700</td>\n",
       "      <td>0.987954</td>\n",
       "      <td>0.551293</td>\n",
       "      <td>0.763091</td>\n",
       "      <td>-0.410000</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-0.896000</td>\n",
       "      <td>0.555837</td>\n",
       "      <td>0.895012</td>\n",
       "      <td>0.988485</td>\n",
       "      <td>-0.714000</td>\n",
       "      <td>0.732979</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.997537</td>\n",
       "      <td>-0.229000</td>\n",
       "      <td>-0.974000</td>\n",
       "      <td>-0.963000</td>\n",
       "      <td>-0.493000</td>\n",
       "      <td>0.483726</td>\n",
       "      <td>-0.076800</td>\n",
       "      <td>-0.423000</td>\n",
       "      <td>-0.981000</td>\n",
       "      <td>0.302772</td>\n",
       "      <td>-0.113000</td>\n",
       "      <td>0.998833</td>\n",
       "      <td>-0.277000</td>\n",
       "      <td>0.998994</td>\n",
       "      <td>0.999594</td>\n",
       "      <td>-0.158000</td>\n",
       "      <td>0.924195</td>\n",
       "      <td>0.989543</td>\n",
       "      <td>0.010018</td>\n",
       "      <td>0.046268</td>\n",
       "      <td>0.992128</td>\n",
       "      <td>-0.991000</td>\n",
       "      <td>-0.984000</td>\n",
       "      <td>0.196335</td>\n",
       "      <td>0.265038</td>\n",
       "      <td>0.210359</td>\n",
       "      <td>-0.991000</td>\n",
       "      <td>-0.305000</td>\n",
       "      <td>-0.987000</td>\n",
       "      <td>0.520107</td>\n",
       "      <td>-0.957000</td>\n",
       "      <td>-0.103000</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>-0.376000</td>\n",
       "      <td>0.767108</td>\n",
       "      <td>0.993970</td>\n",
       "      <td>0.040434</td>\n",
       "      <td>0.273594</td>\n",
       "      <td>-0.130000</td>\n",
       "      <td>0.352481</td>\n",
       "      <td>0.993538</td>\n",
       "      <td>-0.038200</td>\n",
       "      <td>-0.859000</td>\n",
       "      <td>-0.075900</td>\n",
       "      <td>0.478675</td>\n",
       "      <td>0.372853</td>\n",
       "      <td>0.790405</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.188794</td>\n",
       "      <td>0.998719</td>\n",
       "      <td>-0.529000</td>\n",
       "      <td>0.183876</td>\n",
       "      <td>0.997686</td>\n",
       "      <td>0.363179</td>\n",
       "      <td>0.945341</td>\n",
       "      <td>0.014193</td>\n",
       "      <td>0.357609</td>\n",
       "      <td>-0.436000</td>\n",
       "      <td>-0.305000</td>\n",
       "      <td>0.198819</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>-0.587000</td>\n",
       "      <td>-0.113000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.031844</td>\n",
       "      <td>0.610652</td>\n",
       "      <td>-0.593000</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>-0.562000</td>\n",
       "      <td>-0.368000</td>\n",
       "      <td>-0.059500</td>\n",
       "      <td>0.748359</td>\n",
       "      <td>0.999726</td>\n",
       "      <td>-0.790000</td>\n",
       "      <td>0.325266</td>\n",
       "      <td>-0.233000</td>\n",
       "      <td>0.924168</td>\n",
       "      <td>-0.001650</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>-0.472000</td>\n",
       "      <td>-0.936000</td>\n",
       "      <td>0.968664</td>\n",
       "      <td>0.347250</td>\n",
       "      <td>-0.628000</td>\n",
       "      <td>-0.273000</td>\n",
       "      <td>-0.963000</td>\n",
       "      <td>-0.982000</td>\n",
       "      <td>0.648756</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.905841</td>\n",
       "      <td>0.102062</td>\n",
       "      <td>0.657026</td>\n",
       "      <td>0.505438</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.960000</td>\n",
       "      <td>0.632277</td>\n",
       "      <td>0.479539</td>\n",
       "      <td>0.987655</td>\n",
       "      <td>0.998587</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.152000</td>\n",
       "      <td>0.905977</td>\n",
       "      <td>-0.358000</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.437833</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>-0.556000</td>\n",
       "      <td>-0.281000</td>\n",
       "      <td>-0.030100</td>\n",
       "      <td>0.980011</td>\n",
       "      <td>-0.972000</td>\n",
       "      <td>0.218429</td>\n",
       "      <td>-0.089600</td>\n",
       "      <td>-0.922000</td>\n",
       "      <td>0.305100</td>\n",
       "      <td>0.920896</td>\n",
       "      <td>0.997030</td>\n",
       "      <td>0.134503</td>\n",
       "      <td>0.592979</td>\n",
       "      <td>-0.158000</td>\n",
       "      <td>0.122935</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>-0.367000</td>\n",
       "      <td>-0.597000</td>\n",
       "      <td>-0.112000</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>0.215898</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.855000</td>\n",
       "      <td>0.949854</td>\n",
       "      <td>-0.805000</td>\n",
       "      <td>0.898583</td>\n",
       "      <td>0.950278</td>\n",
       "      <td>-0.544000</td>\n",
       "      <td>-0.033900</td>\n",
       "      <td>0.941936</td>\n",
       "      <td>-0.118000</td>\n",
       "      <td>0.353592</td>\n",
       "      <td>0.275609</td>\n",
       "      <td>0.230965</td>\n",
       "      <td>0.086466</td>\n",
       "      <td>-0.049600</td>\n",
       "      <td>0.942181</td>\n",
       "      <td>-0.430000</td>\n",
       "      <td>-0.265000</td>\n",
       "      <td>0.980873</td>\n",
       "      <td>-0.978000</td>\n",
       "      <td>0.484047</td>\n",
       "      <td>-0.172000</td>\n",
       "      <td>0.997200</td>\n",
       "      <td>0.629332</td>\n",
       "      <td>0.997884</td>\n",
       "      <td>-0.057400</td>\n",
       "      <td>0.311270</td>\n",
       "      <td>0.796157</td>\n",
       "      <td>0.223559</td>\n",
       "      <td>0.046060</td>\n",
       "      <td>-0.114000</td>\n",
       "      <td>-0.990000</td>\n",
       "      <td>0.125186</td>\n",
       "      <td>-0.011900</td>\n",
       "      <td>0.122508</td>\n",
       "      <td>-0.948000</td>\n",
       "      <td>0.541228</td>\n",
       "      <td>-0.103000</td>\n",
       "      <td>-0.311000</td>\n",
       "      <td>-0.255000</td>\n",
       "      <td>-0.978000</td>\n",
       "      <td>0.303367</td>\n",
       "      <td>0.605459</td>\n",
       "      <td>0.500001</td>\n",
       "      <td>0.635336</td>\n",
       "      <td>-0.512000</td>\n",
       "      <td>0.712422</td>\n",
       "      <td>-0.720000</td>\n",
       "      <td>-0.315000</td>\n",
       "      <td>0.975819</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.157041</td>\n",
       "      <td>-0.464000</td>\n",
       "      <td>0.014708</td>\n",
       "      <td>-0.152000</td>\n",
       "      <td>0.919844</td>\n",
       "      <td>0.637677</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.285003</td>\n",
       "      <td>0.998571</td>\n",
       "      <td>-0.808000</td>\n",
       "      <td>0.447064</td>\n",
       "      <td>-0.218000</td>\n",
       "      <td>-0.540000</td>\n",
       "      <td>-0.287000</td>\n",
       "      <td>-0.322000</td>\n",
       "      <td>0.729921</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.417018</td>\n",
       "      <td>0.235072</td>\n",
       "      <td>-0.644000</td>\n",
       "      <td>-0.055300</td>\n",
       "      <td>-0.090300</td>\n",
       "      <td>0.761526</td>\n",
       "      <td>-0.264000</td>\n",
       "      <td>0.198099</td>\n",
       "      <td>-0.819000</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>0.998670</td>\n",
       "      <td>-0.757000</td>\n",
       "      <td>0.943390</td>\n",
       "      <td>0.409910</td>\n",
       "      <td>-0.026900</td>\n",
       "      <td>-0.860000</td>\n",
       "      <td>0.985944</td>\n",
       "      <td>0.583595</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-0.330000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.284013</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>-0.852000</td>\n",
       "      <td>-0.306000</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.359000</td>\n",
       "      <td>0.977130</td>\n",
       "      <td>-0.011600</td>\n",
       "      <td>0.998531</td>\n",
       "      <td>0.220611</td>\n",
       "      <td>-0.982000</td>\n",
       "      <td>-0.718000</td>\n",
       "      <td>0.208881</td>\n",
       "      <td>-0.101000</td>\n",
       "      <td>-0.376000</td>\n",
       "      <td>0.442581</td>\n",
       "      <td>-0.543000</td>\n",
       "      <td>0.973259</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>0.335872</td>\n",
       "      <td>-0.987000</td>\n",
       "      <td>0.481305</td>\n",
       "      <td>-0.066200</td>\n",
       "      <td>0.134225</td>\n",
       "      <td>-0.052300</td>\n",
       "      <td>-0.974000</td>\n",
       "      <td>0.802809</td>\n",
       "      <td>0.429561</td>\n",
       "      <td>-0.984000</td>\n",
       "      <td>-0.913000</td>\n",
       "      <td>-0.885000</td>\n",
       "      <td>0.407996</td>\n",
       "      <td>-0.238000</td>\n",
       "      <td>-0.144000</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>-0.190000</td>\n",
       "      <td>0.347432</td>\n",
       "      <td>0.989491</td>\n",
       "      <td>0.329666</td>\n",
       "      <td>0.999129</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>-0.105000</td>\n",
       "      <td>0.229443</td>\n",
       "      <td>0.992661</td>\n",
       "      <td>0.445500</td>\n",
       "      <td>0.655903</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.261203</td>\n",
       "      <td>0.910099</td>\n",
       "      <td>0.997985</td>\n",
       "      <td>0.846281</td>\n",
       "      <td>0.999691</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.061677</td>\n",
       "      <td>0.244346</td>\n",
       "      <td>-0.382000</td>\n",
       "      <td>-0.226000</td>\n",
       "      <td>-0.104000</td>\n",
       "      <td>0.315518</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.990643</td>\n",
       "      <td>0.495989</td>\n",
       "      <td>0.066373</td>\n",
       "      <td>0.590753</td>\n",
       "      <td>0.714533</td>\n",
       "      <td>0.468489</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.068000</td>\n",
       "      <td>-0.335000</td>\n",
       "      <td>0.081449</td>\n",
       "      <td>-0.387000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>0.986775</td>\n",
       "      <td>-0.214000</td>\n",
       "      <td>-0.513000</td>\n",
       "      <td>-0.139000</td>\n",
       "      <td>0.261339</td>\n",
       "      <td>-0.913000</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>-0.392000</td>\n",
       "      <td>-0.016300</td>\n",
       "      <td>-0.476000</td>\n",
       "      <td>0.021458</td>\n",
       "      <td>0.336718</td>\n",
       "      <td>-0.354000</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.091550</td>\n",
       "      <td>0.102501</td>\n",
       "      <td>-0.512000</td>\n",
       "      <td>-0.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Group_01_101</td>\n",
       "      <td>Group_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995743</td>\n",
       "      <td>0.968646</td>\n",
       "      <td>0.201253</td>\n",
       "      <td>-0.130489</td>\n",
       "      <td>0.660496</td>\n",
       "      <td>0.997078</td>\n",
       "      <td>0.983218</td>\n",
       "      <td>-0.944374</td>\n",
       "      <td>-0.262219</td>\n",
       "      <td>-0.999788</td>\n",
       "      <td>0.322809</td>\n",
       "      <td>-0.978609</td>\n",
       "      <td>-0.682756</td>\n",
       "      <td>-0.994339</td>\n",
       "      <td>0.820431</td>\n",
       "      <td>-0.037593</td>\n",
       "      <td>-0.123590</td>\n",
       "      <td>0.404065</td>\n",
       "      <td>0.078757</td>\n",
       "      <td>0.146876</td>\n",
       "      <td>-0.185831</td>\n",
       "      <td>0.095608</td>\n",
       "      <td>0.775757</td>\n",
       "      <td>0.955985</td>\n",
       "      <td>0.992306</td>\n",
       "      <td>0.979023</td>\n",
       "      <td>-0.123651</td>\n",
       "      <td>-0.009293</td>\n",
       "      <td>0.159130</td>\n",
       "      <td>-0.399745</td>\n",
       "      <td>0.984169</td>\n",
       "      <td>-0.245010</td>\n",
       "      <td>0.499372</td>\n",
       "      <td>0.088424</td>\n",
       "      <td>-0.947444</td>\n",
       "      <td>0.030557</td>\n",
       "      <td>-0.382831</td>\n",
       "      <td>-0.212737</td>\n",
       "      <td>0.885396</td>\n",
       "      <td>-0.101708</td>\n",
       "      <td>0.113619</td>\n",
       "      <td>0.197190</td>\n",
       "      <td>-0.097353</td>\n",
       "      <td>-0.982655</td>\n",
       "      <td>-0.161342</td>\n",
       "      <td>-0.513724</td>\n",
       "      <td>-0.911314</td>\n",
       "      <td>0.244650</td>\n",
       "      <td>0.378630</td>\n",
       "      <td>-0.484025</td>\n",
       "      <td>0.997927</td>\n",
       "      <td>-0.031844</td>\n",
       "      <td>0.997691</td>\n",
       "      <td>-0.243873</td>\n",
       "      <td>0.463397</td>\n",
       "      <td>0.172776</td>\n",
       "      <td>-0.029568</td>\n",
       "      <td>0.233584</td>\n",
       "      <td>-0.999705</td>\n",
       "      <td>-0.999385</td>\n",
       "      <td>0.357327</td>\n",
       "      <td>0.059951</td>\n",
       "      <td>0.998593</td>\n",
       "      <td>0.072189</td>\n",
       "      <td>-0.170197</td>\n",
       "      <td>-0.644919</td>\n",
       "      <td>0.987329</td>\n",
       "      <td>0.302567</td>\n",
       "      <td>-0.302503</td>\n",
       "      <td>0.412640</td>\n",
       "      <td>0.400185</td>\n",
       "      <td>0.999630</td>\n",
       "      <td>-0.552906</td>\n",
       "      <td>-0.238550</td>\n",
       "      <td>-0.814861</td>\n",
       "      <td>-0.376764</td>\n",
       "      <td>0.160603</td>\n",
       "      <td>0.990453</td>\n",
       "      <td>-0.178612</td>\n",
       "      <td>-0.335091</td>\n",
       "      <td>-0.990137</td>\n",
       "      <td>0.209123</td>\n",
       "      <td>0.896167</td>\n",
       "      <td>0.512388</td>\n",
       "      <td>0.817216</td>\n",
       "      <td>-0.999915</td>\n",
       "      <td>0.148945</td>\n",
       "      <td>0.487519</td>\n",
       "      <td>-0.185967</td>\n",
       "      <td>-0.166836</td>\n",
       "      <td>-0.953491</td>\n",
       "      <td>0.100383</td>\n",
       "      <td>0.348470</td>\n",
       "      <td>-0.782110</td>\n",
       "      <td>0.309654</td>\n",
       "      <td>0.640323</td>\n",
       "      <td>0.991681</td>\n",
       "      <td>0.159908</td>\n",
       "      <td>-0.986159</td>\n",
       "      <td>-0.401578</td>\n",
       "      <td>-0.784815</td>\n",
       "      <td>-0.660942</td>\n",
       "      <td>-0.987986</td>\n",
       "      <td>0.101264</td>\n",
       "      <td>-0.210505</td>\n",
       "      <td>0.019022</td>\n",
       "      <td>0.988212</td>\n",
       "      <td>0.413141</td>\n",
       "      <td>-0.241699</td>\n",
       "      <td>-0.963856</td>\n",
       "      <td>0.214280</td>\n",
       "      <td>0.302050</td>\n",
       "      <td>0.999754</td>\n",
       "      <td>-0.936307</td>\n",
       "      <td>-0.230669</td>\n",
       "      <td>0.305292</td>\n",
       "      <td>-0.598932</td>\n",
       "      <td>-0.362496</td>\n",
       "      <td>0.121675</td>\n",
       "      <td>0.944076</td>\n",
       "      <td>-0.967581</td>\n",
       "      <td>-0.288437</td>\n",
       "      <td>-0.997406</td>\n",
       "      <td>-0.953551</td>\n",
       "      <td>-0.148179</td>\n",
       "      <td>0.174083</td>\n",
       "      <td>-0.981706</td>\n",
       "      <td>-0.225681</td>\n",
       "      <td>-0.074562</td>\n",
       "      <td>-0.222324</td>\n",
       "      <td>0.898637</td>\n",
       "      <td>0.807646</td>\n",
       "      <td>0.998805</td>\n",
       "      <td>0.144397</td>\n",
       "      <td>-0.122847</td>\n",
       "      <td>-0.953172</td>\n",
       "      <td>0.999706</td>\n",
       "      <td>-0.975552</td>\n",
       "      <td>-0.996547</td>\n",
       "      <td>0.149772</td>\n",
       "      <td>0.999736</td>\n",
       "      <td>-0.040255</td>\n",
       "      <td>-0.322061</td>\n",
       "      <td>0.987663</td>\n",
       "      <td>0.190079</td>\n",
       "      <td>0.998808</td>\n",
       "      <td>-0.917401</td>\n",
       "      <td>0.975562</td>\n",
       "      <td>-0.907218</td>\n",
       "      <td>-0.058796</td>\n",
       "      <td>-0.442708</td>\n",
       "      <td>0.078037</td>\n",
       "      <td>0.864414</td>\n",
       "      <td>0.279730</td>\n",
       "      <td>-0.122252</td>\n",
       "      <td>-0.223862</td>\n",
       "      <td>0.813816</td>\n",
       "      <td>-0.738355</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>-0.402888</td>\n",
       "      <td>-0.033938</td>\n",
       "      <td>0.055169</td>\n",
       "      <td>-0.422018</td>\n",
       "      <td>0.110428</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>-0.124689</td>\n",
       "      <td>-0.148776</td>\n",
       "      <td>0.133636</td>\n",
       "      <td>0.999474</td>\n",
       "      <td>0.854963</td>\n",
       "      <td>0.100534</td>\n",
       "      <td>-0.989348</td>\n",
       "      <td>0.332419</td>\n",
       "      <td>0.568041</td>\n",
       "      <td>-0.245449</td>\n",
       "      <td>0.128193</td>\n",
       "      <td>-0.907408</td>\n",
       "      <td>0.210808</td>\n",
       "      <td>0.999206</td>\n",
       "      <td>0.440467</td>\n",
       "      <td>0.982606</td>\n",
       "      <td>-0.004847</td>\n",
       "      <td>0.951537</td>\n",
       "      <td>0.099974</td>\n",
       "      <td>-0.178825</td>\n",
       "      <td>-0.997590</td>\n",
       "      <td>-0.998408</td>\n",
       "      <td>-0.860466</td>\n",
       "      <td>-0.187488</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.944710</td>\n",
       "      <td>-0.995817</td>\n",
       "      <td>-0.989500</td>\n",
       "      <td>0.042993</td>\n",
       "      <td>0.979708</td>\n",
       "      <td>-0.078369</td>\n",
       "      <td>-0.991872</td>\n",
       "      <td>-0.891599</td>\n",
       "      <td>0.995261</td>\n",
       "      <td>-0.161372</td>\n",
       "      <td>0.094084</td>\n",
       "      <td>-0.317683</td>\n",
       "      <td>-0.807632</td>\n",
       "      <td>-0.143573</td>\n",
       "      <td>-0.309227</td>\n",
       "      <td>0.975697</td>\n",
       "      <td>-0.328250</td>\n",
       "      <td>0.973273</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>-0.057955</td>\n",
       "      <td>0.350714</td>\n",
       "      <td>0.367109</td>\n",
       "      <td>-0.091826</td>\n",
       "      <td>-0.090268</td>\n",
       "      <td>0.948328</td>\n",
       "      <td>-0.994614</td>\n",
       "      <td>-0.822577</td>\n",
       "      <td>0.986773</td>\n",
       "      <td>-0.030271</td>\n",
       "      <td>0.032968</td>\n",
       "      <td>-0.999687</td>\n",
       "      <td>0.042775</td>\n",
       "      <td>0.626756</td>\n",
       "      <td>0.033820</td>\n",
       "      <td>-0.070183</td>\n",
       "      <td>-0.916457</td>\n",
       "      <td>-0.986161</td>\n",
       "      <td>-0.038200</td>\n",
       "      <td>-0.995507</td>\n",
       "      <td>0.981484</td>\n",
       "      <td>-0.198064</td>\n",
       "      <td>-0.260638</td>\n",
       "      <td>0.046081</td>\n",
       "      <td>-0.228725</td>\n",
       "      <td>0.995506</td>\n",
       "      <td>0.013264</td>\n",
       "      <td>-0.821947</td>\n",
       "      <td>-0.329873</td>\n",
       "      <td>0.191869</td>\n",
       "      <td>-0.354865</td>\n",
       "      <td>-0.025689</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>-0.410095</td>\n",
       "      <td>0.997655</td>\n",
       "      <td>0.019422</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.456091</td>\n",
       "      <td>0.983681</td>\n",
       "      <td>-0.205313</td>\n",
       "      <td>-0.453754</td>\n",
       "      <td>-0.037769</td>\n",
       "      <td>-0.519392</td>\n",
       "      <td>0.088010</td>\n",
       "      <td>0.999311</td>\n",
       "      <td>-0.117204</td>\n",
       "      <td>-0.335919</td>\n",
       "      <td>-0.963763</td>\n",
       "      <td>0.207954</td>\n",
       "      <td>0.746172</td>\n",
       "      <td>-0.062526</td>\n",
       "      <td>-0.998073</td>\n",
       "      <td>-0.397131</td>\n",
       "      <td>-0.686092</td>\n",
       "      <td>-0.036289</td>\n",
       "      <td>0.992899</td>\n",
       "      <td>0.998281</td>\n",
       "      <td>-0.933785</td>\n",
       "      <td>0.275176</td>\n",
       "      <td>-0.143948</td>\n",
       "      <td>0.996659</td>\n",
       "      <td>-0.112410</td>\n",
       "      <td>-0.997598</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>-0.081000</td>\n",
       "      <td>-0.975577</td>\n",
       "      <td>0.981222</td>\n",
       "      <td>0.213124</td>\n",
       "      <td>-0.952811</td>\n",
       "      <td>-0.056019</td>\n",
       "      <td>-0.341751</td>\n",
       "      <td>-0.999095</td>\n",
       "      <td>0.708281</td>\n",
       "      <td>0.998617</td>\n",
       "      <td>-0.619579</td>\n",
       "      <td>-0.090447</td>\n",
       "      <td>0.082961</td>\n",
       "      <td>-0.080683</td>\n",
       "      <td>-0.997709</td>\n",
       "      <td>-0.997275</td>\n",
       "      <td>0.464325</td>\n",
       "      <td>0.164791</td>\n",
       "      <td>-0.332271</td>\n",
       "      <td>0.983002</td>\n",
       "      <td>0.992576</td>\n",
       "      <td>-0.954026</td>\n",
       "      <td>0.297282</td>\n",
       "      <td>0.902562</td>\n",
       "      <td>-0.319605</td>\n",
       "      <td>0.997950</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>-0.985743</td>\n",
       "      <td>-0.340662</td>\n",
       "      <td>0.994939</td>\n",
       "      <td>0.096044</td>\n",
       "      <td>-0.049826</td>\n",
       "      <td>0.242561</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.214967</td>\n",
       "      <td>0.329513</td>\n",
       "      <td>0.116921</td>\n",
       "      <td>-0.803401</td>\n",
       "      <td>-0.281027</td>\n",
       "      <td>0.465449</td>\n",
       "      <td>0.943839</td>\n",
       "      <td>0.318458</td>\n",
       "      <td>0.198965</td>\n",
       "      <td>-0.060849</td>\n",
       "      <td>0.087212</td>\n",
       "      <td>0.983434</td>\n",
       "      <td>0.040102</td>\n",
       "      <td>-0.890958</td>\n",
       "      <td>-0.123496</td>\n",
       "      <td>-0.445025</td>\n",
       "      <td>0.105167</td>\n",
       "      <td>0.138161</td>\n",
       "      <td>-0.943914</td>\n",
       "      <td>-0.414748</td>\n",
       "      <td>-0.629748</td>\n",
       "      <td>-0.040945</td>\n",
       "      <td>0.946682</td>\n",
       "      <td>-0.072607</td>\n",
       "      <td>-0.163050</td>\n",
       "      <td>0.892828</td>\n",
       "      <td>-0.158600</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.262165</td>\n",
       "      <td>-0.987630</td>\n",
       "      <td>-0.295629</td>\n",
       "      <td>-0.159124</td>\n",
       "      <td>0.998965</td>\n",
       "      <td>0.012889</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>0.995901</td>\n",
       "      <td>-0.957314</td>\n",
       "      <td>0.998434</td>\n",
       "      <td>0.628486</td>\n",
       "      <td>0.959560</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>0.871923</td>\n",
       "      <td>-0.072227</td>\n",
       "      <td>0.263661</td>\n",
       "      <td>0.123499</td>\n",
       "      <td>0.054411</td>\n",
       "      <td>-0.228717</td>\n",
       "      <td>0.070382</td>\n",
       "      <td>-0.726856</td>\n",
       "      <td>-0.102950</td>\n",
       "      <td>-0.112264</td>\n",
       "      <td>0.235532</td>\n",
       "      <td>-0.998186</td>\n",
       "      <td>0.435133</td>\n",
       "      <td>-0.535728</td>\n",
       "      <td>0.399740</td>\n",
       "      <td>0.210172</td>\n",
       "      <td>-0.989708</td>\n",
       "      <td>0.401118</td>\n",
       "      <td>0.312936</td>\n",
       "      <td>-0.110271</td>\n",
       "      <td>-0.118043</td>\n",
       "      <td>0.260560</td>\n",
       "      <td>0.960973</td>\n",
       "      <td>-0.108495</td>\n",
       "      <td>0.044689</td>\n",
       "      <td>0.747580</td>\n",
       "      <td>-0.932140</td>\n",
       "      <td>0.035831</td>\n",
       "      <td>0.087814</td>\n",
       "      <td>0.062861</td>\n",
       "      <td>-0.236932</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>0.406365</td>\n",
       "      <td>-0.947651</td>\n",
       "      <td>0.104839</td>\n",
       "      <td>0.973445</td>\n",
       "      <td>-0.532695</td>\n",
       "      <td>0.207996</td>\n",
       "      <td>-0.305103</td>\n",
       "      <td>0.594387</td>\n",
       "      <td>0.107382</td>\n",
       "      <td>-0.084808</td>\n",
       "      <td>0.607165</td>\n",
       "      <td>-0.999882</td>\n",
       "      <td>-0.571597</td>\n",
       "      <td>-0.316334</td>\n",
       "      <td>0.124154</td>\n",
       "      <td>-0.420166</td>\n",
       "      <td>-0.030156</td>\n",
       "      <td>0.999739</td>\n",
       "      <td>-0.403420</td>\n",
       "      <td>-0.070601</td>\n",
       "      <td>-0.953111</td>\n",
       "      <td>-0.895309</td>\n",
       "      <td>-0.185414</td>\n",
       "      <td>0.996444</td>\n",
       "      <td>0.732981</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.167593</td>\n",
       "      <td>-0.028204</td>\n",
       "      <td>-0.977918</td>\n",
       "      <td>0.994693</td>\n",
       "      <td>0.382048</td>\n",
       "      <td>-0.999439</td>\n",
       "      <td>0.219263</td>\n",
       "      <td>-0.983043</td>\n",
       "      <td>0.319936</td>\n",
       "      <td>-0.222750</td>\n",
       "      <td>-0.927772</td>\n",
       "      <td>-0.392106</td>\n",
       "      <td>-0.999604</td>\n",
       "      <td>0.059215</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>-0.228500</td>\n",
       "      <td>0.303830</td>\n",
       "      <td>0.147344</td>\n",
       "      <td>-0.756883</td>\n",
       "      <td>0.337678</td>\n",
       "      <td>-0.016433</td>\n",
       "      <td>-0.161953</td>\n",
       "      <td>0.101423</td>\n",
       "      <td>0.395114</td>\n",
       "      <td>0.468485</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>-0.999605</td>\n",
       "      <td>-0.747062</td>\n",
       "      <td>0.141645</td>\n",
       "      <td>-0.825765</td>\n",
       "      <td>-0.023820</td>\n",
       "      <td>-0.050487</td>\n",
       "      <td>0.379588</td>\n",
       "      <td>0.035843</td>\n",
       "      <td>-0.997796</td>\n",
       "      <td>-0.985537</td>\n",
       "      <td>-0.196123</td>\n",
       "      <td>-0.999888</td>\n",
       "      <td>-0.856673</td>\n",
       "      <td>-0.813508</td>\n",
       "      <td>-0.225260</td>\n",
       "      <td>-0.225347</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>-0.350305</td>\n",
       "      <td>0.341129</td>\n",
       "      <td>-0.088238</td>\n",
       "      <td>0.942831</td>\n",
       "      <td>0.201809</td>\n",
       "      <td>0.996914</td>\n",
       "      <td>0.021832</td>\n",
       "      <td>0.422419</td>\n",
       "      <td>-0.447346</td>\n",
       "      <td>0.948084</td>\n",
       "      <td>0.855229</td>\n",
       "      <td>0.198594</td>\n",
       "      <td>-0.999549</td>\n",
       "      <td>0.148268</td>\n",
       "      <td>0.766933</td>\n",
       "      <td>0.998313</td>\n",
       "      <td>0.708707</td>\n",
       "      <td>0.995239</td>\n",
       "      <td>-0.939160</td>\n",
       "      <td>0.065530</td>\n",
       "      <td>-0.067404</td>\n",
       "      <td>-0.586424</td>\n",
       "      <td>0.538685</td>\n",
       "      <td>-0.077752</td>\n",
       "      <td>0.375222</td>\n",
       "      <td>-0.999742</td>\n",
       "      <td>-0.997861</td>\n",
       "      <td>0.058669</td>\n",
       "      <td>-0.994726</td>\n",
       "      <td>0.957656</td>\n",
       "      <td>0.083517</td>\n",
       "      <td>-0.025152</td>\n",
       "      <td>0.040277</td>\n",
       "      <td>0.299233</td>\n",
       "      <td>-0.347764</td>\n",
       "      <td>-0.928106</td>\n",
       "      <td>-0.977835</td>\n",
       "      <td>0.190333</td>\n",
       "      <td>-0.481819</td>\n",
       "      <td>-0.042741</td>\n",
       "      <td>0.139439</td>\n",
       "      <td>-0.999970</td>\n",
       "      <td>-0.134502</td>\n",
       "      <td>0.650564</td>\n",
       "      <td>-0.003659</td>\n",
       "      <td>0.221336</td>\n",
       "      <td>-0.129485</td>\n",
       "      <td>-0.165533</td>\n",
       "      <td>-0.991738</td>\n",
       "      <td>0.991800</td>\n",
       "      <td>-0.803406</td>\n",
       "      <td>-0.247159</td>\n",
       "      <td>-0.146241</td>\n",
       "      <td>0.149644</td>\n",
       "      <td>-0.149588</td>\n",
       "      <td>-0.248514</td>\n",
       "      <td>0.969256</td>\n",
       "      <td>-0.892916</td>\n",
       "      <td>-0.089568</td>\n",
       "      <td>0.287563</td>\n",
       "      <td>-0.195797</td>\n",
       "      <td>-0.422602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>Group_10_95</td>\n",
       "      <td>Group_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998164</td>\n",
       "      <td>0.837999</td>\n",
       "      <td>0.328195</td>\n",
       "      <td>-0.141000</td>\n",
       "      <td>-0.036300</td>\n",
       "      <td>0.936739</td>\n",
       "      <td>0.952660</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>-0.424000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.094815</td>\n",
       "      <td>-0.983000</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>-0.988000</td>\n",
       "      <td>0.779980</td>\n",
       "      <td>0.072198</td>\n",
       "      <td>-0.226000</td>\n",
       "      <td>0.323816</td>\n",
       "      <td>-0.353000</td>\n",
       "      <td>0.125301</td>\n",
       "      <td>-0.311000</td>\n",
       "      <td>-0.236000</td>\n",
       "      <td>-0.192000</td>\n",
       "      <td>0.998721</td>\n",
       "      <td>0.996508</td>\n",
       "      <td>0.994635</td>\n",
       "      <td>-0.349000</td>\n",
       "      <td>-0.123000</td>\n",
       "      <td>0.343994</td>\n",
       "      <td>-0.945000</td>\n",
       "      <td>0.975559</td>\n",
       "      <td>0.027298</td>\n",
       "      <td>0.446313</td>\n",
       "      <td>0.317386</td>\n",
       "      <td>-0.901000</td>\n",
       "      <td>0.086433</td>\n",
       "      <td>-0.173000</td>\n",
       "      <td>-0.152000</td>\n",
       "      <td>0.901178</td>\n",
       "      <td>-0.109000</td>\n",
       "      <td>0.178331</td>\n",
       "      <td>-0.575000</td>\n",
       "      <td>-0.004610</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>-0.119000</td>\n",
       "      <td>-0.441000</td>\n",
       "      <td>-0.881000</td>\n",
       "      <td>0.418277</td>\n",
       "      <td>0.841193</td>\n",
       "      <td>-0.648000</td>\n",
       "      <td>0.995623</td>\n",
       "      <td>-0.118000</td>\n",
       "      <td>0.997187</td>\n",
       "      <td>-0.448000</td>\n",
       "      <td>-0.144000</td>\n",
       "      <td>0.444532</td>\n",
       "      <td>0.057495</td>\n",
       "      <td>-0.152000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.306473</td>\n",
       "      <td>0.299349</td>\n",
       "      <td>0.992467</td>\n",
       "      <td>0.105458</td>\n",
       "      <td>0.015742</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.996081</td>\n",
       "      <td>0.440762</td>\n",
       "      <td>-0.315000</td>\n",
       "      <td>0.949951</td>\n",
       "      <td>0.998096</td>\n",
       "      <td>0.999872</td>\n",
       "      <td>-0.597000</td>\n",
       "      <td>-0.410000</td>\n",
       "      <td>-0.842000</td>\n",
       "      <td>-0.021400</td>\n",
       "      <td>0.272003</td>\n",
       "      <td>0.998283</td>\n",
       "      <td>-0.101000</td>\n",
       "      <td>-0.389000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.029767</td>\n",
       "      <td>0.950294</td>\n",
       "      <td>0.106504</td>\n",
       "      <td>0.844047</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.276000</td>\n",
       "      <td>0.307516</td>\n",
       "      <td>0.186420</td>\n",
       "      <td>0.156688</td>\n",
       "      <td>-0.974000</td>\n",
       "      <td>0.125469</td>\n",
       "      <td>0.406732</td>\n",
       "      <td>-0.983000</td>\n",
       "      <td>-0.746000</td>\n",
       "      <td>0.735499</td>\n",
       "      <td>0.988801</td>\n",
       "      <td>0.039924</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.987000</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.083100</td>\n",
       "      <td>-0.176000</td>\n",
       "      <td>0.102457</td>\n",
       "      <td>0.985046</td>\n",
       "      <td>0.196582</td>\n",
       "      <td>-0.154000</td>\n",
       "      <td>-0.953000</td>\n",
       "      <td>0.072297</td>\n",
       "      <td>-0.288000</td>\n",
       "      <td>0.996719</td>\n",
       "      <td>-0.969000</td>\n",
       "      <td>-0.024700</td>\n",
       "      <td>0.497623</td>\n",
       "      <td>-0.411000</td>\n",
       "      <td>0.518889</td>\n",
       "      <td>-0.070500</td>\n",
       "      <td>0.995673</td>\n",
       "      <td>-0.988000</td>\n",
       "      <td>0.057844</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-0.914000</td>\n",
       "      <td>-0.256000</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>-0.697000</td>\n",
       "      <td>0.052579</td>\n",
       "      <td>0.039210</td>\n",
       "      <td>-0.423000</td>\n",
       "      <td>0.985511</td>\n",
       "      <td>0.985675</td>\n",
       "      <td>0.999192</td>\n",
       "      <td>0.275309</td>\n",
       "      <td>0.234974</td>\n",
       "      <td>-0.140000</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>-0.983000</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.675909</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.216029</td>\n",
       "      <td>-0.487000</td>\n",
       "      <td>0.992582</td>\n",
       "      <td>0.343987</td>\n",
       "      <td>0.999323</td>\n",
       "      <td>-0.692000</td>\n",
       "      <td>0.998892</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.240000</td>\n",
       "      <td>-0.467000</td>\n",
       "      <td>0.125562</td>\n",
       "      <td>0.995966</td>\n",
       "      <td>0.178769</td>\n",
       "      <td>0.038353</td>\n",
       "      <td>-0.556000</td>\n",
       "      <td>0.992147</td>\n",
       "      <td>0.824020</td>\n",
       "      <td>0.190623</td>\n",
       "      <td>0.353522</td>\n",
       "      <td>-0.435000</td>\n",
       "      <td>0.053441</td>\n",
       "      <td>-0.306000</td>\n",
       "      <td>-0.025700</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>-0.056800</td>\n",
       "      <td>-0.320000</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.998171</td>\n",
       "      <td>0.984348</td>\n",
       "      <td>0.122657</td>\n",
       "      <td>-0.958000</td>\n",
       "      <td>-0.055100</td>\n",
       "      <td>0.975784</td>\n",
       "      <td>0.660940</td>\n",
       "      <td>0.240969</td>\n",
       "      <td>0.763206</td>\n",
       "      <td>-0.179000</td>\n",
       "      <td>0.999345</td>\n",
       "      <td>0.373965</td>\n",
       "      <td>0.858478</td>\n",
       "      <td>-0.353000</td>\n",
       "      <td>0.993927</td>\n",
       "      <td>0.691931</td>\n",
       "      <td>0.620940</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.861000</td>\n",
       "      <td>0.296320</td>\n",
       "      <td>0.994523</td>\n",
       "      <td>0.996471</td>\n",
       "      <td>-0.925000</td>\n",
       "      <td>-0.969000</td>\n",
       "      <td>-0.009330</td>\n",
       "      <td>0.997827</td>\n",
       "      <td>-0.154000</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.895000</td>\n",
       "      <td>0.960631</td>\n",
       "      <td>-0.012800</td>\n",
       "      <td>0.397387</td>\n",
       "      <td>-0.478000</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-0.170000</td>\n",
       "      <td>-0.211000</td>\n",
       "      <td>0.998888</td>\n",
       "      <td>-0.127000</td>\n",
       "      <td>0.987750</td>\n",
       "      <td>0.993631</td>\n",
       "      <td>-0.529000</td>\n",
       "      <td>0.854484</td>\n",
       "      <td>0.968107</td>\n",
       "      <td>-0.046500</td>\n",
       "      <td>0.111968</td>\n",
       "      <td>0.968099</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.987000</td>\n",
       "      <td>0.996115</td>\n",
       "      <td>-0.575000</td>\n",
       "      <td>-0.295000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.331000</td>\n",
       "      <td>-0.729000</td>\n",
       "      <td>-0.026600</td>\n",
       "      <td>-0.723000</td>\n",
       "      <td>-0.785000</td>\n",
       "      <td>-0.958000</td>\n",
       "      <td>0.256362</td>\n",
       "      <td>-0.956000</td>\n",
       "      <td>0.956694</td>\n",
       "      <td>-0.270000</td>\n",
       "      <td>-0.429000</td>\n",
       "      <td>-0.094500</td>\n",
       "      <td>-0.017300</td>\n",
       "      <td>0.992886</td>\n",
       "      <td>-0.299000</td>\n",
       "      <td>-0.963000</td>\n",
       "      <td>-0.513000</td>\n",
       "      <td>0.370053</td>\n",
       "      <td>-0.336000</td>\n",
       "      <td>0.660073</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.111309</td>\n",
       "      <td>0.999469</td>\n",
       "      <td>-0.930000</td>\n",
       "      <td>0.436403</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>-0.005440</td>\n",
       "      <td>0.995996</td>\n",
       "      <td>-0.139000</td>\n",
       "      <td>-0.183000</td>\n",
       "      <td>0.200335</td>\n",
       "      <td>-0.273000</td>\n",
       "      <td>0.310804</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.038062</td>\n",
       "      <td>-0.091100</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>0.324459</td>\n",
       "      <td>0.963984</td>\n",
       "      <td>-0.438000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.489000</td>\n",
       "      <td>-0.872000</td>\n",
       "      <td>0.268496</td>\n",
       "      <td>0.989319</td>\n",
       "      <td>0.999136</td>\n",
       "      <td>-0.669000</td>\n",
       "      <td>0.028217</td>\n",
       "      <td>0.400153</td>\n",
       "      <td>0.999496</td>\n",
       "      <td>-0.090500</td>\n",
       "      <td>-0.990000</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>-0.580000</td>\n",
       "      <td>-0.865000</td>\n",
       "      <td>0.962773</td>\n",
       "      <td>0.231142</td>\n",
       "      <td>-0.911000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.641000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.228163</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.613078</td>\n",
       "      <td>-0.308000</td>\n",
       "      <td>0.258775</td>\n",
       "      <td>-0.019500</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.966000</td>\n",
       "      <td>-0.109000</td>\n",
       "      <td>0.278527</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.994842</td>\n",
       "      <td>0.998572</td>\n",
       "      <td>-0.982000</td>\n",
       "      <td>-0.137000</td>\n",
       "      <td>0.663677</td>\n",
       "      <td>-0.324000</td>\n",
       "      <td>0.999545</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-0.036000</td>\n",
       "      <td>0.999132</td>\n",
       "      <td>-0.167000</td>\n",
       "      <td>-0.049600</td>\n",
       "      <td>0.077018</td>\n",
       "      <td>0.984981</td>\n",
       "      <td>-0.469000</td>\n",
       "      <td>0.315466</td>\n",
       "      <td>0.251467</td>\n",
       "      <td>-0.955000</td>\n",
       "      <td>-0.082800</td>\n",
       "      <td>0.582189</td>\n",
       "      <td>0.982277</td>\n",
       "      <td>0.391696</td>\n",
       "      <td>0.044017</td>\n",
       "      <td>-0.070200</td>\n",
       "      <td>0.642197</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>-0.231000</td>\n",
       "      <td>-0.377000</td>\n",
       "      <td>-0.238000</td>\n",
       "      <td>-0.874000</td>\n",
       "      <td>-0.046600</td>\n",
       "      <td>-0.158000</td>\n",
       "      <td>-0.815000</td>\n",
       "      <td>0.220417</td>\n",
       "      <td>-0.598000</td>\n",
       "      <td>-0.083200</td>\n",
       "      <td>0.974017</td>\n",
       "      <td>-0.156000</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>0.971285</td>\n",
       "      <td>0.103066</td>\n",
       "      <td>-0.221000</td>\n",
       "      <td>-0.046900</td>\n",
       "      <td>-0.769000</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.023887</td>\n",
       "      <td>0.996862</td>\n",
       "      <td>0.141987</td>\n",
       "      <td>0.215997</td>\n",
       "      <td>0.992495</td>\n",
       "      <td>-0.921000</td>\n",
       "      <td>0.943213</td>\n",
       "      <td>0.044181</td>\n",
       "      <td>0.984346</td>\n",
       "      <td>-0.102000</td>\n",
       "      <td>0.973244</td>\n",
       "      <td>-0.102000</td>\n",
       "      <td>0.072232</td>\n",
       "      <td>0.826214</td>\n",
       "      <td>0.016759</td>\n",
       "      <td>-0.773000</td>\n",
       "      <td>-0.063500</td>\n",
       "      <td>-0.974000</td>\n",
       "      <td>-0.130000</td>\n",
       "      <td>-0.068200</td>\n",
       "      <td>-0.192000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.936844</td>\n",
       "      <td>-0.616000</td>\n",
       "      <td>0.038171</td>\n",
       "      <td>0.473945</td>\n",
       "      <td>-0.989000</td>\n",
       "      <td>0.881202</td>\n",
       "      <td>-0.096100</td>\n",
       "      <td>0.037284</td>\n",
       "      <td>0.421270</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>0.987377</td>\n",
       "      <td>0.204614</td>\n",
       "      <td>-0.046300</td>\n",
       "      <td>0.984151</td>\n",
       "      <td>-0.982000</td>\n",
       "      <td>-0.340000</td>\n",
       "      <td>-0.114000</td>\n",
       "      <td>-0.187000</td>\n",
       "      <td>-0.391000</td>\n",
       "      <td>0.923290</td>\n",
       "      <td>0.151400</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.216253</td>\n",
       "      <td>0.995003</td>\n",
       "      <td>-0.425000</td>\n",
       "      <td>0.528564</td>\n",
       "      <td>-0.546000</td>\n",
       "      <td>-0.272000</td>\n",
       "      <td>0.302600</td>\n",
       "      <td>-0.105000</td>\n",
       "      <td>0.951849</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.111952</td>\n",
       "      <td>-0.071100</td>\n",
       "      <td>0.142967</td>\n",
       "      <td>-0.389000</td>\n",
       "      <td>-0.631000</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>-0.221000</td>\n",
       "      <td>-0.076200</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.229000</td>\n",
       "      <td>0.999497</td>\n",
       "      <td>-0.097400</td>\n",
       "      <td>0.983206</td>\n",
       "      <td>-0.019100</td>\n",
       "      <td>0.041086</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>0.992941</td>\n",
       "      <td>0.873848</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.098100</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.149762</td>\n",
       "      <td>0.251897</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>-0.376000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.124000</td>\n",
       "      <td>0.968284</td>\n",
       "      <td>-0.314000</td>\n",
       "      <td>0.979510</td>\n",
       "      <td>0.266484</td>\n",
       "      <td>-0.957000</td>\n",
       "      <td>-0.153000</td>\n",
       "      <td>0.099552</td>\n",
       "      <td>-0.104000</td>\n",
       "      <td>0.310188</td>\n",
       "      <td>0.172602</td>\n",
       "      <td>0.383801</td>\n",
       "      <td>0.999180</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.482000</td>\n",
       "      <td>0.327071</td>\n",
       "      <td>-0.975000</td>\n",
       "      <td>0.509777</td>\n",
       "      <td>0.136009</td>\n",
       "      <td>0.288155</td>\n",
       "      <td>-0.043300</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.930000</td>\n",
       "      <td>0.137226</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>-0.794000</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>-0.122000</td>\n",
       "      <td>-0.148000</td>\n",
       "      <td>-0.164000</td>\n",
       "      <td>-0.018900</td>\n",
       "      <td>-0.395000</td>\n",
       "      <td>0.981906</td>\n",
       "      <td>0.078860</td>\n",
       "      <td>0.982105</td>\n",
       "      <td>0.056391</td>\n",
       "      <td>-0.281000</td>\n",
       "      <td>0.033215</td>\n",
       "      <td>0.992251</td>\n",
       "      <td>0.825535</td>\n",
       "      <td>0.036967</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.277650</td>\n",
       "      <td>0.771464</td>\n",
       "      <td>0.994031</td>\n",
       "      <td>0.443454</td>\n",
       "      <td>0.991865</td>\n",
       "      <td>-0.991000</td>\n",
       "      <td>0.214649</td>\n",
       "      <td>0.286407</td>\n",
       "      <td>-0.946000</td>\n",
       "      <td>-0.093300</td>\n",
       "      <td>0.217141</td>\n",
       "      <td>0.578061</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.153605</td>\n",
       "      <td>-0.971000</td>\n",
       "      <td>0.993360</td>\n",
       "      <td>0.238092</td>\n",
       "      <td>0.110214</td>\n",
       "      <td>0.485985</td>\n",
       "      <td>0.552147</td>\n",
       "      <td>-0.082900</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.023200</td>\n",
       "      <td>-0.105000</td>\n",
       "      <td>0.056106</td>\n",
       "      <td>0.232034</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.598000</td>\n",
       "      <td>0.841625</td>\n",
       "      <td>0.624556</td>\n",
       "      <td>-0.067000</td>\n",
       "      <td>-0.108000</td>\n",
       "      <td>0.226912</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>0.989228</td>\n",
       "      <td>-0.220000</td>\n",
       "      <td>-0.020600</td>\n",
       "      <td>-0.372000</td>\n",
       "      <td>0.195752</td>\n",
       "      <td>0.186262</td>\n",
       "      <td>-0.305000</td>\n",
       "      <td>0.998437</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.303861</td>\n",
       "      <td>0.210397</td>\n",
       "      <td>-0.453000</td>\n",
       "      <td>-0.517000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>Group_10_96</td>\n",
       "      <td>Group_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976472</td>\n",
       "      <td>0.966214</td>\n",
       "      <td>0.092994</td>\n",
       "      <td>0.181245</td>\n",
       "      <td>-0.177000</td>\n",
       "      <td>0.958835</td>\n",
       "      <td>0.579420</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>0.030277</td>\n",
       "      <td>-0.988000</td>\n",
       "      <td>0.119164</td>\n",
       "      <td>-0.979000</td>\n",
       "      <td>-0.050900</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.217856</td>\n",
       "      <td>0.368915</td>\n",
       "      <td>-0.214000</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.111000</td>\n",
       "      <td>-0.021200</td>\n",
       "      <td>-0.106000</td>\n",
       "      <td>-0.135000</td>\n",
       "      <td>0.962444</td>\n",
       "      <td>0.997855</td>\n",
       "      <td>0.993624</td>\n",
       "      <td>-0.454000</td>\n",
       "      <td>0.176624</td>\n",
       "      <td>-0.134000</td>\n",
       "      <td>0.609526</td>\n",
       "      <td>0.986281</td>\n",
       "      <td>0.193663</td>\n",
       "      <td>0.350466</td>\n",
       "      <td>0.074822</td>\n",
       "      <td>-0.950000</td>\n",
       "      <td>0.196402</td>\n",
       "      <td>-0.364000</td>\n",
       "      <td>-0.216000</td>\n",
       "      <td>0.947507</td>\n",
       "      <td>0.036632</td>\n",
       "      <td>0.442075</td>\n",
       "      <td>-0.061300</td>\n",
       "      <td>0.381139</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>0.289471</td>\n",
       "      <td>0.496096</td>\n",
       "      <td>-0.952000</td>\n",
       "      <td>0.311688</td>\n",
       "      <td>0.506335</td>\n",
       "      <td>-0.222000</td>\n",
       "      <td>0.996973</td>\n",
       "      <td>0.106532</td>\n",
       "      <td>0.998081</td>\n",
       "      <td>-0.042100</td>\n",
       "      <td>0.382375</td>\n",
       "      <td>0.168536</td>\n",
       "      <td>-0.165000</td>\n",
       "      <td>-0.201000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>0.086901</td>\n",
       "      <td>0.134899</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.352979</td>\n",
       "      <td>-0.103000</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>0.997485</td>\n",
       "      <td>0.742126</td>\n",
       "      <td>0.144698</td>\n",
       "      <td>0.264214</td>\n",
       "      <td>0.995406</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>-0.920000</td>\n",
       "      <td>-0.881000</td>\n",
       "      <td>-0.582000</td>\n",
       "      <td>-0.019800</td>\n",
       "      <td>-0.301000</td>\n",
       "      <td>0.997304</td>\n",
       "      <td>-0.148000</td>\n",
       "      <td>-0.321000</td>\n",
       "      <td>-0.988000</td>\n",
       "      <td>0.185159</td>\n",
       "      <td>0.948530</td>\n",
       "      <td>-0.095600</td>\n",
       "      <td>0.992312</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.015077</td>\n",
       "      <td>0.345219</td>\n",
       "      <td>0.100997</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>-0.062600</td>\n",
       "      <td>0.056335</td>\n",
       "      <td>-0.659000</td>\n",
       "      <td>-0.434000</td>\n",
       "      <td>-0.657000</td>\n",
       "      <td>0.995046</td>\n",
       "      <td>0.423368</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.232000</td>\n",
       "      <td>0.027411</td>\n",
       "      <td>-0.987000</td>\n",
       "      <td>-0.971000</td>\n",
       "      <td>0.289940</td>\n",
       "      <td>-0.204000</td>\n",
       "      <td>0.290233</td>\n",
       "      <td>0.731255</td>\n",
       "      <td>0.236098</td>\n",
       "      <td>-0.039300</td>\n",
       "      <td>-0.937000</td>\n",
       "      <td>-0.281000</td>\n",
       "      <td>-0.321000</td>\n",
       "      <td>0.976107</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>0.076579</td>\n",
       "      <td>0.372433</td>\n",
       "      <td>-0.845000</td>\n",
       "      <td>-0.298000</td>\n",
       "      <td>-0.317000</td>\n",
       "      <td>0.988591</td>\n",
       "      <td>-0.976000</td>\n",
       "      <td>-0.087900</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-0.631000</td>\n",
       "      <td>-0.225000</td>\n",
       "      <td>-0.222000</td>\n",
       "      <td>-0.397000</td>\n",
       "      <td>0.108176</td>\n",
       "      <td>-0.319000</td>\n",
       "      <td>-0.119000</td>\n",
       "      <td>0.715349</td>\n",
       "      <td>0.980517</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>-0.121000</td>\n",
       "      <td>0.286654</td>\n",
       "      <td>-0.610000</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.983000</td>\n",
       "      <td>0.178252</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.240468</td>\n",
       "      <td>-0.151000</td>\n",
       "      <td>0.983241</td>\n",
       "      <td>-0.194000</td>\n",
       "      <td>0.998371</td>\n",
       "      <td>-0.899000</td>\n",
       "      <td>0.996921</td>\n",
       "      <td>-0.763000</td>\n",
       "      <td>0.269131</td>\n",
       "      <td>-0.365000</td>\n",
       "      <td>-0.032400</td>\n",
       "      <td>0.962750</td>\n",
       "      <td>0.329860</td>\n",
       "      <td>-0.001580</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.196977</td>\n",
       "      <td>0.810644</td>\n",
       "      <td>-0.276000</td>\n",
       "      <td>0.012494</td>\n",
       "      <td>0.104731</td>\n",
       "      <td>0.267546</td>\n",
       "      <td>-0.526000</td>\n",
       "      <td>0.036401</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>-0.114000</td>\n",
       "      <td>-0.135000</td>\n",
       "      <td>0.316695</td>\n",
       "      <td>0.999742</td>\n",
       "      <td>0.963646</td>\n",
       "      <td>-0.130000</td>\n",
       "      <td>-0.706000</td>\n",
       "      <td>0.265760</td>\n",
       "      <td>-0.445000</td>\n",
       "      <td>0.289894</td>\n",
       "      <td>-0.030500</td>\n",
       "      <td>0.867117</td>\n",
       "      <td>0.125154</td>\n",
       "      <td>0.998515</td>\n",
       "      <td>-0.269000</td>\n",
       "      <td>0.828834</td>\n",
       "      <td>0.039968</td>\n",
       "      <td>0.956172</td>\n",
       "      <td>-0.711000</td>\n",
       "      <td>0.504717</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.991000</td>\n",
       "      <td>-0.703000</td>\n",
       "      <td>-0.018000</td>\n",
       "      <td>0.994946</td>\n",
       "      <td>0.934011</td>\n",
       "      <td>-0.884000</td>\n",
       "      <td>-0.991000</td>\n",
       "      <td>-0.344000</td>\n",
       "      <td>0.991298</td>\n",
       "      <td>0.387910</td>\n",
       "      <td>-0.953000</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>0.971056</td>\n",
       "      <td>0.111397</td>\n",
       "      <td>0.124106</td>\n",
       "      <td>-0.577000</td>\n",
       "      <td>-0.893000</td>\n",
       "      <td>0.196419</td>\n",
       "      <td>0.533539</td>\n",
       "      <td>0.971664</td>\n",
       "      <td>-0.392000</td>\n",
       "      <td>0.977074</td>\n",
       "      <td>0.996998</td>\n",
       "      <td>-0.038900</td>\n",
       "      <td>-0.688000</td>\n",
       "      <td>0.130311</td>\n",
       "      <td>-0.171000</td>\n",
       "      <td>-0.166000</td>\n",
       "      <td>0.985167</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>-0.167000</td>\n",
       "      <td>0.999747</td>\n",
       "      <td>0.871974</td>\n",
       "      <td>-0.283000</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>-0.134000</td>\n",
       "      <td>0.326250</td>\n",
       "      <td>0.453979</td>\n",
       "      <td>-0.234000</td>\n",
       "      <td>-0.965000</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>0.442280</td>\n",
       "      <td>-0.983000</td>\n",
       "      <td>-0.261000</td>\n",
       "      <td>0.047789</td>\n",
       "      <td>0.193900</td>\n",
       "      <td>-0.052300</td>\n",
       "      <td>-0.374000</td>\n",
       "      <td>0.997314</td>\n",
       "      <td>-0.193000</td>\n",
       "      <td>-0.390000</td>\n",
       "      <td>-0.237000</td>\n",
       "      <td>-0.178000</td>\n",
       "      <td>-0.170000</td>\n",
       "      <td>0.776282</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>-0.726000</td>\n",
       "      <td>0.999200</td>\n",
       "      <td>-0.246000</td>\n",
       "      <td>0.217383</td>\n",
       "      <td>0.999690</td>\n",
       "      <td>-0.243000</td>\n",
       "      <td>0.967823</td>\n",
       "      <td>-0.310000</td>\n",
       "      <td>-0.395000</td>\n",
       "      <td>0.330748</td>\n",
       "      <td>-0.170000</td>\n",
       "      <td>0.140115</td>\n",
       "      <td>0.999338</td>\n",
       "      <td>0.090732</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.865000</td>\n",
       "      <td>-0.079800</td>\n",
       "      <td>0.905974</td>\n",
       "      <td>-0.358000</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.089030</td>\n",
       "      <td>-0.946000</td>\n",
       "      <td>0.078523</td>\n",
       "      <td>0.985624</td>\n",
       "      <td>0.997673</td>\n",
       "      <td>-0.903000</td>\n",
       "      <td>-0.073800</td>\n",
       "      <td>-0.028000</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>-0.062900</td>\n",
       "      <td>-0.795000</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>-0.116000</td>\n",
       "      <td>-0.830000</td>\n",
       "      <td>0.403189</td>\n",
       "      <td>0.196774</td>\n",
       "      <td>0.574785</td>\n",
       "      <td>-0.218000</td>\n",
       "      <td>0.562822</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.766805</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>-0.051800</td>\n",
       "      <td>-0.034700</td>\n",
       "      <td>-0.298000</td>\n",
       "      <td>0.047519</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.991000</td>\n",
       "      <td>-0.216000</td>\n",
       "      <td>0.033850</td>\n",
       "      <td>-0.167000</td>\n",
       "      <td>0.945981</td>\n",
       "      <td>0.999302</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.255000</td>\n",
       "      <td>0.855767</td>\n",
       "      <td>-0.186000</td>\n",
       "      <td>0.997187</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.312862</td>\n",
       "      <td>-0.562000</td>\n",
       "      <td>0.994305</td>\n",
       "      <td>0.179985</td>\n",
       "      <td>0.175859</td>\n",
       "      <td>0.177313</td>\n",
       "      <td>0.995453</td>\n",
       "      <td>0.788372</td>\n",
       "      <td>0.228086</td>\n",
       "      <td>0.653279</td>\n",
       "      <td>-0.730000</td>\n",
       "      <td>-0.308000</td>\n",
       "      <td>0.955654</td>\n",
       "      <td>0.899007</td>\n",
       "      <td>0.221897</td>\n",
       "      <td>-0.152000</td>\n",
       "      <td>-0.295000</td>\n",
       "      <td>0.297758</td>\n",
       "      <td>0.999556</td>\n",
       "      <td>0.125114</td>\n",
       "      <td>0.515869</td>\n",
       "      <td>-0.561000</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.230563</td>\n",
       "      <td>-0.040700</td>\n",
       "      <td>-0.614000</td>\n",
       "      <td>0.277921</td>\n",
       "      <td>-0.985000</td>\n",
       "      <td>-0.853000</td>\n",
       "      <td>0.967329</td>\n",
       "      <td>0.042435</td>\n",
       "      <td>-0.032100</td>\n",
       "      <td>-0.063300</td>\n",
       "      <td>0.054849</td>\n",
       "      <td>-0.048800</td>\n",
       "      <td>0.297042</td>\n",
       "      <td>-0.715000</td>\n",
       "      <td>-0.532000</td>\n",
       "      <td>-0.015700</td>\n",
       "      <td>0.990777</td>\n",
       "      <td>0.170099</td>\n",
       "      <td>-0.132000</td>\n",
       "      <td>0.996434</td>\n",
       "      <td>-0.585000</td>\n",
       "      <td>0.735161</td>\n",
       "      <td>0.786084</td>\n",
       "      <td>0.994493</td>\n",
       "      <td>-0.359000</td>\n",
       "      <td>0.488482</td>\n",
       "      <td>-0.000408</td>\n",
       "      <td>-0.059200</td>\n",
       "      <td>0.488652</td>\n",
       "      <td>0.057344</td>\n",
       "      <td>0.831556</td>\n",
       "      <td>0.185354</td>\n",
       "      <td>0.171250</td>\n",
       "      <td>-0.156000</td>\n",
       "      <td>-0.127000</td>\n",
       "      <td>-0.036500</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.596000</td>\n",
       "      <td>-0.208000</td>\n",
       "      <td>-0.012200</td>\n",
       "      <td>0.430089</td>\n",
       "      <td>-0.987000</td>\n",
       "      <td>-0.762000</td>\n",
       "      <td>-0.255000</td>\n",
       "      <td>-0.501000</td>\n",
       "      <td>-0.020400</td>\n",
       "      <td>0.176314</td>\n",
       "      <td>0.939738</td>\n",
       "      <td>0.044714</td>\n",
       "      <td>0.183340</td>\n",
       "      <td>0.605901</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>-0.098500</td>\n",
       "      <td>-0.421000</td>\n",
       "      <td>-0.196000</td>\n",
       "      <td>-0.166000</td>\n",
       "      <td>0.881534</td>\n",
       "      <td>0.205062</td>\n",
       "      <td>-0.985000</td>\n",
       "      <td>-0.143000</td>\n",
       "      <td>0.999625</td>\n",
       "      <td>0.631879</td>\n",
       "      <td>0.485617</td>\n",
       "      <td>-0.014700</td>\n",
       "      <td>0.328279</td>\n",
       "      <td>-0.088400</td>\n",
       "      <td>-0.360000</td>\n",
       "      <td>0.993871</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.259000</td>\n",
       "      <td>-0.304000</td>\n",
       "      <td>-0.101000</td>\n",
       "      <td>0.269966</td>\n",
       "      <td>-0.301000</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>-0.298000</td>\n",
       "      <td>-0.352000</td>\n",
       "      <td>-0.916000</td>\n",
       "      <td>-0.606000</td>\n",
       "      <td>-0.029100</td>\n",
       "      <td>0.999003</td>\n",
       "      <td>-0.078400</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.224102</td>\n",
       "      <td>-0.141000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.862760</td>\n",
       "      <td>0.558123</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.056800</td>\n",
       "      <td>-0.746000</td>\n",
       "      <td>0.097533</td>\n",
       "      <td>0.117713</td>\n",
       "      <td>-0.933000</td>\n",
       "      <td>0.396301</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.210126</td>\n",
       "      <td>0.979113</td>\n",
       "      <td>-0.374000</td>\n",
       "      <td>0.891207</td>\n",
       "      <td>0.114523</td>\n",
       "      <td>-0.937000</td>\n",
       "      <td>0.334600</td>\n",
       "      <td>-0.007680</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>-0.022000</td>\n",
       "      <td>0.228273</td>\n",
       "      <td>-0.751000</td>\n",
       "      <td>0.994494</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.221000</td>\n",
       "      <td>0.120964</td>\n",
       "      <td>-0.906000</td>\n",
       "      <td>-0.806000</td>\n",
       "      <td>0.197499</td>\n",
       "      <td>0.350951</td>\n",
       "      <td>-0.295000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>-0.246000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>-0.983000</td>\n",
       "      <td>-0.039200</td>\n",
       "      <td>-0.016600</td>\n",
       "      <td>0.059997</td>\n",
       "      <td>-0.104000</td>\n",
       "      <td>0.049140</td>\n",
       "      <td>-0.044500</td>\n",
       "      <td>0.831505</td>\n",
       "      <td>0.219434</td>\n",
       "      <td>0.530111</td>\n",
       "      <td>-0.462000</td>\n",
       "      <td>0.104782</td>\n",
       "      <td>-0.216000</td>\n",
       "      <td>0.975176</td>\n",
       "      <td>0.444326</td>\n",
       "      <td>-0.257000</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.332140</td>\n",
       "      <td>0.990061</td>\n",
       "      <td>0.997665</td>\n",
       "      <td>0.915089</td>\n",
       "      <td>0.437201</td>\n",
       "      <td>-0.976000</td>\n",
       "      <td>0.132573</td>\n",
       "      <td>0.336856</td>\n",
       "      <td>-0.889000</td>\n",
       "      <td>0.578274</td>\n",
       "      <td>0.007676</td>\n",
       "      <td>0.412364</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>0.048517</td>\n",
       "      <td>-0.945000</td>\n",
       "      <td>0.966838</td>\n",
       "      <td>0.049834</td>\n",
       "      <td>0.006290</td>\n",
       "      <td>0.219993</td>\n",
       "      <td>0.086624</td>\n",
       "      <td>-0.135000</td>\n",
       "      <td>-0.940000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.157000</td>\n",
       "      <td>0.008617</td>\n",
       "      <td>-0.491000</td>\n",
       "      <td>-0.138000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.560000</td>\n",
       "      <td>-0.517000</td>\n",
       "      <td>0.027885</td>\n",
       "      <td>0.076535</td>\n",
       "      <td>-0.181000</td>\n",
       "      <td>0.289863</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.997953</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>0.076742</td>\n",
       "      <td>0.165756</td>\n",
       "      <td>-0.051600</td>\n",
       "      <td>-0.090800</td>\n",
       "      <td>-0.751000</td>\n",
       "      <td>0.975555</td>\n",
       "      <td>-0.931000</td>\n",
       "      <td>-0.225000</td>\n",
       "      <td>0.358259</td>\n",
       "      <td>-0.137000</td>\n",
       "      <td>-0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>Group_10_97</td>\n",
       "      <td>Group_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996249</td>\n",
       "      <td>0.850641</td>\n",
       "      <td>-0.034200</td>\n",
       "      <td>0.275094</td>\n",
       "      <td>0.378156</td>\n",
       "      <td>0.892405</td>\n",
       "      <td>0.817468</td>\n",
       "      <td>-0.987000</td>\n",
       "      <td>-0.201000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.107625</td>\n",
       "      <td>-0.988000</td>\n",
       "      <td>0.250781</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>-0.493000</td>\n",
       "      <td>0.269503</td>\n",
       "      <td>-0.304000</td>\n",
       "      <td>0.056290</td>\n",
       "      <td>-0.042600</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>-0.006050</td>\n",
       "      <td>-0.005230</td>\n",
       "      <td>-0.940000</td>\n",
       "      <td>0.802912</td>\n",
       "      <td>0.999335</td>\n",
       "      <td>0.999003</td>\n",
       "      <td>0.400539</td>\n",
       "      <td>-0.164000</td>\n",
       "      <td>0.042764</td>\n",
       "      <td>0.764451</td>\n",
       "      <td>0.996090</td>\n",
       "      <td>-0.292000</td>\n",
       "      <td>0.556738</td>\n",
       "      <td>-0.022600</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>0.339236</td>\n",
       "      <td>-0.393000</td>\n",
       "      <td>-0.087100</td>\n",
       "      <td>0.967174</td>\n",
       "      <td>0.069377</td>\n",
       "      <td>-0.057600</td>\n",
       "      <td>0.095174</td>\n",
       "      <td>0.174192</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>-0.133000</td>\n",
       "      <td>-0.248000</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>0.101304</td>\n",
       "      <td>0.657507</td>\n",
       "      <td>-0.262000</td>\n",
       "      <td>0.994555</td>\n",
       "      <td>-0.058600</td>\n",
       "      <td>0.999810</td>\n",
       "      <td>0.065108</td>\n",
       "      <td>0.737731</td>\n",
       "      <td>0.219697</td>\n",
       "      <td>0.135541</td>\n",
       "      <td>0.195049</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.961000</td>\n",
       "      <td>-0.096900</td>\n",
       "      <td>-0.445000</td>\n",
       "      <td>0.990518</td>\n",
       "      <td>-0.014600</td>\n",
       "      <td>-0.065200</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>0.969650</td>\n",
       "      <td>0.874684</td>\n",
       "      <td>-0.246000</td>\n",
       "      <td>-0.347000</td>\n",
       "      <td>0.998312</td>\n",
       "      <td>0.999427</td>\n",
       "      <td>-0.864000</td>\n",
       "      <td>-0.880000</td>\n",
       "      <td>-0.939000</td>\n",
       "      <td>-0.113000</td>\n",
       "      <td>-0.526000</td>\n",
       "      <td>0.996681</td>\n",
       "      <td>-0.045100</td>\n",
       "      <td>-0.578000</td>\n",
       "      <td>-0.704000</td>\n",
       "      <td>-0.011400</td>\n",
       "      <td>0.981035</td>\n",
       "      <td>0.087866</td>\n",
       "      <td>0.995233</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.254000</td>\n",
       "      <td>0.216205</td>\n",
       "      <td>-0.359000</td>\n",
       "      <td>0.016856</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.308000</td>\n",
       "      <td>-0.113000</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>-0.936000</td>\n",
       "      <td>-0.631000</td>\n",
       "      <td>0.988966</td>\n",
       "      <td>0.268401</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-0.126000</td>\n",
       "      <td>0.350839</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.988000</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>-0.390000</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.323051</td>\n",
       "      <td>0.349014</td>\n",
       "      <td>-0.353000</td>\n",
       "      <td>-0.858000</td>\n",
       "      <td>0.179453</td>\n",
       "      <td>-0.029600</td>\n",
       "      <td>0.986412</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.164233</td>\n",
       "      <td>0.236288</td>\n",
       "      <td>-0.967000</td>\n",
       "      <td>0.554462</td>\n",
       "      <td>-0.244000</td>\n",
       "      <td>0.966775</td>\n",
       "      <td>0.053261</td>\n",
       "      <td>-0.187000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.015670</td>\n",
       "      <td>-0.068600</td>\n",
       "      <td>0.481252</td>\n",
       "      <td>-0.987000</td>\n",
       "      <td>-0.409000</td>\n",
       "      <td>-0.435000</td>\n",
       "      <td>0.274295</td>\n",
       "      <td>0.993690</td>\n",
       "      <td>0.916473</td>\n",
       "      <td>0.993967</td>\n",
       "      <td>-0.134000</td>\n",
       "      <td>0.492531</td>\n",
       "      <td>-0.938000</td>\n",
       "      <td>0.999758</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.784000</td>\n",
       "      <td>0.403493</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>-0.014800</td>\n",
       "      <td>0.114864</td>\n",
       "      <td>0.974028</td>\n",
       "      <td>-0.578000</td>\n",
       "      <td>0.999810</td>\n",
       "      <td>-0.973000</td>\n",
       "      <td>0.999497</td>\n",
       "      <td>-0.963000</td>\n",
       "      <td>0.275022</td>\n",
       "      <td>-0.116000</td>\n",
       "      <td>-0.036900</td>\n",
       "      <td>0.916547</td>\n",
       "      <td>-0.015000</td>\n",
       "      <td>-0.121000</td>\n",
       "      <td>-0.297000</td>\n",
       "      <td>-0.297000</td>\n",
       "      <td>0.301366</td>\n",
       "      <td>-0.109000</td>\n",
       "      <td>0.277923</td>\n",
       "      <td>-0.431000</td>\n",
       "      <td>0.095091</td>\n",
       "      <td>-0.177000</td>\n",
       "      <td>0.014848</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>-0.413000</td>\n",
       "      <td>-0.187000</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>0.999284</td>\n",
       "      <td>-0.284000</td>\n",
       "      <td>-0.146000</td>\n",
       "      <td>-0.987000</td>\n",
       "      <td>-0.633000</td>\n",
       "      <td>-0.710000</td>\n",
       "      <td>0.142690</td>\n",
       "      <td>0.142850</td>\n",
       "      <td>-0.840000</td>\n",
       "      <td>0.038139</td>\n",
       "      <td>0.998962</td>\n",
       "      <td>0.997009</td>\n",
       "      <td>0.991527</td>\n",
       "      <td>-0.317000</td>\n",
       "      <td>0.989952</td>\n",
       "      <td>-0.018500</td>\n",
       "      <td>0.481829</td>\n",
       "      <td>-0.972000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.671000</td>\n",
       "      <td>-0.013600</td>\n",
       "      <td>0.998806</td>\n",
       "      <td>-0.075900</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>0.113718</td>\n",
       "      <td>0.992580</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>-0.737000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.988104</td>\n",
       "      <td>-0.343000</td>\n",
       "      <td>-0.215000</td>\n",
       "      <td>-0.103000</td>\n",
       "      <td>-0.673000</td>\n",
       "      <td>0.080141</td>\n",
       "      <td>0.232339</td>\n",
       "      <td>0.993143</td>\n",
       "      <td>-0.349000</td>\n",
       "      <td>0.999743</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>-0.127000</td>\n",
       "      <td>-0.504000</td>\n",
       "      <td>-0.015900</td>\n",
       "      <td>0.059672</td>\n",
       "      <td>-0.032500</td>\n",
       "      <td>0.997321</td>\n",
       "      <td>-0.975000</td>\n",
       "      <td>-0.322000</td>\n",
       "      <td>0.993879</td>\n",
       "      <td>0.950041</td>\n",
       "      <td>0.084141</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.241429</td>\n",
       "      <td>-0.611000</td>\n",
       "      <td>0.321815</td>\n",
       "      <td>0.129017</td>\n",
       "      <td>-0.801000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.368152</td>\n",
       "      <td>-0.468000</td>\n",
       "      <td>0.090970</td>\n",
       "      <td>-0.329000</td>\n",
       "      <td>0.051395</td>\n",
       "      <td>-0.281000</td>\n",
       "      <td>0.393877</td>\n",
       "      <td>0.999366</td>\n",
       "      <td>0.245983</td>\n",
       "      <td>-0.875000</td>\n",
       "      <td>-0.492000</td>\n",
       "      <td>-0.191000</td>\n",
       "      <td>-0.309000</td>\n",
       "      <td>0.545061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.860000</td>\n",
       "      <td>0.997929</td>\n",
       "      <td>0.428038</td>\n",
       "      <td>0.171183</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>-0.143000</td>\n",
       "      <td>0.991610</td>\n",
       "      <td>0.031583</td>\n",
       "      <td>-0.255000</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>0.067496</td>\n",
       "      <td>-0.134000</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>-0.067600</td>\n",
       "      <td>0.223678</td>\n",
       "      <td>-0.972000</td>\n",
       "      <td>-0.192000</td>\n",
       "      <td>0.708586</td>\n",
       "      <td>-0.041800</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.180000</td>\n",
       "      <td>-0.724000</td>\n",
       "      <td>0.069614</td>\n",
       "      <td>0.926636</td>\n",
       "      <td>0.999423</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>0.213249</td>\n",
       "      <td>-0.068600</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.056676</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>-0.033800</td>\n",
       "      <td>-0.981000</td>\n",
       "      <td>0.996186</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.725557</td>\n",
       "      <td>-0.282000</td>\n",
       "      <td>-0.675000</td>\n",
       "      <td>-0.981000</td>\n",
       "      <td>0.378815</td>\n",
       "      <td>0.999835</td>\n",
       "      <td>-0.713000</td>\n",
       "      <td>0.188145</td>\n",
       "      <td>-0.311000</td>\n",
       "      <td>-0.099400</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.020604</td>\n",
       "      <td>-0.006660</td>\n",
       "      <td>0.242547</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.999810</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>-0.032200</td>\n",
       "      <td>0.988037</td>\n",
       "      <td>0.236791</td>\n",
       "      <td>0.999082</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>-0.919000</td>\n",
       "      <td>-0.694000</td>\n",
       "      <td>0.999125</td>\n",
       "      <td>-0.220000</td>\n",
       "      <td>-0.451000</td>\n",
       "      <td>0.251210</td>\n",
       "      <td>0.998837</td>\n",
       "      <td>0.531746</td>\n",
       "      <td>-0.105000</td>\n",
       "      <td>0.058571</td>\n",
       "      <td>-0.639000</td>\n",
       "      <td>-0.355000</td>\n",
       "      <td>0.986870</td>\n",
       "      <td>0.986936</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>0.028141</td>\n",
       "      <td>-0.081400</td>\n",
       "      <td>0.275401</td>\n",
       "      <td>0.999354</td>\n",
       "      <td>0.065021</td>\n",
       "      <td>-0.294000</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>-0.932000</td>\n",
       "      <td>0.133581</td>\n",
       "      <td>0.080153</td>\n",
       "      <td>-0.987000</td>\n",
       "      <td>0.500482</td>\n",
       "      <td>-0.991000</td>\n",
       "      <td>0.299985</td>\n",
       "      <td>0.970503</td>\n",
       "      <td>0.219597</td>\n",
       "      <td>-0.268000</td>\n",
       "      <td>0.949432</td>\n",
       "      <td>0.097839</td>\n",
       "      <td>0.272638</td>\n",
       "      <td>0.160443</td>\n",
       "      <td>0.421621</td>\n",
       "      <td>-0.823000</td>\n",
       "      <td>0.227114</td>\n",
       "      <td>0.994985</td>\n",
       "      <td>0.231989</td>\n",
       "      <td>0.064888</td>\n",
       "      <td>0.979644</td>\n",
       "      <td>-0.849000</td>\n",
       "      <td>0.966496</td>\n",
       "      <td>0.942835</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.050663</td>\n",
       "      <td>0.345903</td>\n",
       "      <td>-0.051800</td>\n",
       "      <td>0.325987</td>\n",
       "      <td>0.542395</td>\n",
       "      <td>-0.118000</td>\n",
       "      <td>0.934903</td>\n",
       "      <td>-0.009840</td>\n",
       "      <td>-0.705000</td>\n",
       "      <td>0.140355</td>\n",
       "      <td>-0.411000</td>\n",
       "      <td>-0.036000</td>\n",
       "      <td>-0.991000</td>\n",
       "      <td>-0.812000</td>\n",
       "      <td>-0.397000</td>\n",
       "      <td>0.268980</td>\n",
       "      <td>0.246626</td>\n",
       "      <td>-0.976000</td>\n",
       "      <td>-0.872000</td>\n",
       "      <td>0.615564</td>\n",
       "      <td>-0.145000</td>\n",
       "      <td>-0.027600</td>\n",
       "      <td>0.221557</td>\n",
       "      <td>0.993269</td>\n",
       "      <td>-0.381000</td>\n",
       "      <td>0.229303</td>\n",
       "      <td>0.873854</td>\n",
       "      <td>-0.974000</td>\n",
       "      <td>0.072509</td>\n",
       "      <td>0.215451</td>\n",
       "      <td>-0.190000</td>\n",
       "      <td>-0.060000</td>\n",
       "      <td>0.933309</td>\n",
       "      <td>0.162448</td>\n",
       "      <td>-0.981000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0.999713</td>\n",
       "      <td>-0.878000</td>\n",
       "      <td>0.395916</td>\n",
       "      <td>-0.247000</td>\n",
       "      <td>0.535432</td>\n",
       "      <td>-0.382000</td>\n",
       "      <td>-0.347000</td>\n",
       "      <td>0.991858</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.364000</td>\n",
       "      <td>-0.172000</td>\n",
       "      <td>-0.030900</td>\n",
       "      <td>0.033595</td>\n",
       "      <td>-0.309000</td>\n",
       "      <td>0.979734</td>\n",
       "      <td>0.093773</td>\n",
       "      <td>0.305459</td>\n",
       "      <td>-0.989000</td>\n",
       "      <td>-0.498000</td>\n",
       "      <td>-0.043700</td>\n",
       "      <td>0.999221</td>\n",
       "      <td>-0.742000</td>\n",
       "      <td>-0.336000</td>\n",
       "      <td>0.080458</td>\n",
       "      <td>0.143301</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.942267</td>\n",
       "      <td>-0.854000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.102000</td>\n",
       "      <td>-0.943000</td>\n",
       "      <td>0.270288</td>\n",
       "      <td>0.409559</td>\n",
       "      <td>-0.784000</td>\n",
       "      <td>0.533321</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.373000</td>\n",
       "      <td>-0.453000</td>\n",
       "      <td>-0.342000</td>\n",
       "      <td>0.798408</td>\n",
       "      <td>0.062563</td>\n",
       "      <td>-0.721000</td>\n",
       "      <td>0.191840</td>\n",
       "      <td>0.044179</td>\n",
       "      <td>-0.303000</td>\n",
       "      <td>0.090925</td>\n",
       "      <td>0.311871</td>\n",
       "      <td>-0.985000</td>\n",
       "      <td>0.995408</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.988000</td>\n",
       "      <td>0.192646</td>\n",
       "      <td>-0.749000</td>\n",
       "      <td>-0.891000</td>\n",
       "      <td>0.105141</td>\n",
       "      <td>0.033972</td>\n",
       "      <td>0.148865</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.917000</td>\n",
       "      <td>-0.036700</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.921000</td>\n",
       "      <td>0.326177</td>\n",
       "      <td>-0.283000</td>\n",
       "      <td>-0.356000</td>\n",
       "      <td>0.019045</td>\n",
       "      <td>0.478050</td>\n",
       "      <td>0.211792</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>0.030556</td>\n",
       "      <td>0.910574</td>\n",
       "      <td>0.244484</td>\n",
       "      <td>0.189636</td>\n",
       "      <td>-0.484000</td>\n",
       "      <td>0.996913</td>\n",
       "      <td>0.819436</td>\n",
       "      <td>0.134835</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.054624</td>\n",
       "      <td>0.995002</td>\n",
       "      <td>0.999764</td>\n",
       "      <td>0.800812</td>\n",
       "      <td>0.538879</td>\n",
       "      <td>-0.908000</td>\n",
       "      <td>-0.243000</td>\n",
       "      <td>0.444392</td>\n",
       "      <td>0.677627</td>\n",
       "      <td>0.871612</td>\n",
       "      <td>0.180869</td>\n",
       "      <td>0.424984</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.040628</td>\n",
       "      <td>-0.929000</td>\n",
       "      <td>0.985985</td>\n",
       "      <td>-0.081400</td>\n",
       "      <td>-0.272000</td>\n",
       "      <td>0.131157</td>\n",
       "      <td>-0.164000</td>\n",
       "      <td>-0.272000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.069800</td>\n",
       "      <td>-0.436000</td>\n",
       "      <td>0.026454</td>\n",
       "      <td>-0.412000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.742000</td>\n",
       "      <td>-0.043600</td>\n",
       "      <td>-0.372000</td>\n",
       "      <td>0.358223</td>\n",
       "      <td>-0.080200</td>\n",
       "      <td>0.383769</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>0.998174</td>\n",
       "      <td>-0.982000</td>\n",
       "      <td>-0.047800</td>\n",
       "      <td>0.162663</td>\n",
       "      <td>-0.114000</td>\n",
       "      <td>0.105253</td>\n",
       "      <td>-0.924000</td>\n",
       "      <td>0.900333</td>\n",
       "      <td>-0.921000</td>\n",
       "      <td>-0.076900</td>\n",
       "      <td>0.361062</td>\n",
       "      <td>-0.255000</td>\n",
       "      <td>-0.602000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>Group_10_98</td>\n",
       "      <td>Group_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992738</td>\n",
       "      <td>-0.303000</td>\n",
       "      <td>0.015695</td>\n",
       "      <td>0.271703</td>\n",
       "      <td>0.517016</td>\n",
       "      <td>0.977484</td>\n",
       "      <td>0.922489</td>\n",
       "      <td>-0.982000</td>\n",
       "      <td>-0.061300</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.014900</td>\n",
       "      <td>-0.961000</td>\n",
       "      <td>-0.830000</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>0.752070</td>\n",
       "      <td>0.292949</td>\n",
       "      <td>-0.102000</td>\n",
       "      <td>0.027236</td>\n",
       "      <td>-0.384000</td>\n",
       "      <td>0.009468</td>\n",
       "      <td>0.259648</td>\n",
       "      <td>0.057584</td>\n",
       "      <td>-0.110000</td>\n",
       "      <td>0.980436</td>\n",
       "      <td>0.988972</td>\n",
       "      <td>0.998248</td>\n",
       "      <td>0.160122</td>\n",
       "      <td>-0.172000</td>\n",
       "      <td>0.333261</td>\n",
       "      <td>0.461619</td>\n",
       "      <td>0.993170</td>\n",
       "      <td>0.100335</td>\n",
       "      <td>0.327036</td>\n",
       "      <td>0.315734</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>0.190597</td>\n",
       "      <td>-0.010800</td>\n",
       "      <td>-0.412000</td>\n",
       "      <td>0.826586</td>\n",
       "      <td>0.135248</td>\n",
       "      <td>0.202276</td>\n",
       "      <td>-0.017100</td>\n",
       "      <td>0.073677</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.317000</td>\n",
       "      <td>-0.640000</td>\n",
       "      <td>-0.620000</td>\n",
       "      <td>-0.003270</td>\n",
       "      <td>-0.099200</td>\n",
       "      <td>-0.392000</td>\n",
       "      <td>0.905579</td>\n",
       "      <td>-0.024400</td>\n",
       "      <td>0.999746</td>\n",
       "      <td>0.252376</td>\n",
       "      <td>0.740984</td>\n",
       "      <td>0.512058</td>\n",
       "      <td>0.033735</td>\n",
       "      <td>-0.253000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>0.150639</td>\n",
       "      <td>-0.342000</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>0.529865</td>\n",
       "      <td>-0.036600</td>\n",
       "      <td>-0.984000</td>\n",
       "      <td>0.992775</td>\n",
       "      <td>0.882539</td>\n",
       "      <td>-0.416000</td>\n",
       "      <td>0.512314</td>\n",
       "      <td>0.946722</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>-0.731000</td>\n",
       "      <td>-0.786000</td>\n",
       "      <td>-0.913000</td>\n",
       "      <td>0.101972</td>\n",
       "      <td>-0.369000</td>\n",
       "      <td>0.999079</td>\n",
       "      <td>-0.059900</td>\n",
       "      <td>-0.707000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.116000</td>\n",
       "      <td>0.999572</td>\n",
       "      <td>-0.656000</td>\n",
       "      <td>0.986333</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.022900</td>\n",
       "      <td>0.184245</td>\n",
       "      <td>-0.434000</td>\n",
       "      <td>0.348432</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>-0.518000</td>\n",
       "      <td>-0.115000</td>\n",
       "      <td>-0.728000</td>\n",
       "      <td>0.503660</td>\n",
       "      <td>0.250528</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.320982</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>-0.209000</td>\n",
       "      <td>-0.956000</td>\n",
       "      <td>-0.814000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.038400</td>\n",
       "      <td>-0.562000</td>\n",
       "      <td>-0.277000</td>\n",
       "      <td>0.887576</td>\n",
       "      <td>0.400993</td>\n",
       "      <td>-0.204000</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>0.384248</td>\n",
       "      <td>-0.602000</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-0.070000</td>\n",
       "      <td>0.469369</td>\n",
       "      <td>-0.797000</td>\n",
       "      <td>-0.056100</td>\n",
       "      <td>-0.121000</td>\n",
       "      <td>0.797823</td>\n",
       "      <td>-0.936000</td>\n",
       "      <td>-0.437000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.986000</td>\n",
       "      <td>-0.211000</td>\n",
       "      <td>0.276203</td>\n",
       "      <td>-0.956000</td>\n",
       "      <td>-0.114000</td>\n",
       "      <td>-0.516000</td>\n",
       "      <td>0.025879</td>\n",
       "      <td>0.181874</td>\n",
       "      <td>0.639992</td>\n",
       "      <td>0.999572</td>\n",
       "      <td>0.181660</td>\n",
       "      <td>0.521625</td>\n",
       "      <td>-0.975000</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>0.263832</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>0.141983</td>\n",
       "      <td>-0.142000</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.141534</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>-0.967000</td>\n",
       "      <td>0.994478</td>\n",
       "      <td>-0.959000</td>\n",
       "      <td>-0.117000</td>\n",
       "      <td>-0.277000</td>\n",
       "      <td>-0.218000</td>\n",
       "      <td>0.985649</td>\n",
       "      <td>0.119554</td>\n",
       "      <td>0.040008</td>\n",
       "      <td>-0.343000</td>\n",
       "      <td>0.771243</td>\n",
       "      <td>-0.873000</td>\n",
       "      <td>-0.134000</td>\n",
       "      <td>-0.149000</td>\n",
       "      <td>0.120238</td>\n",
       "      <td>0.273908</td>\n",
       "      <td>-0.217000</td>\n",
       "      <td>0.080381</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>-0.618000</td>\n",
       "      <td>-0.360000</td>\n",
       "      <td>0.071979</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.987364</td>\n",
       "      <td>-0.333000</td>\n",
       "      <td>-0.980000</td>\n",
       "      <td>-0.798000</td>\n",
       "      <td>-0.059000</td>\n",
       "      <td>-0.428000</td>\n",
       "      <td>0.344291</td>\n",
       "      <td>-0.771000</td>\n",
       "      <td>-0.104000</td>\n",
       "      <td>0.998726</td>\n",
       "      <td>0.801511</td>\n",
       "      <td>0.941077</td>\n",
       "      <td>-0.695000</td>\n",
       "      <td>0.266969</td>\n",
       "      <td>-0.676000</td>\n",
       "      <td>0.594326</td>\n",
       "      <td>-0.884000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.079400</td>\n",
       "      <td>0.068126</td>\n",
       "      <td>0.999771</td>\n",
       "      <td>0.995145</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>-0.943000</td>\n",
       "      <td>0.052254</td>\n",
       "      <td>0.994336</td>\n",
       "      <td>0.141648</td>\n",
       "      <td>-0.990000</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>0.973641</td>\n",
       "      <td>-0.036500</td>\n",
       "      <td>-0.161000</td>\n",
       "      <td>-0.146000</td>\n",
       "      <td>-0.879000</td>\n",
       "      <td>0.460386</td>\n",
       "      <td>-0.032300</td>\n",
       "      <td>0.991020</td>\n",
       "      <td>-0.326000</td>\n",
       "      <td>0.999479</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>-0.508000</td>\n",
       "      <td>0.562166</td>\n",
       "      <td>-0.851000</td>\n",
       "      <td>0.211722</td>\n",
       "      <td>0.204541</td>\n",
       "      <td>0.993332</td>\n",
       "      <td>-0.988000</td>\n",
       "      <td>-0.775000</td>\n",
       "      <td>0.984168</td>\n",
       "      <td>0.821142</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.133948</td>\n",
       "      <td>0.970742</td>\n",
       "      <td>0.723823</td>\n",
       "      <td>-0.820000</td>\n",
       "      <td>-0.933000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.184874</td>\n",
       "      <td>-0.864000</td>\n",
       "      <td>0.480171</td>\n",
       "      <td>-0.205000</td>\n",
       "      <td>-0.197000</td>\n",
       "      <td>-0.415000</td>\n",
       "      <td>0.262243</td>\n",
       "      <td>0.999617</td>\n",
       "      <td>0.155635</td>\n",
       "      <td>-0.806000</td>\n",
       "      <td>-0.632000</td>\n",
       "      <td>0.269053</td>\n",
       "      <td>-0.403000</td>\n",
       "      <td>-0.934000</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>0.998559</td>\n",
       "      <td>0.641778</td>\n",
       "      <td>0.137802</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.010880</td>\n",
       "      <td>0.979552</td>\n",
       "      <td>-0.162000</td>\n",
       "      <td>0.059501</td>\n",
       "      <td>-0.172000</td>\n",
       "      <td>-0.328000</td>\n",
       "      <td>-0.254000</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.077634</td>\n",
       "      <td>-0.183000</td>\n",
       "      <td>-0.687000</td>\n",
       "      <td>0.321121</td>\n",
       "      <td>0.859444</td>\n",
       "      <td>0.336462</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.036600</td>\n",
       "      <td>-0.756000</td>\n",
       "      <td>0.254344</td>\n",
       "      <td>0.989391</td>\n",
       "      <td>0.999306</td>\n",
       "      <td>-0.975000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.121829</td>\n",
       "      <td>0.999664</td>\n",
       "      <td>-0.343000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>-0.218000</td>\n",
       "      <td>-0.468000</td>\n",
       "      <td>0.911660</td>\n",
       "      <td>0.309775</td>\n",
       "      <td>-0.702000</td>\n",
       "      <td>0.112847</td>\n",
       "      <td>0.573322</td>\n",
       "      <td>-0.987000</td>\n",
       "      <td>0.859716</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>-0.968000</td>\n",
       "      <td>0.235972</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.062900</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.473175</td>\n",
       "      <td>0.431838</td>\n",
       "      <td>0.972692</td>\n",
       "      <td>0.998424</td>\n",
       "      <td>-0.962000</td>\n",
       "      <td>-0.322000</td>\n",
       "      <td>0.975382</td>\n",
       "      <td>-0.275000</td>\n",
       "      <td>0.999588</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.778000</td>\n",
       "      <td>0.999458</td>\n",
       "      <td>0.045066</td>\n",
       "      <td>0.141705</td>\n",
       "      <td>0.097845</td>\n",
       "      <td>0.998486</td>\n",
       "      <td>0.805715</td>\n",
       "      <td>0.120867</td>\n",
       "      <td>0.094464</td>\n",
       "      <td>-0.963000</td>\n",
       "      <td>-0.123000</td>\n",
       "      <td>0.978432</td>\n",
       "      <td>0.958891</td>\n",
       "      <td>0.068546</td>\n",
       "      <td>-0.222000</td>\n",
       "      <td>-0.442000</td>\n",
       "      <td>0.286142</td>\n",
       "      <td>0.998662</td>\n",
       "      <td>0.245897</td>\n",
       "      <td>-0.770000</td>\n",
       "      <td>-0.204000</td>\n",
       "      <td>-0.985000</td>\n",
       "      <td>0.377962</td>\n",
       "      <td>-0.097800</td>\n",
       "      <td>-0.509000</td>\n",
       "      <td>-0.216000</td>\n",
       "      <td>-0.973000</td>\n",
       "      <td>0.511659</td>\n",
       "      <td>0.828907</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>0.275358</td>\n",
       "      <td>0.984321</td>\n",
       "      <td>-0.254000</td>\n",
       "      <td>0.442250</td>\n",
       "      <td>-0.036300</td>\n",
       "      <td>0.078219</td>\n",
       "      <td>-0.534000</td>\n",
       "      <td>0.129309</td>\n",
       "      <td>0.999467</td>\n",
       "      <td>-0.104000</td>\n",
       "      <td>-0.154000</td>\n",
       "      <td>0.998228</td>\n",
       "      <td>-0.778000</td>\n",
       "      <td>0.999528</td>\n",
       "      <td>0.848450</td>\n",
       "      <td>0.979365</td>\n",
       "      <td>-0.380000</td>\n",
       "      <td>0.765042</td>\n",
       "      <td>0.084485</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>-0.376000</td>\n",
       "      <td>-0.090500</td>\n",
       "      <td>0.750718</td>\n",
       "      <td>-0.156000</td>\n",
       "      <td>-0.521000</td>\n",
       "      <td>0.110749</td>\n",
       "      <td>-0.543000</td>\n",
       "      <td>-0.065600</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.486000</td>\n",
       "      <td>-0.416000</td>\n",
       "      <td>-0.015900</td>\n",
       "      <td>0.420715</td>\n",
       "      <td>-0.990000</td>\n",
       "      <td>-0.608000</td>\n",
       "      <td>0.476470</td>\n",
       "      <td>-0.052400</td>\n",
       "      <td>0.190181</td>\n",
       "      <td>0.144227</td>\n",
       "      <td>0.965701</td>\n",
       "      <td>-0.031800</td>\n",
       "      <td>0.284619</td>\n",
       "      <td>0.944747</td>\n",
       "      <td>-0.933000</td>\n",
       "      <td>-0.331000</td>\n",
       "      <td>0.233082</td>\n",
       "      <td>-0.327000</td>\n",
       "      <td>-0.134000</td>\n",
       "      <td>0.992719</td>\n",
       "      <td>0.401395</td>\n",
       "      <td>-0.763000</td>\n",
       "      <td>-0.154000</td>\n",
       "      <td>0.998379</td>\n",
       "      <td>-0.477000</td>\n",
       "      <td>0.564174</td>\n",
       "      <td>-0.598000</td>\n",
       "      <td>-0.163000</td>\n",
       "      <td>-0.142000</td>\n",
       "      <td>-0.455000</td>\n",
       "      <td>0.975081</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.782000</td>\n",
       "      <td>-0.028400</td>\n",
       "      <td>-0.005960</td>\n",
       "      <td>-0.177000</td>\n",
       "      <td>-0.403000</td>\n",
       "      <td>0.999162</td>\n",
       "      <td>0.406542</td>\n",
       "      <td>0.363271</td>\n",
       "      <td>-0.937000</td>\n",
       "      <td>-0.876000</td>\n",
       "      <td>-0.148000</td>\n",
       "      <td>0.989989</td>\n",
       "      <td>0.334718</td>\n",
       "      <td>0.354665</td>\n",
       "      <td>-0.251000</td>\n",
       "      <td>0.145622</td>\n",
       "      <td>-0.988000</td>\n",
       "      <td>0.980056</td>\n",
       "      <td>-0.238000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.121417</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.402542</td>\n",
       "      <td>-0.017000</td>\n",
       "      <td>-0.742000</td>\n",
       "      <td>0.240636</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.089865</td>\n",
       "      <td>0.986397</td>\n",
       "      <td>-0.298000</td>\n",
       "      <td>0.660506</td>\n",
       "      <td>0.044545</td>\n",
       "      <td>0.930299</td>\n",
       "      <td>0.284453</td>\n",
       "      <td>-0.187000</td>\n",
       "      <td>-0.102000</td>\n",
       "      <td>0.161273</td>\n",
       "      <td>0.369242</td>\n",
       "      <td>0.217032</td>\n",
       "      <td>0.999583</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.929000</td>\n",
       "      <td>0.216135</td>\n",
       "      <td>-0.988000</td>\n",
       "      <td>-0.823000</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.310128</td>\n",
       "      <td>0.240177</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.391346</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.877162</td>\n",
       "      <td>0.023150</td>\n",
       "      <td>-0.402000</td>\n",
       "      <td>-0.102000</td>\n",
       "      <td>0.373704</td>\n",
       "      <td>0.205379</td>\n",
       "      <td>-0.395000</td>\n",
       "      <td>0.990302</td>\n",
       "      <td>0.339932</td>\n",
       "      <td>0.948025</td>\n",
       "      <td>0.310753</td>\n",
       "      <td>0.547075</td>\n",
       "      <td>-0.216000</td>\n",
       "      <td>0.972217</td>\n",
       "      <td>0.975693</td>\n",
       "      <td>0.127694</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.421407</td>\n",
       "      <td>0.985368</td>\n",
       "      <td>0.999855</td>\n",
       "      <td>0.820924</td>\n",
       "      <td>0.933697</td>\n",
       "      <td>-0.970000</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.324981</td>\n",
       "      <td>-0.861000</td>\n",
       "      <td>0.841761</td>\n",
       "      <td>-0.077300</td>\n",
       "      <td>0.494266</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.148878</td>\n",
       "      <td>-0.934000</td>\n",
       "      <td>0.998717</td>\n",
       "      <td>-0.056300</td>\n",
       "      <td>0.033905</td>\n",
       "      <td>0.413262</td>\n",
       "      <td>0.174543</td>\n",
       "      <td>-0.109000</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.315624</td>\n",
       "      <td>-0.039700</td>\n",
       "      <td>-0.359000</td>\n",
       "      <td>0.110618</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.866000</td>\n",
       "      <td>0.412542</td>\n",
       "      <td>-0.204000</td>\n",
       "      <td>-0.336000</td>\n",
       "      <td>0.087926</td>\n",
       "      <td>0.036314</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.988888</td>\n",
       "      <td>-0.967000</td>\n",
       "      <td>-0.096300</td>\n",
       "      <td>-0.173000</td>\n",
       "      <td>-0.001410</td>\n",
       "      <td>-0.081400</td>\n",
       "      <td>-0.886000</td>\n",
       "      <td>0.983224</td>\n",
       "      <td>-0.960000</td>\n",
       "      <td>-0.219000</td>\n",
       "      <td>-0.224000</td>\n",
       "      <td>-0.310000</td>\n",
       "      <td>-0.213000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>Group_10_99</td>\n",
       "      <td>Group_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993555</td>\n",
       "      <td>-0.806485</td>\n",
       "      <td>-0.221613</td>\n",
       "      <td>-0.055766</td>\n",
       "      <td>-0.722580</td>\n",
       "      <td>0.922490</td>\n",
       "      <td>0.973702</td>\n",
       "      <td>-0.906779</td>\n",
       "      <td>0.162151</td>\n",
       "      <td>-0.974018</td>\n",
       "      <td>0.172568</td>\n",
       "      <td>-0.992739</td>\n",
       "      <td>-0.997850</td>\n",
       "      <td>-0.847709</td>\n",
       "      <td>0.671818</td>\n",
       "      <td>-0.226100</td>\n",
       "      <td>0.081409</td>\n",
       "      <td>0.226553</td>\n",
       "      <td>-0.446694</td>\n",
       "      <td>0.195839</td>\n",
       "      <td>0.139793</td>\n",
       "      <td>-0.215831</td>\n",
       "      <td>0.459237</td>\n",
       "      <td>0.993739</td>\n",
       "      <td>0.785295</td>\n",
       "      <td>0.996511</td>\n",
       "      <td>-0.135805</td>\n",
       "      <td>-0.027017</td>\n",
       "      <td>0.574346</td>\n",
       "      <td>-0.954790</td>\n",
       "      <td>0.878902</td>\n",
       "      <td>0.288012</td>\n",
       "      <td>0.105963</td>\n",
       "      <td>0.270602</td>\n",
       "      <td>-0.998850</td>\n",
       "      <td>0.205840</td>\n",
       "      <td>0.262236</td>\n",
       "      <td>0.343939</td>\n",
       "      <td>0.998299</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>0.241992</td>\n",
       "      <td>-0.061234</td>\n",
       "      <td>0.119233</td>\n",
       "      <td>-0.995245</td>\n",
       "      <td>-0.047621</td>\n",
       "      <td>-0.802699</td>\n",
       "      <td>-0.995225</td>\n",
       "      <td>0.188419</td>\n",
       "      <td>-0.289426</td>\n",
       "      <td>-0.234432</td>\n",
       "      <td>0.975579</td>\n",
       "      <td>-0.324845</td>\n",
       "      <td>0.996910</td>\n",
       "      <td>-0.287194</td>\n",
       "      <td>-0.221748</td>\n",
       "      <td>0.525390</td>\n",
       "      <td>-0.319222</td>\n",
       "      <td>-0.261247</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.987392</td>\n",
       "      <td>-0.206326</td>\n",
       "      <td>-0.236248</td>\n",
       "      <td>0.908935</td>\n",
       "      <td>0.178757</td>\n",
       "      <td>-0.177303</td>\n",
       "      <td>-0.997006</td>\n",
       "      <td>0.996684</td>\n",
       "      <td>-0.539695</td>\n",
       "      <td>-0.454076</td>\n",
       "      <td>0.993184</td>\n",
       "      <td>0.998018</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>-0.561665</td>\n",
       "      <td>-0.945794</td>\n",
       "      <td>0.259743</td>\n",
       "      <td>0.037030</td>\n",
       "      <td>-0.014528</td>\n",
       "      <td>0.997158</td>\n",
       "      <td>-0.022599</td>\n",
       "      <td>0.156143</td>\n",
       "      <td>-0.998311</td>\n",
       "      <td>0.430464</td>\n",
       "      <td>0.997836</td>\n",
       "      <td>0.369956</td>\n",
       "      <td>0.839649</td>\n",
       "      <td>-0.998303</td>\n",
       "      <td>-0.025642</td>\n",
       "      <td>-0.076911</td>\n",
       "      <td>0.033299</td>\n",
       "      <td>0.094056</td>\n",
       "      <td>-0.969405</td>\n",
       "      <td>0.508547</td>\n",
       "      <td>-0.274506</td>\n",
       "      <td>-0.873196</td>\n",
       "      <td>-0.983253</td>\n",
       "      <td>0.997366</td>\n",
       "      <td>0.978435</td>\n",
       "      <td>0.045478</td>\n",
       "      <td>-0.998015</td>\n",
       "      <td>0.059217</td>\n",
       "      <td>-0.791625</td>\n",
       "      <td>-0.979608</td>\n",
       "      <td>-0.991121</td>\n",
       "      <td>0.162023</td>\n",
       "      <td>-0.057041</td>\n",
       "      <td>0.135822</td>\n",
       "      <td>0.962947</td>\n",
       "      <td>-0.101392</td>\n",
       "      <td>-0.143780</td>\n",
       "      <td>-0.987610</td>\n",
       "      <td>-0.022499</td>\n",
       "      <td>-0.611598</td>\n",
       "      <td>0.982917</td>\n",
       "      <td>-0.980967</td>\n",
       "      <td>0.582922</td>\n",
       "      <td>0.294286</td>\n",
       "      <td>-0.824605</td>\n",
       "      <td>0.992247</td>\n",
       "      <td>-0.413502</td>\n",
       "      <td>0.955437</td>\n",
       "      <td>-0.987819</td>\n",
       "      <td>0.337243</td>\n",
       "      <td>-0.998639</td>\n",
       "      <td>-0.233642</td>\n",
       "      <td>0.046098</td>\n",
       "      <td>0.074094</td>\n",
       "      <td>-0.977780</td>\n",
       "      <td>0.123190</td>\n",
       "      <td>0.438497</td>\n",
       "      <td>-0.097966</td>\n",
       "      <td>0.993174</td>\n",
       "      <td>0.945650</td>\n",
       "      <td>0.997868</td>\n",
       "      <td>-0.052251</td>\n",
       "      <td>0.285326</td>\n",
       "      <td>-0.692271</td>\n",
       "      <td>0.998446</td>\n",
       "      <td>-0.992756</td>\n",
       "      <td>-0.997498</td>\n",
       "      <td>0.487509</td>\n",
       "      <td>0.999752</td>\n",
       "      <td>0.050350</td>\n",
       "      <td>-0.236902</td>\n",
       "      <td>0.457237</td>\n",
       "      <td>0.176075</td>\n",
       "      <td>0.996614</td>\n",
       "      <td>-0.758457</td>\n",
       "      <td>0.994513</td>\n",
       "      <td>-0.999639</td>\n",
       "      <td>-0.352789</td>\n",
       "      <td>-0.205283</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.925202</td>\n",
       "      <td>0.047074</td>\n",
       "      <td>0.146677</td>\n",
       "      <td>0.185355</td>\n",
       "      <td>0.997662</td>\n",
       "      <td>-0.132477</td>\n",
       "      <td>-0.182271</td>\n",
       "      <td>0.176097</td>\n",
       "      <td>-0.242447</td>\n",
       "      <td>0.161041</td>\n",
       "      <td>-0.314564</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.020533</td>\n",
       "      <td>-0.024087</td>\n",
       "      <td>-0.223726</td>\n",
       "      <td>0.982762</td>\n",
       "      <td>0.965232</td>\n",
       "      <td>-0.060244</td>\n",
       "      <td>-0.976071</td>\n",
       "      <td>-0.999647</td>\n",
       "      <td>0.981554</td>\n",
       "      <td>0.233144</td>\n",
       "      <td>0.007866</td>\n",
       "      <td>-0.104609</td>\n",
       "      <td>-0.008858</td>\n",
       "      <td>0.994477</td>\n",
       "      <td>0.983536</td>\n",
       "      <td>0.987525</td>\n",
       "      <td>0.232934</td>\n",
       "      <td>0.992889</td>\n",
       "      <td>0.762964</td>\n",
       "      <td>0.085581</td>\n",
       "      <td>-0.700913</td>\n",
       "      <td>-0.999288</td>\n",
       "      <td>0.092549</td>\n",
       "      <td>0.330552</td>\n",
       "      <td>0.977486</td>\n",
       "      <td>0.971425</td>\n",
       "      <td>-0.985275</td>\n",
       "      <td>-0.495316</td>\n",
       "      <td>-0.257995</td>\n",
       "      <td>0.987276</td>\n",
       "      <td>-0.039791</td>\n",
       "      <td>-0.877627</td>\n",
       "      <td>-0.948685</td>\n",
       "      <td>0.391427</td>\n",
       "      <td>0.270121</td>\n",
       "      <td>0.244885</td>\n",
       "      <td>-0.683268</td>\n",
       "      <td>-0.987551</td>\n",
       "      <td>-0.105522</td>\n",
       "      <td>-0.105962</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.050711</td>\n",
       "      <td>0.999712</td>\n",
       "      <td>0.997492</td>\n",
       "      <td>-0.006787</td>\n",
       "      <td>0.836617</td>\n",
       "      <td>0.966313</td>\n",
       "      <td>-0.148427</td>\n",
       "      <td>-0.018599</td>\n",
       "      <td>0.976537</td>\n",
       "      <td>-0.993428</td>\n",
       "      <td>-0.998126</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>-0.604048</td>\n",
       "      <td>-0.093745</td>\n",
       "      <td>-0.994025</td>\n",
       "      <td>-0.220823</td>\n",
       "      <td>-0.994958</td>\n",
       "      <td>0.117252</td>\n",
       "      <td>-0.747237</td>\n",
       "      <td>-0.160889</td>\n",
       "      <td>-0.991224</td>\n",
       "      <td>0.290096</td>\n",
       "      <td>-0.132550</td>\n",
       "      <td>0.984738</td>\n",
       "      <td>0.018223</td>\n",
       "      <td>-0.135954</td>\n",
       "      <td>0.263565</td>\n",
       "      <td>-0.084759</td>\n",
       "      <td>0.997634</td>\n",
       "      <td>-0.351718</td>\n",
       "      <td>-0.914998</td>\n",
       "      <td>0.154713</td>\n",
       "      <td>0.192087</td>\n",
       "      <td>0.150106</td>\n",
       "      <td>0.489156</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.183250</td>\n",
       "      <td>0.999463</td>\n",
       "      <td>-0.908273</td>\n",
       "      <td>0.282874</td>\n",
       "      <td>0.999759</td>\n",
       "      <td>0.335690</td>\n",
       "      <td>0.966692</td>\n",
       "      <td>-0.434366</td>\n",
       "      <td>-0.061198</td>\n",
       "      <td>-0.071863</td>\n",
       "      <td>-0.083151</td>\n",
       "      <td>-0.099671</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>0.027773</td>\n",
       "      <td>0.273080</td>\n",
       "      <td>-0.995230</td>\n",
       "      <td>-0.138413</td>\n",
       "      <td>-0.042460</td>\n",
       "      <td>-0.679780</td>\n",
       "      <td>-0.998105</td>\n",
       "      <td>-0.068644</td>\n",
       "      <td>0.032080</td>\n",
       "      <td>0.140456</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>0.999846</td>\n",
       "      <td>-0.940688</td>\n",
       "      <td>0.259593</td>\n",
       "      <td>0.269545</td>\n",
       "      <td>0.996739</td>\n",
       "      <td>0.123518</td>\n",
       "      <td>-0.997418</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>-0.129450</td>\n",
       "      <td>-0.929186</td>\n",
       "      <td>0.974012</td>\n",
       "      <td>-0.001645</td>\n",
       "      <td>-0.808354</td>\n",
       "      <td>-0.114893</td>\n",
       "      <td>-0.608060</td>\n",
       "      <td>-0.993053</td>\n",
       "      <td>-0.051044</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.408360</td>\n",
       "      <td>0.179336</td>\n",
       "      <td>0.491992</td>\n",
       "      <td>0.206420</td>\n",
       "      <td>-0.998458</td>\n",
       "      <td>-0.998746</td>\n",
       "      <td>-0.771610</td>\n",
       "      <td>-0.031196</td>\n",
       "      <td>0.502469</td>\n",
       "      <td>0.952788</td>\n",
       "      <td>0.994429</td>\n",
       "      <td>-0.997483</td>\n",
       "      <td>0.242725</td>\n",
       "      <td>0.923144</td>\n",
       "      <td>0.174193</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>-0.996836</td>\n",
       "      <td>0.382523</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.178281</td>\n",
       "      <td>0.184382</td>\n",
       "      <td>-0.302208</td>\n",
       "      <td>0.994569</td>\n",
       "      <td>-0.987053</td>\n",
       "      <td>0.307194</td>\n",
       "      <td>0.103798</td>\n",
       "      <td>0.552196</td>\n",
       "      <td>0.097548</td>\n",
       "      <td>0.816593</td>\n",
       "      <td>0.963246</td>\n",
       "      <td>0.311863</td>\n",
       "      <td>0.054469</td>\n",
       "      <td>-0.177031</td>\n",
       "      <td>-0.190743</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>-0.143514</td>\n",
       "      <td>-0.158788</td>\n",
       "      <td>-0.047902</td>\n",
       "      <td>-0.986135</td>\n",
       "      <td>0.348546</td>\n",
       "      <td>0.075210</td>\n",
       "      <td>-0.934432</td>\n",
       "      <td>0.836547</td>\n",
       "      <td>-0.525250</td>\n",
       "      <td>0.932744</td>\n",
       "      <td>0.391139</td>\n",
       "      <td>-0.120745</td>\n",
       "      <td>-0.328195</td>\n",
       "      <td>0.738342</td>\n",
       "      <td>-0.270251</td>\n",
       "      <td>-0.186684</td>\n",
       "      <td>-0.277560</td>\n",
       "      <td>0.765908</td>\n",
       "      <td>0.914064</td>\n",
       "      <td>0.417545</td>\n",
       "      <td>0.908767</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>-0.077439</td>\n",
       "      <td>0.973321</td>\n",
       "      <td>-0.495565</td>\n",
       "      <td>0.967346</td>\n",
       "      <td>-0.218443</td>\n",
       "      <td>0.811849</td>\n",
       "      <td>0.328866</td>\n",
       "      <td>0.994861</td>\n",
       "      <td>-0.212514</td>\n",
       "      <td>-0.210815</td>\n",
       "      <td>0.855013</td>\n",
       "      <td>-0.107762</td>\n",
       "      <td>-0.805101</td>\n",
       "      <td>-0.282929</td>\n",
       "      <td>-0.982227</td>\n",
       "      <td>0.103752</td>\n",
       "      <td>0.248123</td>\n",
       "      <td>-0.247725</td>\n",
       "      <td>-0.917273</td>\n",
       "      <td>0.939347</td>\n",
       "      <td>-0.438405</td>\n",
       "      <td>-0.302731</td>\n",
       "      <td>0.571255</td>\n",
       "      <td>-0.997710</td>\n",
       "      <td>0.884101</td>\n",
       "      <td>0.162021</td>\n",
       "      <td>-0.112181</td>\n",
       "      <td>0.183855</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>0.582215</td>\n",
       "      <td>0.117205</td>\n",
       "      <td>-0.255009</td>\n",
       "      <td>0.978362</td>\n",
       "      <td>-0.998241</td>\n",
       "      <td>-0.050235</td>\n",
       "      <td>-0.350103</td>\n",
       "      <td>0.202121</td>\n",
       "      <td>0.018535</td>\n",
       "      <td>0.980579</td>\n",
       "      <td>0.056348</td>\n",
       "      <td>-0.999834</td>\n",
       "      <td>0.329096</td>\n",
       "      <td>0.968031</td>\n",
       "      <td>-0.842781</td>\n",
       "      <td>0.297022</td>\n",
       "      <td>-0.451640</td>\n",
       "      <td>-0.591060</td>\n",
       "      <td>0.230832</td>\n",
       "      <td>0.086729</td>\n",
       "      <td>0.695167</td>\n",
       "      <td>-0.999940</td>\n",
       "      <td>-0.199494</td>\n",
       "      <td>-0.090790</td>\n",
       "      <td>-0.276009</td>\n",
       "      <td>-0.326347</td>\n",
       "      <td>-0.013146</td>\n",
       "      <td>0.927860</td>\n",
       "      <td>-0.051925</td>\n",
       "      <td>0.211471</td>\n",
       "      <td>-0.996866</td>\n",
       "      <td>-0.998621</td>\n",
       "      <td>-0.038820</td>\n",
       "      <td>0.961117</td>\n",
       "      <td>-0.081699</td>\n",
       "      <td>0.993020</td>\n",
       "      <td>0.152697</td>\n",
       "      <td>-0.197617</td>\n",
       "      <td>-0.732109</td>\n",
       "      <td>0.979181</td>\n",
       "      <td>0.595306</td>\n",
       "      <td>-0.998264</td>\n",
       "      <td>-0.025770</td>\n",
       "      <td>-0.997552</td>\n",
       "      <td>0.229365</td>\n",
       "      <td>0.146171</td>\n",
       "      <td>-0.920912</td>\n",
       "      <td>-0.481030</td>\n",
       "      <td>-0.999671</td>\n",
       "      <td>0.211468</td>\n",
       "      <td>0.992738</td>\n",
       "      <td>-0.369775</td>\n",
       "      <td>0.894887</td>\n",
       "      <td>-0.024157</td>\n",
       "      <td>-0.994591</td>\n",
       "      <td>-0.214546</td>\n",
       "      <td>-0.006333</td>\n",
       "      <td>-0.199811</td>\n",
       "      <td>-0.165532</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>-0.229808</td>\n",
       "      <td>0.994126</td>\n",
       "      <td>-0.999897</td>\n",
       "      <td>-0.862203</td>\n",
       "      <td>0.337109</td>\n",
       "      <td>-0.919005</td>\n",
       "      <td>0.542583</td>\n",
       "      <td>-0.163110</td>\n",
       "      <td>0.194815</td>\n",
       "      <td>-0.016603</td>\n",
       "      <td>-0.983116</td>\n",
       "      <td>0.436810</td>\n",
       "      <td>0.552288</td>\n",
       "      <td>-0.998427</td>\n",
       "      <td>-0.987024</td>\n",
       "      <td>-0.006685</td>\n",
       "      <td>0.372734</td>\n",
       "      <td>0.159917</td>\n",
       "      <td>0.054467</td>\n",
       "      <td>-0.256975</td>\n",
       "      <td>-0.289996</td>\n",
       "      <td>-0.111987</td>\n",
       "      <td>0.991884</td>\n",
       "      <td>-0.402949</td>\n",
       "      <td>0.985482</td>\n",
       "      <td>-0.135595</td>\n",
       "      <td>-0.184385</td>\n",
       "      <td>0.133085</td>\n",
       "      <td>0.893717</td>\n",
       "      <td>0.473543</td>\n",
       "      <td>-0.034678</td>\n",
       "      <td>-0.999706</td>\n",
       "      <td>0.320707</td>\n",
       "      <td>0.738357</td>\n",
       "      <td>0.996846</td>\n",
       "      <td>0.568701</td>\n",
       "      <td>0.994903</td>\n",
       "      <td>-0.999387</td>\n",
       "      <td>0.383925</td>\n",
       "      <td>0.062153</td>\n",
       "      <td>-0.492315</td>\n",
       "      <td>-0.287153</td>\n",
       "      <td>-0.244908</td>\n",
       "      <td>0.315129</td>\n",
       "      <td>-0.999380</td>\n",
       "      <td>-0.995197</td>\n",
       "      <td>0.127385</td>\n",
       "      <td>-0.988414</td>\n",
       "      <td>0.943812</td>\n",
       "      <td>-0.026681</td>\n",
       "      <td>-0.152489</td>\n",
       "      <td>0.615243</td>\n",
       "      <td>0.262883</td>\n",
       "      <td>0.348678</td>\n",
       "      <td>-0.999666</td>\n",
       "      <td>-0.997261</td>\n",
       "      <td>-0.186937</td>\n",
       "      <td>-0.353943</td>\n",
       "      <td>-0.197295</td>\n",
       "      <td>0.088398</td>\n",
       "      <td>-0.997083</td>\n",
       "      <td>-0.996905</td>\n",
       "      <td>0.987672</td>\n",
       "      <td>0.156175</td>\n",
       "      <td>-0.267036</td>\n",
       "      <td>0.159746</td>\n",
       "      <td>0.322282</td>\n",
       "      <td>-0.996291</td>\n",
       "      <td>0.999796</td>\n",
       "      <td>-0.969733</td>\n",
       "      <td>-0.260363</td>\n",
       "      <td>-0.487101</td>\n",
       "      <td>-0.198966</td>\n",
       "      <td>-0.363342</td>\n",
       "      <td>-0.879410</td>\n",
       "      <td>0.998646</td>\n",
       "      <td>-0.999864</td>\n",
       "      <td>-0.173692</td>\n",
       "      <td>0.204035</td>\n",
       "      <td>-0.570824</td>\n",
       "      <td>-0.437862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1822 rows  533 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       utteranceID     Group  CPS_CONST_SharesU_Situation  \\\n",
       "0       Group_01_0  Group_01                          NaN   \n",
       "1       Group_01_1  Group_01                          NaN   \n",
       "2      Group_01_10  Group_01                          1.0   \n",
       "3     Group_01_100  Group_01                          NaN   \n",
       "4     Group_01_101  Group_01                          NaN   \n",
       "...            ...       ...                          ...   \n",
       "1817   Group_10_95  Group_10                          NaN   \n",
       "1818   Group_10_96  Group_10                          NaN   \n",
       "1819   Group_10_97  Group_10                          NaN   \n",
       "1820   Group_10_98  Group_10                          NaN   \n",
       "1821   Group_10_99  Group_10                          NaN   \n",
       "\n",
       "      CPS_CONST_SharesU_CorrectSolutions  \\\n",
       "0                                    NaN   \n",
       "1                                    NaN   \n",
       "2                                    NaN   \n",
       "3                                    NaN   \n",
       "4                                    NaN   \n",
       "...                                  ...   \n",
       "1817                                 NaN   \n",
       "1818                                 NaN   \n",
       "1819                                 NaN   \n",
       "1820                                 1.0   \n",
       "1821                                 NaN   \n",
       "\n",
       "      CPS_CONST_SharesU_IncorrectSolutions  CPS_CONST_EstablishesCG_Confirms  \\\n",
       "0                                      NaN                               NaN   \n",
       "1                                      NaN                               NaN   \n",
       "2                                      NaN                               NaN   \n",
       "3                                      NaN                               NaN   \n",
       "4                                      NaN                               NaN   \n",
       "...                                    ...                               ...   \n",
       "1817                                   NaN                               NaN   \n",
       "1818                                   NaN                               1.0   \n",
       "1819                                   NaN                               NaN   \n",
       "1820                                   NaN                               1.0   \n",
       "1821                                   NaN                               NaN   \n",
       "\n",
       "      CPS_CONST_EstablishesCG_Interrupts  CPS_NEG_Responds_Reasons  \\\n",
       "0                                    NaN                       NaN   \n",
       "1                                    NaN                       NaN   \n",
       "2                                    NaN                       NaN   \n",
       "3                                    NaN                       NaN   \n",
       "4                                    NaN                       NaN   \n",
       "...                                  ...                       ...   \n",
       "1817                                 NaN                       NaN   \n",
       "1818                                 NaN                       NaN   \n",
       "1819                                 NaN                       1.0   \n",
       "1820                                 NaN                       NaN   \n",
       "1821                                 NaN                       NaN   \n",
       "\n",
       "      CPS_NEG_Responds_QuestionsOthers  CPS_NEG_Responds_Responds  \\\n",
       "0                                  NaN                        NaN   \n",
       "1                                  NaN                        NaN   \n",
       "2                                  NaN                        NaN   \n",
       "3                                  NaN                        NaN   \n",
       "4                                  NaN                        1.0   \n",
       "...                                ...                        ...   \n",
       "1817                               NaN                        NaN   \n",
       "1818                               NaN                        1.0   \n",
       "1819                               NaN                        NaN   \n",
       "1820                               NaN                        NaN   \n",
       "1821                               NaN                        NaN   \n",
       "\n",
       "      CPS_NEG_MonitorsE_Results  CPS_NEG_MonitorsE_Strategizes  \\\n",
       "0                           NaN                            NaN   \n",
       "1                           NaN                            NaN   \n",
       "2                           NaN                            NaN   \n",
       "3                           NaN                            NaN   \n",
       "4                           NaN                            NaN   \n",
       "...                         ...                            ...   \n",
       "1817                        1.0                            NaN   \n",
       "1818                        1.0                            NaN   \n",
       "1819                        NaN                            NaN   \n",
       "1820                        NaN                            NaN   \n",
       "1821                        NaN                            NaN   \n",
       "\n",
       "      CPS_NEG_MonitorsE_Save  CPS_NEG_MonitorsE_GivingUp  \\\n",
       "0                        NaN                         NaN   \n",
       "1                        NaN                         NaN   \n",
       "2                        NaN                         NaN   \n",
       "3                        NaN                         NaN   \n",
       "4                        NaN                         NaN   \n",
       "...                      ...                         ...   \n",
       "1817                     NaN                         NaN   \n",
       "1818                     NaN                         NaN   \n",
       "1819                     NaN                         NaN   \n",
       "1820                     NaN                         NaN   \n",
       "1821                     NaN                         NaN   \n",
       "\n",
       "      CPS_MAINTAIN_Initiative_Suggestions  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                     NaN   \n",
       "3                                     NaN   \n",
       "4                                     NaN   \n",
       "...                                   ...   \n",
       "1817                                  NaN   \n",
       "1818                                  NaN   \n",
       "1819                                  1.0   \n",
       "1820                                  NaN   \n",
       "1821                                  NaN   \n",
       "\n",
       "      CPS_MAINTAIN_Initiative_Compliments  CPS_MAINTAIN_Initiative_Criticizes  \\\n",
       "0                                     NaN                                 NaN   \n",
       "1                                     NaN                                 NaN   \n",
       "2                                     NaN                                 NaN   \n",
       "3                                     NaN                                 NaN   \n",
       "4                                     1.0                                 NaN   \n",
       "...                                   ...                                 ...   \n",
       "1817                                  NaN                                 NaN   \n",
       "1818                                  NaN                                 NaN   \n",
       "1819                                  1.0                                 NaN   \n",
       "1820                                  NaN                                 NaN   \n",
       "1821                                  NaN                                 NaN   \n",
       "\n",
       "      CPS_MAINTAIN_FulfillsR_Support  CPS_MAINTAIN_FulfillsR_Apologizes  \\\n",
       "0                                NaN                                NaN   \n",
       "1                                NaN                                NaN   \n",
       "2                                NaN                                NaN   \n",
       "3                                NaN                                NaN   \n",
       "4                                NaN                                NaN   \n",
       "...                              ...                                ...   \n",
       "1817                             NaN                                NaN   \n",
       "1818                             NaN                                NaN   \n",
       "1819                             1.0                                NaN   \n",
       "1820                             NaN                                NaN   \n",
       "1821                             NaN                                NaN   \n",
       "\n",
       "      CPS_MAINTAIN_FulfillsR_InitiatesOffTopic  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "...                                        ...   \n",
       "1817                                       NaN   \n",
       "1818                                       NaN   \n",
       "1819                                       NaN   \n",
       "1820                                       NaN   \n",
       "1821                                       NaN   \n",
       "\n",
       "      CPS_MAINTAIN_FulfillsR_JoinsOffTopic    bert_0    bert_1    bert_2  \\\n",
       "0                                      NaN  0.993518  0.365759 -0.108810   \n",
       "1                                      NaN  0.992203 -0.195000 -0.025400   \n",
       "2                                      NaN  0.990013  0.750048 -0.134000   \n",
       "3                                      NaN  0.996965 -0.983000 -0.458000   \n",
       "4                                      NaN  0.995743  0.968646  0.201253   \n",
       "...                                    ...       ...       ...       ...   \n",
       "1817                                   NaN  0.998164  0.837999  0.328195   \n",
       "1818                                   NaN  0.976472  0.966214  0.092994   \n",
       "1819                                   NaN  0.996249  0.850641 -0.034200   \n",
       "1820                                   NaN  0.992738 -0.303000  0.015695   \n",
       "1821                                   NaN  0.993555 -0.806485 -0.221613   \n",
       "\n",
       "        bert_3    bert_4    bert_5    bert_6    bert_7    bert_8    bert_9  \\\n",
       "0     0.422874  0.451778  0.961461  0.710460 -0.999845 -0.267417 -0.999266   \n",
       "1     0.008844 -0.044000  0.991036  0.992010 -0.993000 -0.208000 -1.000000   \n",
       "2     0.130585  0.618464  0.944665  0.338610 -0.998000 -0.020900 -0.993000   \n",
       "3    -0.137000 -0.737000  0.980881  0.999139 -0.937000 -0.389000 -0.998000   \n",
       "4    -0.130489  0.660496  0.997078  0.983218 -0.944374 -0.262219 -0.999788   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.141000 -0.036300  0.936739  0.952660 -0.995000 -0.424000 -1.000000   \n",
       "1818  0.181245 -0.177000  0.958835  0.579420 -0.995000  0.030277 -0.988000   \n",
       "1819  0.275094  0.378156  0.892405  0.817468 -0.987000 -0.201000 -0.999000   \n",
       "1820  0.271703  0.517016  0.977484  0.922489 -0.982000 -0.061300 -0.998000   \n",
       "1821 -0.055766 -0.722580  0.922490  0.973702 -0.906779  0.162151 -0.974018   \n",
       "\n",
       "       bert_10   bert_11   bert_12   bert_13   bert_14   bert_15   bert_16  \\\n",
       "0     0.270915 -0.997165 -0.973942 -0.998901  0.051721  0.175755 -0.139673   \n",
       "1     0.237743 -0.960000 -0.981000 -0.984000  0.431453  0.012080  0.112708   \n",
       "2     0.040928 -0.988000  0.375986 -0.993000 -0.391000  0.015971 -0.273000   \n",
       "3    -0.034400 -0.990000 -1.000000 -0.679000 -0.284000 -0.231000  0.105658   \n",
       "4     0.322809 -0.978609 -0.682756 -0.994339  0.820431 -0.037593 -0.123590   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.094815 -0.983000 -0.992000 -0.988000  0.779980  0.072198 -0.226000   \n",
       "1818  0.119164 -0.979000 -0.050900 -0.997000  0.217856  0.368915 -0.214000   \n",
       "1819  0.107625 -0.988000  0.250781 -0.992000 -0.493000  0.269503 -0.304000   \n",
       "1820 -0.014900 -0.961000 -0.830000 -0.994000  0.752070  0.292949 -0.102000   \n",
       "1821  0.172568 -0.992739 -0.997850 -0.847709  0.671818 -0.226100  0.081409   \n",
       "\n",
       "       bert_17   bert_18   bert_19   bert_20   bert_21   bert_22   bert_23  \\\n",
       "0     0.104318 -0.272146  0.394232 -0.152230 -0.302303  0.799073  0.944860   \n",
       "1    -0.346000  0.021867  0.296921  0.024934 -0.378000  0.021184  0.985416   \n",
       "2     0.543410 -0.631000 -0.198000  0.263983 -0.381000 -0.232000  0.517442   \n",
       "3     0.381090 -0.580000  0.431569  0.045249 -0.455000  0.555593  0.957810   \n",
       "4     0.404065  0.078757  0.146876 -0.185831  0.095608  0.775757  0.955985   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.323816 -0.353000  0.125301 -0.311000 -0.236000 -0.192000  0.998721   \n",
       "1818  0.008805 -0.400000 -0.111000 -0.021200 -0.106000 -0.135000  0.962444   \n",
       "1819  0.056290 -0.042600  0.012566 -0.006050 -0.005230 -0.940000  0.802912   \n",
       "1820  0.027236 -0.384000  0.009468  0.259648  0.057584 -0.110000  0.980436   \n",
       "1821  0.226553 -0.446694  0.195839  0.139793 -0.215831  0.459237  0.993739   \n",
       "\n",
       "       bert_24   bert_25   bert_26   bert_27   bert_28   bert_29   bert_30  \\\n",
       "0     0.993572  0.998466  0.061202  0.003223  0.302294  0.534748  0.999390   \n",
       "1     0.994567  0.998374 -0.254000 -0.190000  0.275593 -0.170000  0.996735   \n",
       "2     0.999072  0.976915 -0.173000 -0.012100  0.351231  0.745242  0.998227   \n",
       "3     0.988089  0.977598 -0.045200 -0.305000  0.696800 -0.645000  0.997460   \n",
       "4     0.992306  0.979023 -0.123651 -0.009293  0.159130 -0.399745  0.984169   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.996508  0.994635 -0.349000 -0.123000  0.343994 -0.945000  0.975559   \n",
       "1818  0.997855  0.993624 -0.454000  0.176624 -0.134000  0.609526  0.986281   \n",
       "1819  0.999335  0.999003  0.400539 -0.164000  0.042764  0.764451  0.996090   \n",
       "1820  0.988972  0.998248  0.160122 -0.172000  0.333261  0.461619  0.993170   \n",
       "1821  0.785295  0.996511 -0.135805 -0.027017  0.574346 -0.954790  0.878902   \n",
       "\n",
       "       bert_31   bert_32   bert_33   bert_34   bert_35   bert_36   bert_37  \\\n",
       "0     0.147512  0.389890  0.041206 -0.996541  0.532553  0.011078 -0.091283   \n",
       "1    -0.350000  0.354280  0.248492 -0.952000 -0.225000 -0.060400 -0.070000   \n",
       "2     0.103937  0.075398  0.270600 -0.999000  0.296710  0.091600 -0.386000   \n",
       "3     0.080209  0.236457  0.154092 -0.986000  0.168325  0.122909 -0.017600   \n",
       "4    -0.245010  0.499372  0.088424 -0.947444  0.030557 -0.382831 -0.212737   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.027298  0.446313  0.317386 -0.901000  0.086433 -0.173000 -0.152000   \n",
       "1818  0.193663  0.350466  0.074822 -0.950000  0.196402 -0.364000 -0.216000   \n",
       "1819 -0.292000  0.556738 -0.022600 -0.993000  0.339236 -0.393000 -0.087100   \n",
       "1820  0.100335  0.327036  0.315734 -0.994000  0.190597 -0.010800 -0.412000   \n",
       "1821  0.288012  0.105963  0.270602 -0.998850  0.205840  0.262236  0.343939   \n",
       "\n",
       "       bert_38   bert_39   bert_40   bert_41   bert_42   bert_43   bert_44  \\\n",
       "0     0.984499  0.367115  0.044604  0.076422  0.008113 -0.999874  0.139501   \n",
       "1     0.977625  0.337965 -0.102000 -0.054500 -0.187000 -0.991000 -0.354000   \n",
       "2     0.920225  0.036674  0.256350  0.224223  0.099948 -0.999000  0.041984   \n",
       "3     0.999633 -0.353000 -0.328000  0.205288  0.112366 -0.998000 -0.058500   \n",
       "4     0.885396 -0.101708  0.113619  0.197190 -0.097353 -0.982655 -0.161342   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.901178 -0.109000  0.178331 -0.575000 -0.004610 -0.993000 -0.119000   \n",
       "1818  0.947507  0.036632  0.442075 -0.061300  0.381139 -0.994000  0.289471   \n",
       "1819  0.967174  0.069377 -0.057600  0.095174  0.174192 -0.995000 -0.133000   \n",
       "1820  0.826586  0.135248  0.202276 -0.017100  0.073677 -0.999000 -0.317000   \n",
       "1821  0.998299  0.005737  0.241992 -0.061234  0.119233 -0.995245 -0.047621   \n",
       "\n",
       "       bert_45   bert_46   bert_47   bert_48   bert_49   bert_50   bert_51  \\\n",
       "0     0.069888 -0.896454  0.300547  0.390984 -0.150038  0.977756 -0.266266   \n",
       "1    -0.620000 -0.988000 -0.407000 -0.444000 -0.493000  0.998378 -0.190000   \n",
       "2     0.582943 -0.979000  0.264309  0.093355  0.125059  0.986786 -0.032100   \n",
       "3    -0.387000 -0.994000 -0.329000 -0.211000 -0.192000  0.993463  0.000403   \n",
       "4    -0.513724 -0.911314  0.244650  0.378630 -0.484025  0.997927 -0.031844   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.441000 -0.881000  0.418277  0.841193 -0.648000  0.995623 -0.118000   \n",
       "1818  0.496096 -0.952000  0.311688  0.506335 -0.222000  0.996973  0.106532   \n",
       "1819 -0.248000 -0.994000  0.101304  0.657507 -0.262000  0.994555 -0.058600   \n",
       "1820 -0.640000 -0.620000 -0.003270 -0.099200 -0.392000  0.905579 -0.024400   \n",
       "1821 -0.802699 -0.995225  0.188419 -0.289426 -0.234432  0.975579 -0.324845   \n",
       "\n",
       "       bert_52   bert_53   bert_54   bert_55   bert_56   bert_57   bert_58  \\\n",
       "0     0.999803  0.006934  0.485656  0.362324  0.187488  0.141071 -0.999607   \n",
       "1     0.999699 -0.293000 -0.133000  0.190672  0.272142 -0.361000 -1.000000   \n",
       "2     0.989188 -0.175000 -0.177000 -0.022700 -0.393000  0.350795 -1.000000   \n",
       "3     0.999516 -0.204000 -0.671000  0.425997  0.068917 -0.555000 -1.000000   \n",
       "4     0.997691 -0.243873  0.463397  0.172776 -0.029568  0.233584 -0.999705   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.997187 -0.448000 -0.144000  0.444532  0.057495 -0.152000 -1.000000   \n",
       "1818  0.998081 -0.042100  0.382375  0.168536 -0.165000 -0.201000 -0.999000   \n",
       "1819  0.999810  0.065108  0.737731  0.219697  0.135541  0.195049 -1.000000   \n",
       "1820  0.999746  0.252376  0.740984  0.512058  0.033735 -0.253000 -1.000000   \n",
       "1821  0.996910 -0.287194 -0.221748  0.525390 -0.319222 -0.261247 -0.999991   \n",
       "\n",
       "       bert_59   bert_60   bert_61   bert_62   bert_63   bert_64   bert_65  \\\n",
       "0    -0.987854  0.112721 -0.516108  0.996057 -0.025922  0.009192 -0.973916   \n",
       "1    -0.998000  0.229848  0.308777  0.989184  0.080059  0.342320 -0.992000   \n",
       "2    -0.998000 -0.090400  0.001656  0.988602  0.316577 -0.130000 -0.998000   \n",
       "3    -0.985000 -0.316000 -0.115000  0.791934  0.333388  0.185355 -0.997000   \n",
       "4    -0.999385  0.357327  0.059951  0.998593  0.072189 -0.170197 -0.644919   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -1.000000  0.306473  0.299349  0.992467  0.105458  0.015742 -0.999000   \n",
       "1818 -0.994000  0.086901  0.134899  0.993853  0.352979 -0.103000 -0.996000   \n",
       "1819 -0.961000 -0.096900 -0.445000  0.990518 -0.014600 -0.065200 -0.995000   \n",
       "1820 -0.993000  0.150639 -0.342000  0.999340  0.529865 -0.036600 -0.984000   \n",
       "1821 -0.987392 -0.206326 -0.236248  0.908935  0.178757 -0.177303 -0.997006   \n",
       "\n",
       "       bert_66   bert_67   bert_68   bert_69   bert_70   bert_71   bert_72  \\\n",
       "0     0.999949  0.910910 -0.237158 -0.162820  0.980844  0.999961 -0.930536   \n",
       "1     0.999421  0.671315 -0.386000  0.945902  0.999461  0.999767 -0.388000   \n",
       "2     0.989132  0.732761 -0.263000 -0.849000  0.978371  0.999881 -0.949000   \n",
       "3     0.999400  0.284351 -0.577000  0.997611  0.998764  0.999493 -0.589000   \n",
       "4     0.987329  0.302567 -0.302503  0.412640  0.400185  0.999630 -0.552906   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.996081  0.440762 -0.315000  0.949951  0.998096  0.999872 -0.597000   \n",
       "1818  0.997485  0.742126  0.144698  0.264214  0.995406  0.999919 -0.920000   \n",
       "1819  0.969650  0.874684 -0.246000 -0.347000  0.998312  0.999427 -0.864000   \n",
       "1820  0.992775  0.882539 -0.416000  0.512314  0.946722  0.999992 -0.731000   \n",
       "1821  0.996684 -0.539695 -0.454076  0.993184  0.998018  0.999978 -0.561665   \n",
       "\n",
       "       bert_73   bert_74   bert_75   bert_76   bert_77   bert_78   bert_79  \\\n",
       "0    -0.761945 -0.956196 -0.127413 -0.054906  0.988883  0.268531 -0.136805   \n",
       "1    -0.856000 -0.879000  0.085517  0.411025  0.983853 -0.341000 -0.013800   \n",
       "2    -0.661000 -0.797000 -0.352000 -0.220000  0.998991  0.008501  0.249850   \n",
       "3    -0.712000 -0.959000  0.180407  0.472433  0.971119  0.170162 -0.154000   \n",
       "4    -0.238550 -0.814861 -0.376764  0.160603  0.990453 -0.178612 -0.335091   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.410000 -0.842000 -0.021400  0.272003  0.998283 -0.101000 -0.389000   \n",
       "1818 -0.881000 -0.582000 -0.019800 -0.301000  0.997304 -0.148000 -0.321000   \n",
       "1819 -0.880000 -0.939000 -0.113000 -0.526000  0.996681 -0.045100 -0.578000   \n",
       "1820 -0.786000 -0.913000  0.101972 -0.369000  0.999079 -0.059900 -0.707000   \n",
       "1821 -0.945794  0.259743  0.037030 -0.014528  0.997158 -0.022599  0.156143   \n",
       "\n",
       "       bert_80   bert_81   bert_82   bert_83   bert_84   bert_85   bert_86  \\\n",
       "0    -0.999541  0.226200  0.996731 -0.699441  0.990424 -0.999233  0.085551   \n",
       "1    -0.997000 -0.186000  0.953507 -0.249000  0.985975 -0.997000  0.181870   \n",
       "2    -0.999000  0.238930  0.996669  0.129989  0.979419 -0.999000 -0.038700   \n",
       "3    -0.999000 -0.041200  0.986258  0.027472  0.927011 -0.894000  0.183809   \n",
       "4    -0.990137  0.209123  0.896167  0.512388  0.817216 -0.999915  0.148945   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.999000  0.029767  0.950294  0.106504  0.844047 -0.998000 -0.276000   \n",
       "1818 -0.988000  0.185159  0.948530 -0.095600  0.992312 -0.998000  0.015077   \n",
       "1819 -0.704000 -0.011400  0.981035  0.087866  0.995233 -1.000000 -0.254000   \n",
       "1820 -0.999000 -0.116000  0.999572 -0.656000  0.986333 -1.000000 -0.022900   \n",
       "1821 -0.998311  0.430464  0.997836  0.369956  0.839649 -0.998303 -0.025642   \n",
       "\n",
       "       bert_87   bert_88   bert_89   bert_90   bert_91   bert_92   bert_93  \\\n",
       "0     0.185651 -0.295660 -0.306530 -0.989447 -0.117240 -0.025444 -0.998039   \n",
       "1     0.249904 -0.025600  0.153448 -0.994000 -0.148000  0.465504 -0.992000   \n",
       "2     0.275069 -0.079500 -0.296000 -0.985000  0.032675  0.181985 -0.985000   \n",
       "3     0.019951 -0.474000  0.046255 -0.989000  0.408095  0.713163 -0.979000   \n",
       "4     0.487519 -0.185967 -0.166836 -0.953491  0.100383  0.348470 -0.782110   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.307516  0.186420  0.156688 -0.974000  0.125469  0.406732 -0.983000   \n",
       "1818  0.345219  0.100997 -0.250000 -0.994000 -0.062600  0.056335 -0.659000   \n",
       "1819  0.216205 -0.359000  0.016856 -0.997000 -0.308000 -0.113000 -0.993000   \n",
       "1820  0.184245 -0.434000  0.348432 -0.994000 -0.518000 -0.115000 -0.728000   \n",
       "1821 -0.076911  0.033299  0.094056 -0.969405  0.508547 -0.274506 -0.873196   \n",
       "\n",
       "       bert_94   bert_95   bert_96   bert_97   bert_98   bert_99  bert_100  \\\n",
       "0    -0.448954  0.784459  0.995247  0.338093 -0.999861 -0.182477 -0.961148   \n",
       "1    -0.964000  0.460726  0.991903  0.150491 -0.996000 -0.438000 -0.922000   \n",
       "2    -0.660000 -0.832000  0.995754  0.157598 -0.994000  0.114108 -0.705000   \n",
       "3    -0.990000  0.982813  0.959628 -0.175000 -0.994000 -0.040300 -0.978000   \n",
       "4     0.309654  0.640323  0.991681  0.159908 -0.986159 -0.401578 -0.784815   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.746000  0.735499  0.988801  0.039924 -0.998000 -0.300000 -0.987000   \n",
       "1818 -0.434000 -0.657000  0.995046  0.423368 -0.999000 -0.232000  0.027411   \n",
       "1819 -0.936000 -0.631000  0.988966  0.268401 -0.996000 -0.126000  0.350839   \n",
       "1820  0.503660  0.250528  0.999652  0.320982 -0.994000 -0.209000 -0.956000   \n",
       "1821 -0.983253  0.997366  0.978435  0.045478 -0.998015  0.059217 -0.791625   \n",
       "\n",
       "      bert_101  bert_102  bert_103  bert_104  bert_105  bert_106  bert_107  \\\n",
       "0    -0.894223 -0.994171  0.108406 -0.163455 -0.057791  0.991676 -0.226500   \n",
       "1    -0.989000 -1.000000  0.054668 -0.236000 -0.070600  0.982736  0.233068   \n",
       "2    -0.976000 -0.981000  0.140159 -0.175000 -0.121000  0.869535  0.317020   \n",
       "3    -0.992000 -0.995000 -0.048900 -0.072000 -0.441000  0.981805 -0.036700   \n",
       "4    -0.660942 -0.987986  0.101264 -0.210505  0.019022  0.988212  0.413141   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.995000 -0.999000 -0.083100 -0.176000  0.102457  0.985046  0.196582   \n",
       "1818 -0.987000 -0.971000  0.289940 -0.204000  0.290233  0.731255  0.236098   \n",
       "1819 -0.300000 -0.988000  0.002587 -0.390000 -0.120000  0.323051  0.349014   \n",
       "1820 -0.814000 -0.999000 -0.038400 -0.562000 -0.277000  0.887576  0.400993   \n",
       "1821 -0.979608 -0.991121  0.162023 -0.057041  0.135822  0.962947 -0.101392   \n",
       "\n",
       "      bert_108  bert_109  bert_110  bert_111  bert_112  bert_113  bert_114  \\\n",
       "0    -0.332793 -0.978470  0.323056 -0.688976  0.998172 -0.994303  0.195427   \n",
       "1    -0.225000 -0.967000 -0.498000  0.170076  0.998986 -0.990000 -0.278000   \n",
       "2    -0.261000 -0.976000 -0.122000 -0.175000  0.993566 -0.989000  0.130981   \n",
       "3    -0.362000 -0.966000 -0.596000 -0.611000  0.967405 -0.989000  0.098778   \n",
       "4    -0.241699 -0.963856  0.214280  0.302050  0.999754 -0.936307 -0.230669   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.154000 -0.953000  0.072297 -0.288000  0.996719 -0.969000 -0.024700   \n",
       "1818 -0.039300 -0.937000 -0.281000 -0.321000  0.976107 -0.995000  0.076579   \n",
       "1819 -0.353000 -0.858000  0.179453 -0.029600  0.986412 -0.999000  0.164233   \n",
       "1820 -0.204000 -0.993000  0.384248 -0.602000  0.999667 -0.996000 -0.070000   \n",
       "1821 -0.143780 -0.987610 -0.022499 -0.611598  0.982917 -0.980967  0.582922   \n",
       "\n",
       "      bert_115  bert_116  bert_117  bert_118  bert_119  bert_120  bert_121  \\\n",
       "0    -0.023967 -0.987200 -0.103923  0.103828  0.994514 -0.859864  0.134679   \n",
       "1     0.451641 -0.368000  0.828351 -0.079000  0.998146 -0.974000 -0.060100   \n",
       "2     0.271772 -0.952000 -0.139000 -0.021800  0.995086 -0.846000 -0.068900   \n",
       "3     0.383866 -0.852000  0.999215 -0.103000  0.994441 -0.966000 -0.308000   \n",
       "4     0.305292 -0.598932 -0.362496  0.121675  0.944076 -0.967581 -0.288437   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.497623 -0.411000  0.518889 -0.070500  0.995673 -0.988000  0.057844   \n",
       "1818  0.372433 -0.845000 -0.298000 -0.317000  0.988591 -0.976000 -0.087900   \n",
       "1819  0.236288 -0.967000  0.554462 -0.244000  0.966775  0.053261 -0.187000   \n",
       "1820  0.469369 -0.797000 -0.056100 -0.121000  0.797823 -0.936000 -0.437000   \n",
       "1821  0.294286 -0.824605  0.992247 -0.413502  0.955437 -0.987819  0.337243   \n",
       "\n",
       "      bert_122  bert_123  bert_124  bert_125  bert_126  bert_127  bert_128  \\\n",
       "0    -0.998463 -0.953276 -0.044310 -0.025508 -0.532861 -0.384716 -0.163408   \n",
       "1    -0.998000 -0.979000 -0.137000 -0.310000 -0.761000 -0.312000 -0.317000   \n",
       "2    -0.978000  0.083944  0.305471 -0.342000 -0.494000  0.100076 -0.339000   \n",
       "3    -0.998000  0.575902 -0.073700 -0.311000 -0.901000 -0.296000 -0.177000   \n",
       "4    -0.997406 -0.953551 -0.148179  0.174083 -0.981706 -0.225681 -0.074562   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.996000 -0.914000 -0.256000  0.006252 -0.697000  0.052579  0.039210   \n",
       "1818 -0.996000 -0.631000 -0.225000 -0.222000 -0.397000  0.108176 -0.319000   \n",
       "1819 -1.000000  0.015670 -0.068600  0.481252 -0.987000 -0.409000 -0.435000   \n",
       "1820 -0.999000 -0.986000 -0.211000  0.276203 -0.956000 -0.114000 -0.516000   \n",
       "1821 -0.998639 -0.233642  0.046098  0.074094 -0.977780  0.123190  0.438497   \n",
       "\n",
       "      bert_129  bert_130  bert_131  bert_132  bert_133  bert_134  bert_135  \\\n",
       "0     0.240638  0.990385  0.190070  0.998588 -0.126664  0.495204 -0.936047   \n",
       "1     0.124763  0.985110  0.961786  0.997659 -0.233000  0.461310 -0.950000   \n",
       "2    -0.185000  0.903439  0.646815  0.988795 -0.182000  0.126245 -0.521000   \n",
       "3    -0.001050  0.997983  0.844818  0.996208 -0.350000  0.369340 -0.922000   \n",
       "4    -0.222324  0.898637  0.807646  0.998805  0.144397 -0.122847 -0.953172   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.423000  0.985511  0.985675  0.999192  0.275309  0.234974 -0.140000   \n",
       "1818 -0.119000  0.715349  0.980517  0.999580 -0.121000  0.286654 -0.610000   \n",
       "1819  0.274295  0.993690  0.916473  0.993967 -0.134000  0.492531 -0.938000   \n",
       "1820  0.025879  0.181874  0.639992  0.999572  0.181660  0.521625 -0.975000   \n",
       "1821 -0.097966  0.993174  0.945650  0.997868 -0.052251  0.285326 -0.692271   \n",
       "\n",
       "      bert_136  bert_137  bert_138  bert_139  bert_140  bert_141  bert_142  \\\n",
       "0     0.999970 -0.999296 -0.999930 -0.064550  0.999842  0.131687  0.233106   \n",
       "1     0.999834 -0.992000 -0.998000  0.130054  0.999395  0.016705 -0.541000   \n",
       "2     0.999390 -0.998000 -0.981000  0.251484  0.999997 -0.037500  0.049766   \n",
       "3     0.999177 -0.997000 -0.991000  0.350612  0.999837  0.179926 -0.446000   \n",
       "4     0.999706 -0.975552 -0.996547  0.149772  0.999736 -0.040255 -0.322061   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.999777 -0.983000 -0.997000  0.675909  0.999991  0.216029 -0.487000   \n",
       "1818  0.999920 -0.998000 -0.983000  0.178252  0.999957  0.240468 -0.151000   \n",
       "1819  0.999758 -1.000000 -0.784000  0.403493  0.999995 -0.014800  0.114864   \n",
       "1820  0.999994 -0.997000 -0.996000  0.263832  0.998970  0.141983 -0.142000   \n",
       "1821  0.998446 -0.992756 -0.997498  0.487509  0.999752  0.050350 -0.236902   \n",
       "\n",
       "      bert_143  bert_144  bert_145  bert_146  bert_147  bert_148  bert_149  \\\n",
       "0     0.995198  0.103147  0.999794 -0.987756  0.999856 -0.982450 -0.153721   \n",
       "1     0.824489  0.142941  0.999652 -0.834000  0.997545 -0.993000  0.012214   \n",
       "2     0.837111 -0.214000  0.996144 -0.843000  0.999474 -0.922000  0.107709   \n",
       "3     0.828365 -0.064700  0.994384 -0.920000  0.999849 -0.998000 -0.255000   \n",
       "4     0.987663  0.190079  0.998808 -0.917401  0.975562 -0.907218 -0.058796   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.992582  0.343987  0.999323 -0.692000  0.998892 -0.999000 -0.240000   \n",
       "1818  0.983241 -0.194000  0.998371 -0.899000  0.996921 -0.763000  0.269131   \n",
       "1819  0.974028 -0.578000  0.999810 -0.973000  0.999497 -0.963000  0.275022   \n",
       "1820  0.998333  0.141534  0.999951 -0.967000  0.994478 -0.959000 -0.117000   \n",
       "1821  0.457237  0.176075  0.996614 -0.758457  0.994513 -0.999639 -0.352789   \n",
       "\n",
       "      bert_150  bert_151  bert_152  bert_153  bert_154  bert_155  bert_156  \\\n",
       "0     0.053282 -0.158230  0.997394  0.110863 -0.015773  0.065952  0.388155   \n",
       "1    -0.654000  0.248004  0.992716 -0.185000  0.373863 -0.477000  0.957066   \n",
       "2    -0.192000 -0.282000  0.970726  0.312049 -0.129000  0.381809 -0.399000   \n",
       "3    -0.662000  0.015664  0.996735 -0.427000  0.542020  0.126793  0.976722   \n",
       "4    -0.442708  0.078037  0.864414  0.279730 -0.122252 -0.223862  0.813816   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.467000  0.125562  0.995966  0.178769  0.038353 -0.556000  0.992147   \n",
       "1818 -0.365000 -0.032400  0.962750  0.329860 -0.001580  0.003876  0.196977   \n",
       "1819 -0.116000 -0.036900  0.916547 -0.015000 -0.121000 -0.297000 -0.297000   \n",
       "1820 -0.277000 -0.218000  0.985649  0.119554  0.040008 -0.343000  0.771243   \n",
       "1821 -0.205283  0.005981  0.925202  0.047074  0.146677  0.185355  0.997662   \n",
       "\n",
       "      bert_157  bert_158  bert_159  bert_160  bert_161  bert_162  bert_163  \\\n",
       "0     0.063206  0.470285 -0.018017 -0.388176  0.060075 -0.456877  0.141881   \n",
       "1     0.489266 -0.037000 -0.195000 -0.094900 -0.193000 -0.337000 -0.035600   \n",
       "2     0.366038 -0.020400 -0.055100 -0.070900  0.017522 -0.143000  0.027316   \n",
       "3     0.311476  0.154330  0.041014 -0.043500 -0.121000 -0.132000 -0.720000   \n",
       "4    -0.738355  0.054500 -0.402888 -0.033938  0.055169 -0.422018  0.110428   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.824020  0.190623  0.353522 -0.435000  0.053441 -0.306000 -0.025700   \n",
       "1818  0.810644 -0.276000  0.012494  0.104731  0.267546 -0.526000  0.036401   \n",
       "1819  0.301366 -0.109000  0.277923 -0.431000  0.095091 -0.177000  0.014848   \n",
       "1820 -0.873000 -0.134000 -0.149000  0.120238  0.273908 -0.217000  0.080381   \n",
       "1821 -0.132477 -0.182271  0.176097 -0.242447  0.161041 -0.314564  0.006800   \n",
       "\n",
       "      bert_164  bert_165  bert_166  bert_167  bert_168  bert_169  bert_170  \\\n",
       "0     0.999995 -0.390667 -0.247091 -0.323712  0.999905  0.991694 -0.096647   \n",
       "1     0.999991  0.138639 -0.653000 -0.028800  0.998052  0.997043  0.405457   \n",
       "2     0.999967 -0.129000  0.192006 -0.476000  0.998942  0.963639 -0.219000   \n",
       "3     0.999999 -0.155000 -0.629000 -0.328000  0.943368  0.988999  0.409009   \n",
       "4     0.999841 -0.124689 -0.148776  0.133636  0.999474  0.854963  0.100534   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.999966 -0.056800 -0.320000  0.002439  0.998171  0.984348  0.122657   \n",
       "1818  0.999910 -0.114000 -0.135000  0.316695  0.999742  0.963646 -0.130000   \n",
       "1819  0.999997 -0.413000 -0.187000 -0.175000  0.999284 -0.284000 -0.146000   \n",
       "1820  0.999989 -0.618000 -0.360000  0.071979  0.999966  0.987364 -0.333000   \n",
       "1821  0.999970  0.020533 -0.024087 -0.223726  0.982762  0.965232 -0.060244   \n",
       "\n",
       "      bert_171  bert_172  bert_173  bert_174  bert_175  bert_176  bert_177  \\\n",
       "0    -0.937747 -0.994561 -0.240205  0.120738  0.242119  0.546910 -0.002095   \n",
       "1    -0.878000 -0.769000  0.609645  0.696417  0.564661 -0.017700 -0.145000   \n",
       "2    -0.464000 -0.884000 -0.670000  0.181567  0.146198 -0.473000  0.030433   \n",
       "3    -0.928000 -0.999000  0.868686  0.612045  0.602473 -0.651000 -0.215000   \n",
       "4    -0.989348  0.332419  0.568041 -0.245449  0.128193 -0.907408  0.210808   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.958000 -0.055100  0.975784  0.660940  0.240969  0.763206 -0.179000   \n",
       "1818 -0.706000  0.265760 -0.445000  0.289894 -0.030500  0.867117  0.125154   \n",
       "1819 -0.987000 -0.633000 -0.710000  0.142690  0.142850 -0.840000  0.038139   \n",
       "1820 -0.980000 -0.798000 -0.059000 -0.428000  0.344291 -0.771000 -0.104000   \n",
       "1821 -0.976071 -0.999647  0.981554  0.233144  0.007866 -0.104609 -0.008858   \n",
       "\n",
       "      bert_178  bert_179  bert_180  bert_181  bert_182  bert_183  bert_184  \\\n",
       "0     0.999731  0.830225  0.871223  0.040535  0.992771 -0.169057  0.920263   \n",
       "1     0.999552  0.886281  0.771532 -0.071500  0.992598  0.170551  0.942658   \n",
       "2     0.998868  0.753553  0.682994  0.194283  0.994441 -0.867000 -0.207000   \n",
       "3     0.992593  0.989176  0.995800 -0.063700  0.987954  0.551293  0.763091   \n",
       "4     0.999206  0.440467  0.982606 -0.004847  0.951537  0.099974 -0.178825   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.999345  0.373965  0.858478 -0.353000  0.993927  0.691931  0.620940   \n",
       "1818  0.998515 -0.269000  0.828834  0.039968  0.956172 -0.711000  0.504717   \n",
       "1819  0.998962  0.997009  0.991527 -0.317000  0.989952 -0.018500  0.481829   \n",
       "1820  0.998726  0.801511  0.941077 -0.695000  0.266969 -0.676000  0.594326   \n",
       "1821  0.994477  0.983536  0.987525  0.232934  0.992889  0.762964  0.085581   \n",
       "\n",
       "      bert_185  bert_186  bert_187  bert_188  bert_189  bert_190  bert_191  \\\n",
       "0    -0.963128 -0.999420 -0.829070  0.398747  0.999377  0.998754 -0.663970   \n",
       "1    -0.957000 -0.999000 -0.946000  0.504705  0.933801  0.984782 -0.905000   \n",
       "2    -0.966000 -0.966000 -0.323000  0.016843  0.996583  0.969245 -0.985000   \n",
       "3    -0.410000 -0.996000 -0.896000  0.555837  0.895012  0.988485 -0.714000   \n",
       "4    -0.997590 -0.998408 -0.860466 -0.187488  0.997118  0.944710 -0.995817   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.996000 -1.000000 -0.861000  0.296320  0.994523  0.996471 -0.925000   \n",
       "1818 -0.999000 -0.991000 -0.703000 -0.018000  0.994946  0.934011 -0.884000   \n",
       "1819 -0.972000 -0.999000 -0.671000 -0.013600  0.998806 -0.075900 -0.992000   \n",
       "1820 -0.884000 -0.999000 -0.079400  0.068126  0.999771  0.995145 -0.993000   \n",
       "1821 -0.700913 -0.999288  0.092549  0.330552  0.977486  0.971425 -0.985275   \n",
       "\n",
       "      bert_192  bert_193  bert_194  bert_195  bert_196  bert_197  bert_198  \\\n",
       "0    -0.846856 -0.147407  0.995585 -0.185271 -0.997134 -0.996027  0.422330   \n",
       "1     0.505902 -0.469000  0.994556 -0.123000 -0.824000 -0.985000  0.890216   \n",
       "2    -0.997000 -0.344000  0.993916  0.226423 -0.971000 -0.988000  0.365620   \n",
       "3     0.732979 -0.500000  0.997537 -0.229000 -0.974000 -0.963000 -0.493000   \n",
       "4    -0.989500  0.042993  0.979708 -0.078369 -0.991872 -0.891599  0.995261   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.969000 -0.009330  0.997827 -0.154000 -0.997000 -0.895000  0.960631   \n",
       "1818 -0.991000 -0.344000  0.991298  0.387910 -0.953000 -0.996000  0.971056   \n",
       "1819 -0.993000  0.113718  0.992580  0.022532 -0.737000 -0.998000  0.988104   \n",
       "1820 -0.943000  0.052254  0.994336  0.141648 -0.990000 -0.993000  0.973641   \n",
       "1821 -0.495316 -0.257995  0.987276 -0.039791 -0.877627 -0.948685  0.391427   \n",
       "\n",
       "      bert_199  bert_200  bert_201  bert_202  bert_203  bert_204  bert_205  \\\n",
       "0    -0.190198 -0.347406 -0.495388 -0.971927 -0.280146 -0.063150  0.964428   \n",
       "1     0.089982 -0.366000 -0.011700 -0.965000  0.154911 -0.371000  0.998081   \n",
       "2     0.101432  0.254417 -0.362000 -0.893000 -0.377000  0.159259  0.753790   \n",
       "3     0.483726 -0.076800 -0.423000 -0.981000  0.302772 -0.113000  0.998833   \n",
       "4    -0.161372  0.094084 -0.317683 -0.807632 -0.143573 -0.309227  0.975697   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.012800  0.397387 -0.478000 -0.996000 -0.170000 -0.211000  0.998888   \n",
       "1818  0.111397  0.124106 -0.577000 -0.893000  0.196419  0.533539  0.971664   \n",
       "1819 -0.343000 -0.215000 -0.103000 -0.673000  0.080141  0.232339  0.993143   \n",
       "1820 -0.036500 -0.161000 -0.146000 -0.879000  0.460386 -0.032300  0.991020   \n",
       "1821  0.270121  0.244885 -0.683268 -0.987551 -0.105522 -0.105962  0.999936   \n",
       "\n",
       "      bert_206  bert_207  bert_208  bert_209  bert_210  bert_211  bert_212  \\\n",
       "0    -0.335161  0.999681  0.998341  0.013911 -0.814345 -0.586523 -0.208074   \n",
       "1    -0.378000  0.996804  0.999004  0.197746  0.945838  0.917937 -0.102000   \n",
       "2    -0.302000  0.999589  0.992928 -0.245000 -0.804000 -0.497000  0.129984   \n",
       "3    -0.277000  0.998994  0.999594 -0.158000  0.924195  0.989543  0.010018   \n",
       "4    -0.328250  0.973273  0.999228 -0.057955  0.350714  0.367109 -0.091826   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.127000  0.987750  0.993631 -0.529000  0.854484  0.968107 -0.046500   \n",
       "1818 -0.392000  0.977074  0.996998 -0.038900 -0.688000  0.130311 -0.171000   \n",
       "1819 -0.349000  0.999743  0.999840 -0.127000 -0.504000 -0.015900  0.059672   \n",
       "1820 -0.326000  0.999479  0.999755 -0.508000  0.562166 -0.851000  0.211722   \n",
       "1821  0.050711  0.999712  0.997492 -0.006787  0.836617  0.966313 -0.148427   \n",
       "\n",
       "      bert_213  bert_214  bert_215  bert_216  bert_217  bert_218  bert_219  \\\n",
       "0    -0.223687  0.986227 -0.874348 -0.688999  0.983429  0.888864  0.258210   \n",
       "1    -0.240000  0.983375 -0.999000 -0.895000  0.923222  0.759845  0.031928   \n",
       "2    -0.008330  0.984743 -0.983000  0.724334  0.992088  0.879922 -0.122000   \n",
       "3     0.046268  0.992128 -0.991000 -0.984000  0.196335  0.265038  0.210359   \n",
       "4    -0.090268  0.948328 -0.994614 -0.822577  0.986773 -0.030271  0.032968   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.111968  0.968099 -0.999000 -0.987000  0.996115 -0.575000 -0.295000   \n",
       "1818 -0.166000  0.985167 -0.995000 -0.167000  0.999747  0.871974 -0.283000   \n",
       "1819 -0.032500  0.997321 -0.975000 -0.322000  0.993879  0.950041  0.084141   \n",
       "1820  0.204541  0.993332 -0.988000 -0.775000  0.984168  0.821142  0.000304   \n",
       "1821 -0.018599  0.976537 -0.993428 -0.998126  0.042100 -0.604048 -0.093745   \n",
       "\n",
       "      bert_220  bert_221  bert_222  bert_223  bert_224  bert_225  bert_226  \\\n",
       "0    -0.999492  0.299267  0.149031  0.268726 -0.930555 -0.989398 -0.998085   \n",
       "1    -0.997000 -0.314000 -0.606000  0.208250 -0.856000 -0.543000 -0.994000   \n",
       "2    -0.980000  0.267830 -0.616000  0.394264  0.219160 -0.986000 -0.985000   \n",
       "3    -0.991000 -0.305000 -0.987000  0.520107 -0.957000 -0.103000 -0.994000   \n",
       "4    -0.999687  0.042775  0.626756  0.033820 -0.070183 -0.916457 -0.986161   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.999000 -0.331000 -0.729000 -0.026600 -0.723000 -0.785000 -0.958000   \n",
       "1818 -0.993000 -0.134000  0.326250  0.453979 -0.234000 -0.965000 -0.994000   \n",
       "1819 -0.997000  0.241429 -0.611000  0.321815  0.129017 -0.801000 -0.999000   \n",
       "1820 -0.999000  0.133948  0.970742  0.723823 -0.820000 -0.933000 -0.999000   \n",
       "1821 -0.994025 -0.220823 -0.994958  0.117252 -0.747237 -0.160889 -0.991224   \n",
       "\n",
       "      bert_227  bert_228  bert_229  bert_230  bert_231  bert_232  bert_233  \\\n",
       "0    -0.454995 -0.913763  0.444294 -0.143297  0.095703 -0.193915  0.167189   \n",
       "1    -0.041500 -0.721000  0.996308  0.084507  0.332726  0.114710  0.090718   \n",
       "2     0.228070 -0.861000 -0.061000  0.152341 -0.069100 -0.407000 -0.160000   \n",
       "3    -0.376000  0.767108  0.993970  0.040434  0.273594 -0.130000  0.352481   \n",
       "4    -0.038200 -0.995507  0.981484 -0.198064 -0.260638  0.046081 -0.228725   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.256362 -0.956000  0.956694 -0.270000 -0.429000 -0.094500 -0.017300   \n",
       "1818  0.442280 -0.983000 -0.261000  0.047789  0.193900 -0.052300 -0.374000   \n",
       "1819  0.368152 -0.468000  0.090970 -0.329000  0.051395 -0.281000  0.393877   \n",
       "1820  0.184874 -0.864000  0.480171 -0.205000 -0.197000 -0.415000  0.262243   \n",
       "1821  0.290096 -0.132550  0.984738  0.018223 -0.135954  0.263565 -0.084759   \n",
       "\n",
       "      bert_234  bert_235  bert_236  bert_237  bert_238  bert_239  bert_240  \\\n",
       "0     0.998244  0.112099 -0.816726  0.272809  0.060892 -0.063746 -0.686249   \n",
       "1     0.997523 -0.416000 -0.165000 -0.504000  0.281646 -0.338000 -0.025700   \n",
       "2     0.968031  0.033380 -0.973000  0.031390  0.116557 -0.011000  0.571601   \n",
       "3     0.993538 -0.038200 -0.859000 -0.075900  0.478675  0.372853  0.790405   \n",
       "4     0.995506  0.013264 -0.821947 -0.329873  0.191869 -0.354865 -0.025689   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.992886 -0.299000 -0.963000 -0.513000  0.370053 -0.336000  0.660073   \n",
       "1818  0.997314 -0.193000 -0.390000 -0.237000 -0.178000 -0.170000  0.776282   \n",
       "1819  0.999366  0.245983 -0.875000 -0.492000 -0.191000 -0.309000  0.545061   \n",
       "1820  0.999617  0.155635 -0.806000 -0.632000  0.269053 -0.403000 -0.934000   \n",
       "1821  0.997634 -0.351718 -0.914998  0.154713  0.192087  0.150106  0.489156   \n",
       "\n",
       "      bert_241  bert_242  bert_243  bert_244  bert_245  bert_246  bert_247  \\\n",
       "0     0.999996 -0.814935  0.999894  0.083189  0.349218  0.999678 -0.305613   \n",
       "1     0.999914 -0.350000  0.999813 -0.597000 -0.168000  0.999958  0.234174   \n",
       "2     0.999998 -0.629000  0.995906  0.615156  0.155956  0.999515 -0.167000   \n",
       "3     0.999984  0.188794  0.998719 -0.529000  0.183876  0.997686  0.363179   \n",
       "4     0.999885 -0.410095  0.997655  0.019422  0.315545  0.999966  0.456091   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.999998  0.111309  0.999469 -0.930000  0.436403  0.999933 -0.005440   \n",
       "1818  0.999971 -0.726000  0.999200 -0.246000  0.217383  0.999690 -0.243000   \n",
       "1819  1.000000 -0.860000  0.997929  0.428038  0.171183  0.999993 -0.143000   \n",
       "1820  0.999994 -0.900000  0.998559  0.641778  0.137802  0.999994  0.010880   \n",
       "1821  0.999980  0.183250  0.999463 -0.908273  0.282874  0.999759  0.335690   \n",
       "\n",
       "      bert_248  bert_249  bert_250  bert_251  bert_252  bert_253  bert_254  \\\n",
       "0     0.988084 -0.129852  0.058127  0.379818 -0.319978 -0.072744  0.999956   \n",
       "1     0.992798 -0.137000 -0.282000 -0.099400  0.082188  0.422520  0.999793   \n",
       "2     0.974963 -0.292000  0.140689  0.427767  0.004234 -0.089400  0.999846   \n",
       "3     0.945341  0.014193  0.357609 -0.436000 -0.305000  0.198819  0.999923   \n",
       "4     0.983681 -0.205313 -0.453754 -0.037769 -0.519392  0.088010  0.999311   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.995996 -0.139000 -0.183000  0.200335 -0.273000  0.310804  0.999851   \n",
       "1818  0.967823 -0.310000 -0.395000  0.330748 -0.170000  0.140115  0.999338   \n",
       "1819  0.991610  0.031583 -0.255000 -0.150000  0.067496 -0.134000  0.999928   \n",
       "1820  0.979552 -0.162000  0.059501 -0.172000 -0.328000 -0.254000  0.999934   \n",
       "1821  0.966692 -0.434366 -0.061198 -0.071863 -0.083151 -0.099671  0.999711   \n",
       "\n",
       "      bert_255  bert_256  bert_257  bert_258  bert_259  bert_260  bert_261  \\\n",
       "0     0.315953 -0.139727 -0.483264 -0.631395  0.902325 -0.246594 -0.999511   \n",
       "1     0.026241 -0.077000 -0.999000  0.624846  0.691106 -0.334000 -0.999000   \n",
       "2     0.090744  0.110101 -0.828000 -0.541000  0.933814 -0.196000 -1.000000   \n",
       "3    -0.587000 -0.113000 -1.000000  0.031844  0.610652 -0.593000 -0.995000   \n",
       "4    -0.117204 -0.335919 -0.963763  0.207954  0.746172 -0.062526 -0.998073   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.038062 -0.091100 -0.992000  0.324459  0.963984 -0.438000 -0.999000   \n",
       "1818  0.090732 -0.250000 -0.865000 -0.079800  0.905974 -0.358000 -0.997000   \n",
       "1819 -0.067600  0.223678 -0.972000 -0.192000  0.708586 -0.041800 -1.000000   \n",
       "1820  0.077634 -0.183000 -0.687000  0.321121  0.859444  0.336462 -1.000000   \n",
       "1821  0.027773  0.273080 -0.995230 -0.138413 -0.042460 -0.679780 -0.998105   \n",
       "\n",
       "      bert_262  bert_263  bert_264  bert_265  bert_266  bert_267  bert_268  \\\n",
       "0     0.086733 -0.777795 -0.067256  0.997084  0.998849 -0.757679  0.379327   \n",
       "1    -0.395000 -0.075000 -0.188000  0.924990  0.999238 -0.283000  0.317798   \n",
       "2     0.074826 -0.943000  0.074229  0.984524  0.986345 -0.893000  0.367183   \n",
       "3    -0.562000 -0.368000 -0.059500  0.748359  0.999726 -0.790000  0.325266   \n",
       "4    -0.397131 -0.686092 -0.036289  0.992899  0.998281 -0.933785  0.275176   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.489000 -0.872000  0.268496  0.989319  0.999136 -0.669000  0.028217   \n",
       "1818  0.089030 -0.946000  0.078523  0.985624  0.997673 -0.903000 -0.073800   \n",
       "1819 -0.180000 -0.724000  0.069614  0.926636  0.999423 -0.996000  0.213249   \n",
       "1820 -0.036600 -0.756000  0.254344  0.989391  0.999306 -0.975000 -0.125000   \n",
       "1821 -0.068644  0.032080  0.140456  0.981031  0.999846 -0.940688  0.259593   \n",
       "\n",
       "      bert_269  bert_270  bert_271  bert_272  bert_273  bert_274  bert_275  \\\n",
       "0     0.047055  0.997867 -0.017929 -0.992369  0.999995 -0.382769 -0.803451   \n",
       "1    -0.045800  0.999637  0.219680 -0.999000  0.999981 -0.173000 -0.956000   \n",
       "2     0.030727  0.999232  0.105616 -0.960000  0.999982 -0.357000 -0.934000   \n",
       "3    -0.233000  0.924168 -0.001650 -0.997000  0.999976 -0.472000 -0.936000   \n",
       "4    -0.143948  0.996659 -0.112410 -0.997598  0.999812 -0.081000 -0.975577   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.400153  0.999496 -0.090500 -0.990000  0.999963 -0.580000 -0.865000   \n",
       "1818 -0.028000  0.999751 -0.062900 -0.795000  0.999977 -0.116000 -0.830000   \n",
       "1819 -0.068600  0.999878  0.056676 -0.995000  0.999976 -0.033800 -0.981000   \n",
       "1820  0.121829  0.999664 -0.343000 -0.999000  0.999980 -0.218000 -0.468000   \n",
       "1821  0.269545  0.996739  0.123518 -0.997418  0.999991 -0.129450 -0.929186   \n",
       "\n",
       "      bert_276  bert_277  bert_278  bert_279  bert_280  bert_281  bert_282  \\\n",
       "0     0.991455  0.132520  0.608287  0.247420  0.156043 -0.998999  0.851507   \n",
       "1     0.511480  0.194148 -0.983000 -0.460000 -0.330000 -0.998000  0.888024   \n",
       "2     0.967844 -0.203000  0.948408  0.491955  0.175758 -0.994000  0.924632   \n",
       "3     0.968664  0.347250 -0.628000 -0.273000 -0.963000 -0.982000  0.648756   \n",
       "4     0.981222  0.213124 -0.952811 -0.056019 -0.341751 -0.999095  0.708281   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.962773  0.231142 -0.911000 -0.200000 -0.641000 -1.000000  0.228163   \n",
       "1818  0.403189  0.196774  0.574785 -0.218000  0.562822 -1.000000  0.766805   \n",
       "1819  0.996186  0.000138  0.725557 -0.282000 -0.675000 -0.981000  0.378815   \n",
       "1820  0.911660  0.309775 -0.702000  0.112847  0.573322 -0.987000  0.859716   \n",
       "1821  0.974012 -0.001645 -0.808354 -0.114893 -0.608060 -0.993053 -0.051044   \n",
       "\n",
       "      bert_283  bert_284  bert_285  bert_286  bert_287  bert_288  bert_289  \\\n",
       "0     0.999991 -0.678790  0.068183 -0.107639  0.026917 -0.999776 -0.998124   \n",
       "1     0.999987  0.470900 -0.451000  0.100027  0.180963 -0.997000 -0.992000   \n",
       "2     0.999923 -0.477000  0.206851 -0.089600 -0.019200 -0.999000 -0.998000   \n",
       "3     0.999980  0.905841  0.102062  0.657026  0.505438 -1.000000 -1.000000   \n",
       "4     0.998617 -0.619579 -0.090447  0.082961 -0.080683 -0.997709 -0.997275   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.999995  0.613078 -0.308000  0.258775 -0.019500 -0.999000 -0.966000   \n",
       "1818  0.999971 -0.051800 -0.034700 -0.298000  0.047519 -0.999000 -0.991000   \n",
       "1819  0.999835 -0.713000  0.188145 -0.311000 -0.099400 -1.000000 -1.000000   \n",
       "1820  0.999938 -0.968000  0.235972 -0.500000 -0.062900 -0.999000 -0.999000   \n",
       "1821  0.999979  0.408360  0.179336  0.491992  0.206420 -0.998458 -0.998746   \n",
       "\n",
       "      bert_290  bert_291  bert_292  bert_293  bert_294  bert_295  bert_296  \\\n",
       "0    -0.880143  0.383719 -0.107090  0.994365  0.999410 -0.989632  0.152308   \n",
       "1    -0.381000  0.744640  0.192876  0.998887  0.998605 -0.984000 -0.187000   \n",
       "2    -0.526000 -0.226000  0.121709  0.932784  0.999713 -0.996000 -0.060300   \n",
       "3    -0.960000  0.632277  0.479539  0.987655  0.998587 -0.998000 -0.152000   \n",
       "4     0.464325  0.164791 -0.332271  0.983002  0.992576 -0.954026  0.297282   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.109000  0.278527  0.000475  0.994842  0.998572 -0.982000 -0.137000   \n",
       "1818 -0.216000  0.033850 -0.167000  0.945981  0.999302 -0.998000 -0.255000   \n",
       "1819  0.020604 -0.006660  0.242547  0.999500  0.999810 -0.995000 -0.032200   \n",
       "1820 -0.600000  0.473175  0.431838  0.972692  0.998424 -0.962000 -0.322000   \n",
       "1821 -0.771610 -0.031196  0.502469  0.952788  0.994429 -0.997483  0.242725   \n",
       "\n",
       "      bert_297  bert_298  bert_299  bert_300  bert_301  bert_302  bert_303  \\\n",
       "0     0.958914  0.154982  0.997206  0.999987 -0.997493 -0.573020  0.999320   \n",
       "1     0.856523 -0.567000  0.999678  0.999976 -0.991000 -0.145000  0.999723   \n",
       "2     0.673281 -0.127000  0.994465  0.999585 -0.447000 -0.544000  0.994414   \n",
       "3     0.905977 -0.358000  0.999950  0.999974 -1.000000  0.437833  0.999903   \n",
       "4     0.902562 -0.319605  0.997950  0.999924 -0.985743 -0.340662  0.994939   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.663677 -0.324000  0.999545  0.999970 -0.996000 -0.036000  0.999132   \n",
       "1818  0.855767 -0.186000  0.997187  0.999891  0.312862 -0.562000  0.994305   \n",
       "1819  0.988037  0.236791  0.999082  0.999938 -0.919000 -0.694000  0.999125   \n",
       "1820  0.975382 -0.275000  0.999588  0.999998 -0.997000 -0.778000  0.999458   \n",
       "1821  0.923144  0.174193  0.999963  0.999966 -0.996836  0.382523  0.999861   \n",
       "\n",
       "      bert_304  bert_305  bert_306  bert_307  bert_308  bert_309  bert_310  \\\n",
       "0    -0.374868 -0.204477  0.099023  0.996594  0.948357 -0.112678  0.241461   \n",
       "1    -0.415000  0.272462  0.035769  0.988414 -0.539000  0.431718  0.234432   \n",
       "2    -0.126000 -0.281000 -0.318000  0.996715  0.620176 -0.044600  0.408722   \n",
       "3    -0.556000 -0.281000 -0.030100  0.980011 -0.972000  0.218429 -0.089600   \n",
       "4     0.096044 -0.049826  0.242561  0.993377  0.214967  0.329513  0.116921   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.167000 -0.049600  0.077018  0.984981 -0.469000  0.315466  0.251467   \n",
       "1818  0.179985  0.175859  0.177313  0.995453  0.788372  0.228086  0.653279   \n",
       "1819 -0.220000 -0.451000  0.251210  0.998837  0.531746 -0.105000  0.058571   \n",
       "1820  0.045066  0.141705  0.097845  0.998486  0.805715  0.120867  0.094464   \n",
       "1821  0.178281  0.184382 -0.302208  0.994569 -0.987053  0.307194  0.103798   \n",
       "\n",
       "      bert_311  bert_312  bert_313  bert_314  bert_315  bert_316  bert_317  \\\n",
       "0    -0.997445 -0.397005  0.998168  0.995064 -0.221232  0.035435 -0.092964   \n",
       "1    -0.977000 -0.358000 -0.096900  0.997075  0.404281  0.465322 -0.157000   \n",
       "2    -0.847000  0.070309  0.998687  0.978490  0.129572 -0.040700 -0.151000   \n",
       "3    -0.922000  0.305100  0.920896  0.997030  0.134503  0.592979 -0.158000   \n",
       "4    -0.803401 -0.281027  0.465449  0.943839  0.318458  0.198965 -0.060849   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.955000 -0.082800  0.582189  0.982277  0.391696  0.044017 -0.070200   \n",
       "1818 -0.730000 -0.308000  0.955654  0.899007  0.221897 -0.152000 -0.295000   \n",
       "1819 -0.639000 -0.355000  0.986870  0.986936 -0.160000  0.028141 -0.081400   \n",
       "1820 -0.963000 -0.123000  0.978432  0.958891  0.068546 -0.222000 -0.442000   \n",
       "1821  0.552196  0.097548  0.816593  0.963246  0.311863  0.054469 -0.177031   \n",
       "\n",
       "      bert_318  bert_319  bert_320  bert_321  bert_322  bert_323  bert_324  \\\n",
       "0     0.151324  0.999848  0.009777  0.852312 -0.177322 -0.839064 -0.211912   \n",
       "1    -0.034400  0.998150  0.336056  0.003673 -0.346000 -0.923000  0.076270   \n",
       "2     0.320149  0.999961 -0.248000  0.837871 -0.087400 -0.781000  0.007338   \n",
       "3     0.122935  0.999964 -0.367000 -0.597000 -0.112000 -0.993000  0.215898   \n",
       "4     0.087212  0.983434  0.040102 -0.890958 -0.123496 -0.445025  0.105167   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.642197  0.999909 -0.231000 -0.377000 -0.238000 -0.874000 -0.046600   \n",
       "1818  0.297758  0.999556  0.125114  0.515869 -0.561000  0.096000  0.230563   \n",
       "1819  0.275401  0.999354  0.065021 -0.294000  0.002870 -0.932000  0.133581   \n",
       "1820  0.286142  0.998662  0.245897 -0.770000 -0.204000 -0.985000  0.377962   \n",
       "1821 -0.190743  0.999711 -0.143514 -0.158788 -0.047902 -0.986135  0.348546   \n",
       "\n",
       "      bert_325  bert_326  bert_327  bert_328  bert_329  bert_330  bert_331  \\\n",
       "0     0.086590 -0.810184 -0.293656 -0.988491  0.591749  0.997119 -0.115562   \n",
       "1     0.287246 -0.745000  0.657670 -0.969000  0.720943  0.956508 -0.133000   \n",
       "2     0.148104 -0.860000 -0.159000 -0.974000 -0.509000  0.995315 -0.185000   \n",
       "3    -0.200000 -0.855000  0.949854 -0.805000  0.898583  0.950278 -0.544000   \n",
       "4     0.138161 -0.943914 -0.414748 -0.629748 -0.040945  0.946682 -0.072607   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.158000 -0.815000  0.220417 -0.598000 -0.083200  0.974017 -0.156000   \n",
       "1818 -0.040700 -0.614000  0.277921 -0.985000 -0.853000  0.967329  0.042435   \n",
       "1819  0.080153 -0.987000  0.500482 -0.991000  0.299985  0.970503  0.219597   \n",
       "1820 -0.097800 -0.509000 -0.216000 -0.973000  0.511659  0.828907  0.012288   \n",
       "1821  0.075210 -0.934432  0.836547 -0.525250  0.932744  0.391139 -0.120745   \n",
       "\n",
       "      bert_332  bert_333  bert_334  bert_335  bert_336  bert_337  bert_338  \\\n",
       "0     0.062400 -0.125006 -0.016574 -0.230939  0.234504 -0.870815 -0.430600   \n",
       "1    -0.020800  0.880393  0.162702  0.147762  0.235067  0.023444  0.077684   \n",
       "2    -0.000523 -0.610000 -0.149000  0.064591  0.211459  0.173628 -0.740000   \n",
       "3    -0.033900  0.941936 -0.118000  0.353592  0.275609  0.230965  0.086466   \n",
       "4    -0.163050  0.892828 -0.158600  0.005034  0.262165 -0.987630 -0.295629   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.175000  0.971285  0.103066 -0.221000 -0.046900 -0.769000  0.776667   \n",
       "1818 -0.032100 -0.063300  0.054849 -0.048800  0.297042 -0.715000 -0.532000   \n",
       "1819 -0.268000  0.949432  0.097839  0.272638  0.160443  0.421621 -0.823000   \n",
       "1820  0.275358  0.984321 -0.254000  0.442250 -0.036300  0.078219 -0.534000   \n",
       "1821 -0.328195  0.738342 -0.270251 -0.186684 -0.277560  0.765908  0.914064   \n",
       "\n",
       "      bert_339  bert_340  bert_341  bert_342  bert_343  bert_344  bert_345  \\\n",
       "0     0.154531  0.998935  0.189843 -0.150902  0.938789 -0.971393  0.890742   \n",
       "1    -0.238000  0.985406 -0.365000  0.246289  0.995883 -0.970000  0.870434   \n",
       "2     0.014987  0.939468  0.138112 -0.192000  0.974841 -0.828000 -0.103000   \n",
       "3    -0.049600  0.942181 -0.430000 -0.265000  0.980873 -0.978000  0.484047   \n",
       "4    -0.159124  0.998965  0.012889  0.001804  0.995901 -0.957314  0.998434   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.023887  0.996862  0.141987  0.215997  0.992495 -0.921000  0.943213   \n",
       "1818 -0.015700  0.990777  0.170099 -0.132000  0.996434 -0.585000  0.735161   \n",
       "1819  0.227114  0.994985  0.231989  0.064888  0.979644 -0.849000  0.966496   \n",
       "1820  0.129309  0.999467 -0.104000 -0.154000  0.998228 -0.778000  0.999528   \n",
       "1821  0.417545  0.908767  0.011700 -0.077439  0.973321 -0.495565  0.967346   \n",
       "\n",
       "      bert_346  bert_347  bert_348  bert_349  bert_350  bert_351  bert_352  \\\n",
       "0     0.797298  0.998961  0.149505  0.513899 -0.065345  0.300547  0.540359   \n",
       "1     0.435602  0.936799 -0.208000  0.998394 -0.164000  0.075216 -0.661000   \n",
       "2     0.844080  0.999859 -0.105000  0.349439  0.073988  0.241605  0.832350   \n",
       "3    -0.172000  0.997200  0.629332  0.997884 -0.057400  0.311270  0.796157   \n",
       "4     0.628486  0.959560  0.006780  0.871923 -0.072227  0.263661  0.123499   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.044181  0.984346 -0.102000  0.973244 -0.102000  0.072232  0.826214   \n",
       "1818  0.786084  0.994493 -0.359000  0.488482 -0.000408 -0.059200  0.488652   \n",
       "1819  0.942835  0.999895  0.050663  0.345903 -0.051800  0.325987  0.542395   \n",
       "1820  0.848450  0.979365 -0.380000  0.765042  0.084485 -0.001130 -0.376000   \n",
       "1821 -0.218443  0.811849  0.328866  0.994861 -0.212514 -0.210815  0.855013   \n",
       "\n",
       "      bert_353  bert_354  bert_355  bert_356  bert_357  bert_358  bert_359  \\\n",
       "0     0.040423  0.842397  0.124134 -0.540130 -0.312522 -0.192270 -0.018904   \n",
       "1     0.342232  0.493600  0.368686 -0.890000 -0.363000  0.211839 -0.275000   \n",
       "2     0.115179  0.848428 -0.262000 -0.237000  0.041896 -0.431000  0.232535   \n",
       "3     0.223559  0.046060 -0.114000 -0.990000  0.125186 -0.011900  0.122508   \n",
       "4     0.054411 -0.228717  0.070382 -0.726856 -0.102950 -0.112264  0.235532   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.016759 -0.773000 -0.063500 -0.974000 -0.130000 -0.068200 -0.192000   \n",
       "1818  0.057344  0.831556  0.185354  0.171250 -0.156000 -0.127000 -0.036500   \n",
       "1819 -0.118000  0.934903 -0.009840 -0.705000  0.140355 -0.411000 -0.036000   \n",
       "1820 -0.090500  0.750718 -0.156000 -0.521000  0.110749 -0.543000 -0.065600   \n",
       "1821 -0.107762 -0.805101 -0.282929 -0.982227  0.103752  0.248123 -0.247725   \n",
       "\n",
       "      bert_360  bert_361  bert_362  bert_363  bert_364  bert_365  bert_366  \\\n",
       "0    -0.998515 -0.553115 -0.449038  0.101221  0.410227 -0.944593 -0.707188   \n",
       "1    -0.997000  0.114500 -0.170000  0.138964 -0.409000 -0.929000 -0.165000   \n",
       "2    -1.000000 -0.713000  0.089098 -0.176000  0.271497 -0.997000 -0.792000   \n",
       "3    -0.948000  0.541228 -0.103000 -0.311000 -0.255000 -0.978000  0.303367   \n",
       "4    -0.998186  0.435133 -0.535728  0.399740  0.210172 -0.989708  0.401118   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.999000  0.936844 -0.616000  0.038171  0.473945 -0.989000  0.881202   \n",
       "1818 -1.000000 -0.596000 -0.208000 -0.012200  0.430089 -0.987000 -0.762000   \n",
       "1819 -0.991000 -0.812000 -0.397000  0.268980  0.246626 -0.976000 -0.872000   \n",
       "1820 -0.998000 -0.486000 -0.416000 -0.015900  0.420715 -0.990000 -0.608000   \n",
       "1821 -0.917273  0.939347 -0.438405 -0.302731  0.571255 -0.997710  0.884101   \n",
       "\n",
       "      bert_367  bert_368  bert_369  bert_370  bert_371  bert_372  bert_373  \\\n",
       "0     0.450232 -0.161911  0.400318  0.132915  0.985735 -0.344011 -0.124004   \n",
       "1     0.185008  0.150503  0.675143 -0.205000  0.844854 -0.534000 -0.094600   \n",
       "2     0.454449 -0.156000 -0.314000  0.015544  0.998459 -0.165000  0.414404   \n",
       "3     0.605459  0.500001  0.635336 -0.512000  0.712422 -0.720000 -0.315000   \n",
       "4     0.312936 -0.110271 -0.118043  0.260560  0.960973 -0.108495  0.044689   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.096100  0.037284  0.421270 -0.160000  0.987377  0.204614 -0.046300   \n",
       "1818 -0.255000 -0.501000 -0.020400  0.176314  0.939738  0.044714  0.183340   \n",
       "1819  0.615564 -0.145000 -0.027600  0.221557  0.993269 -0.381000  0.229303   \n",
       "1820  0.476470 -0.052400  0.190181  0.144227  0.965701 -0.031800  0.284619   \n",
       "1821  0.162021 -0.112181  0.183855  0.021339  0.582215  0.117205 -0.255009   \n",
       "\n",
       "      bert_374  bert_375  bert_376  bert_377  bert_378  bert_379  bert_380  \\\n",
       "0     0.876522 -0.995762 -0.098554 -0.417082 -0.104742  0.070615  0.987843   \n",
       "1     0.955684 -0.998000  0.173560 -0.228000 -0.448000 -0.034600  0.725003   \n",
       "2     0.702676 -0.966000 -0.199000  0.061105  0.203874 -0.316000  0.968342   \n",
       "3     0.975819 -1.000000  0.157041 -0.464000  0.014708 -0.152000  0.919844   \n",
       "4     0.747580 -0.932140  0.035831  0.087814  0.062861 -0.236932  0.773653   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.984151 -0.982000 -0.340000 -0.114000 -0.187000 -0.391000  0.923290   \n",
       "1818  0.605901 -0.992000 -0.098500 -0.421000 -0.196000 -0.166000  0.881534   \n",
       "1819  0.873854 -0.974000  0.072509  0.215451 -0.190000 -0.060000  0.933309   \n",
       "1820  0.944747 -0.933000 -0.331000  0.233082 -0.327000 -0.134000  0.992719   \n",
       "1821  0.978362 -0.998241 -0.050235 -0.350103  0.202121  0.018535  0.980579   \n",
       "\n",
       "      bert_381  bert_382  bert_383  bert_384  bert_385  bert_386  bert_387  \\\n",
       "0     0.170681 -0.608041  0.512824  0.999660 -0.896135  0.472787 -0.269124   \n",
       "1     0.700787 -0.969000 -0.141000  0.997981 -0.759000 -0.079900  0.009560   \n",
       "2    -0.034400 -0.949000  0.047889  0.999705 -0.125000  0.310279 -0.070200   \n",
       "3     0.637677 -0.999000  0.285003  0.998571 -0.808000  0.447064 -0.218000   \n",
       "4     0.406365 -0.947651  0.104839  0.973445 -0.532695  0.207996 -0.305103   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.151400 -0.997000  0.216253  0.995003 -0.425000  0.528564 -0.546000   \n",
       "1818  0.205062 -0.985000 -0.143000  0.999625  0.631879  0.485617 -0.014700   \n",
       "1819  0.162448 -0.981000 -0.010000  0.999713 -0.878000  0.395916 -0.247000   \n",
       "1820  0.401395 -0.763000 -0.154000  0.998379 -0.477000  0.564174 -0.598000   \n",
       "1821  0.056348 -0.999834  0.329096  0.968031 -0.842781  0.297022 -0.451640   \n",
       "\n",
       "      bert_388  bert_389  bert_390  bert_391  bert_392  bert_393  bert_394  \\\n",
       "0    -0.035230 -0.266306 -0.172978  0.991066 -0.999989 -0.186850 -0.060723   \n",
       "1     0.301462  0.347660  0.036429  0.933821 -1.000000  0.045149  0.190278   \n",
       "2     0.868310 -0.494000 -0.442000  0.997342 -1.000000 -0.237000 -0.254000   \n",
       "3    -0.540000 -0.287000 -0.322000  0.729921 -1.000000  0.417018  0.235072   \n",
       "4     0.594387  0.107382 -0.084808  0.607165 -0.999882 -0.571597 -0.316334   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.272000  0.302600 -0.105000  0.951849 -1.000000  0.111952 -0.071100   \n",
       "1818  0.328279 -0.088400 -0.360000  0.993871 -1.000000 -0.259000 -0.304000   \n",
       "1819  0.535432 -0.382000 -0.347000  0.991858 -1.000000 -0.364000 -0.172000   \n",
       "1820 -0.163000 -0.142000 -0.455000  0.975081 -1.000000 -0.782000 -0.028400   \n",
       "1821 -0.591060  0.230832  0.086729  0.695167 -0.999940 -0.199494 -0.090790   \n",
       "\n",
       "      bert_395  bert_396  bert_397  bert_398  bert_399  bert_400  bert_401  \\\n",
       "0     0.217371  0.241739 -0.195661  0.996623  0.010318 -0.064743 -0.907280   \n",
       "1    -0.356000 -0.668000  0.139946  0.992478 -0.528000  0.109165 -0.744000   \n",
       "2     0.286875 -0.109000 -0.600000  0.995162 -0.021300 -0.123000 -0.900000   \n",
       "3    -0.644000 -0.055300 -0.090300  0.761526 -0.264000  0.198099 -0.819000   \n",
       "4     0.124154 -0.420166 -0.030156  0.999739 -0.403420 -0.070601 -0.953111   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.142967 -0.389000 -0.631000  0.999869 -0.221000 -0.076200 -0.997000   \n",
       "1818 -0.101000  0.269966 -0.301000  0.999970 -0.298000 -0.352000 -0.916000   \n",
       "1819 -0.030900  0.033595 -0.309000  0.979734  0.093773  0.305459 -0.989000   \n",
       "1820 -0.005960 -0.177000 -0.403000  0.999162  0.406542  0.363271 -0.937000   \n",
       "1821 -0.276009 -0.326347 -0.013146  0.927860 -0.051925  0.211471 -0.996866   \n",
       "\n",
       "      bert_402  bert_403  bert_404  bert_405  bert_406  bert_407  bert_408  \\\n",
       "0    -0.835072 -0.026326  0.999393 -0.591054  0.124279  0.157127  0.341234   \n",
       "1    -0.987000 -0.044800  0.999789  0.989561  0.874783  0.444602 -0.086700   \n",
       "2     0.076182  0.119006  0.999074 -0.987000 -0.527000 -0.046500  0.178304   \n",
       "3    -0.993000 -0.160000  0.998670 -0.757000  0.943390  0.409910 -0.026900   \n",
       "4    -0.895309 -0.185414  0.996444  0.732981  0.712812  0.167593 -0.028204   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.998000 -0.229000  0.999497 -0.097400  0.983206 -0.019100  0.041086   \n",
       "1818 -0.606000 -0.029100  0.999003 -0.078400 -0.120000  0.224102 -0.141000   \n",
       "1819 -0.498000 -0.043700  0.999221 -0.742000 -0.336000  0.080458  0.143301   \n",
       "1820 -0.876000 -0.148000  0.989989  0.334718  0.354665 -0.251000  0.145622   \n",
       "1821 -0.998621 -0.038820  0.961117 -0.081699  0.993020  0.152697 -0.197617   \n",
       "\n",
       "      bert_409  bert_410  bert_411  bert_412  bert_413  bert_414  bert_415  \\\n",
       "0    -0.996674  0.778285 -0.033876 -0.998908  0.016428 -0.992073 -0.218593   \n",
       "1    -0.971000  0.982121  0.720672 -0.999000 -0.219000 -1.000000  0.301769   \n",
       "2    -0.998000  0.648460 -0.589000 -1.000000  0.182710 -0.854000  0.377037   \n",
       "3    -0.860000  0.985944  0.583595 -0.996000 -0.330000 -1.000000  0.284013   \n",
       "4    -0.977918  0.994693  0.382048 -0.999439  0.219263 -0.983043  0.319936   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.993000  0.992941  0.873848 -1.000000 -0.098100 -0.999000  0.149762   \n",
       "1818 -0.999000  0.862760  0.558123 -1.000000 -0.056800 -0.746000  0.097533   \n",
       "1819 -0.999000  0.942267 -0.854000 -0.999000 -0.102000 -0.943000  0.270288   \n",
       "1820 -0.988000  0.980056 -0.238000 -1.000000  0.121417 -0.997000  0.402542   \n",
       "1821 -0.732109  0.979181  0.595306 -0.998264 -0.025770 -0.997552  0.229365   \n",
       "\n",
       "      bert_416  bert_417  bert_418  bert_419  bert_420  bert_421  bert_422  \\\n",
       "0     0.247950 -0.812904 -0.308834 -0.999918 -0.174223  0.961026  0.048123   \n",
       "1     0.359827 -0.735000 -0.467000 -0.999000 -0.450000  0.932233 -0.494000   \n",
       "2    -0.243000 -0.326000  0.158662 -1.000000  0.101460  0.891874 -0.253000   \n",
       "3     0.061404 -0.852000 -0.306000 -0.997000 -0.359000  0.977130 -0.011600   \n",
       "4    -0.222750 -0.927772 -0.392106 -0.999604  0.059215  0.847619 -0.228500   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.251897 -0.994000 -0.376000 -1.000000 -0.124000  0.968284 -0.314000   \n",
       "1818  0.117713 -0.933000  0.396301 -0.999000  0.210126  0.979113 -0.374000   \n",
       "1819  0.409559 -0.784000  0.533321 -1.000000 -0.373000 -0.453000 -0.342000   \n",
       "1820 -0.017000 -0.742000  0.240636 -1.000000  0.089865  0.986397 -0.298000   \n",
       "1821  0.146171 -0.920912 -0.481030 -0.999671  0.211468  0.992738 -0.369775   \n",
       "\n",
       "      bert_423  bert_424  bert_425  bert_426  bert_427  bert_428  bert_429  \\\n",
       "0     0.987628 -0.192336 -0.005580 -0.283624 -0.056144 -0.078043 -0.279447   \n",
       "1     0.969037  0.477581 -0.801000 -0.227000 -0.147000 -0.206000 -0.250000   \n",
       "2     0.994883  0.196857 -0.939000 -0.180000  0.368143  0.154687 -0.452000   \n",
       "3     0.998531  0.220611 -0.982000 -0.718000  0.208881 -0.101000 -0.376000   \n",
       "4     0.303830  0.147344 -0.756883  0.337678 -0.016433 -0.161953  0.101423   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.979510  0.266484 -0.957000 -0.153000  0.099552 -0.104000  0.310188   \n",
       "1818  0.891207  0.114523 -0.937000  0.334600 -0.007680  0.023943 -0.022000   \n",
       "1819  0.798408  0.062563 -0.721000  0.191840  0.044179 -0.303000  0.090925   \n",
       "1820  0.660506  0.044545  0.930299  0.284453 -0.187000 -0.102000  0.161273   \n",
       "1821  0.894887 -0.024157 -0.994591 -0.214546 -0.006333 -0.199811 -0.165532   \n",
       "\n",
       "      bert_430  bert_431  bert_432  bert_433  bert_434  bert_435  bert_436  \\\n",
       "0     0.137867 -0.889680  0.999811 -0.999953 -0.753577  0.223173 -0.971910   \n",
       "1    -0.191000  0.987950  0.999710 -1.000000 -0.952000  0.099232 -0.981000   \n",
       "2     0.029026 -0.987000  0.965877 -1.000000 -0.891000  0.029939 -0.771000   \n",
       "3     0.442581 -0.543000  0.973259 -1.000000 -0.995000  0.335872 -0.987000   \n",
       "4     0.395114  0.468485  0.998857 -0.999605 -0.747062  0.141645 -0.825765   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.172602  0.383801  0.999180 -0.998000 -0.482000  0.327071 -0.975000   \n",
       "1818  0.228273 -0.751000  0.994494 -0.999000 -0.221000  0.120964 -0.906000   \n",
       "1819  0.311871 -0.985000  0.995408 -1.000000 -0.988000  0.192646 -0.749000   \n",
       "1820  0.369242  0.217032  0.999583 -1.000000 -0.929000  0.216135 -0.988000   \n",
       "1821  0.010327 -0.229808  0.994126 -0.999897 -0.862203  0.337109 -0.919005   \n",
       "\n",
       "      bert_437  bert_438  bert_439  bert_440  bert_441  bert_442  bert_443  \\\n",
       "0    -0.841393 -0.004325  0.384237 -0.036246 -0.998808 -0.907765 -0.213256   \n",
       "1    -0.218000  0.385699 -0.138000 -0.368000 -0.998000  0.033560  0.132350   \n",
       "2    -0.708000 -0.098400  0.364890 -0.131000 -0.996000 -0.770000  0.217463   \n",
       "3     0.481305 -0.066200  0.134225 -0.052300 -0.974000  0.802809  0.429561   \n",
       "4    -0.023820 -0.050487  0.379588  0.035843 -0.997796 -0.985537 -0.196123   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.509777  0.136009  0.288155 -0.043300 -0.998000 -0.930000  0.137226   \n",
       "1818 -0.806000  0.197499  0.350951 -0.295000 -0.999000 -0.992000 -0.246000   \n",
       "1819 -0.891000  0.105141  0.033972  0.148865 -0.999000 -0.917000 -0.036700   \n",
       "1820 -0.823000  0.007782  0.310128  0.240177 -1.000000 -0.999000  0.391346   \n",
       "1821  0.542583 -0.163110  0.194815 -0.016603 -0.983116  0.436810  0.552288   \n",
       "\n",
       "      bert_444  bert_445  bert_446  bert_447  bert_448  bert_449  bert_450  \\\n",
       "0    -0.998089 -0.997144 -0.421826 -0.040656 -0.370235 -0.155066 -0.061990   \n",
       "1    -0.999000 -0.894000 -0.821000  0.497162 -0.202000 -0.293000 -0.440000   \n",
       "2    -0.997000 -0.998000 -0.929000 -0.262000 -0.084600  0.061747  0.090182   \n",
       "3    -0.984000 -0.913000 -0.885000  0.407996 -0.238000 -0.144000  0.012167   \n",
       "4    -0.999888 -0.856673 -0.813508 -0.225260 -0.225347  0.003213 -0.350305   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -1.000000 -0.992000 -0.794000 -0.160000 -0.122000 -0.148000 -0.164000   \n",
       "1818 -0.999000 -0.993000 -0.983000 -0.039200 -0.016600  0.059997 -0.104000   \n",
       "1819 -1.000000 -0.998000 -0.921000  0.326177 -0.283000 -0.356000  0.019045   \n",
       "1820 -1.000000 -0.997000  0.877162  0.023150 -0.402000 -0.102000  0.373704   \n",
       "1821 -0.998427 -0.987024 -0.006685  0.372734  0.159917  0.054467 -0.256975   \n",
       "\n",
       "      bert_451  bert_452  bert_453  bert_454  bert_455  bert_456  bert_457  \\\n",
       "0     0.400699  0.152021  0.996901 -0.017035  0.495728 -0.283716 -0.129142   \n",
       "1     0.242348  0.164634  0.992304  0.255814  0.998284 -0.236000  0.167181   \n",
       "2     0.363796  0.175524  0.995217 -0.119000  0.103468  0.068616 -0.002490   \n",
       "3    -0.190000  0.347432  0.989491  0.329666  0.999129  0.182800 -0.105000   \n",
       "4     0.341129 -0.088238  0.942831  0.201809  0.996914  0.021832  0.422419   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.018900 -0.395000  0.981906  0.078860  0.982105  0.056391 -0.281000   \n",
       "1818  0.049140 -0.044500  0.831505  0.219434  0.530111 -0.462000  0.104782   \n",
       "1819  0.478050  0.211792  0.999552  0.030556  0.910574  0.244484  0.189636   \n",
       "1820  0.205379 -0.395000  0.990302  0.339932  0.948025  0.310753  0.547075   \n",
       "1821 -0.289996 -0.111987  0.991884 -0.402949  0.985482 -0.135595 -0.184385   \n",
       "\n",
       "      bert_458  bert_459  bert_460  bert_461  bert_462  bert_463  bert_464  \\\n",
       "0    -0.475284  0.982396  0.629266 -0.080522 -0.999854  0.434384  0.988834   \n",
       "1    -0.144000  0.998881  0.942642  0.165502 -1.000000  0.098290  0.982202   \n",
       "2    -0.086600  0.979897  0.148795 -0.014700 -0.998000  0.044716  0.977056   \n",
       "3     0.229443  0.992661  0.445500  0.655903 -1.000000  0.261203  0.910099   \n",
       "4    -0.447346  0.948084  0.855229  0.198594 -0.999549  0.148268  0.766933   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.033215  0.992251  0.825535  0.036967 -1.000000  0.277650  0.771464   \n",
       "1818 -0.216000  0.975176  0.444326 -0.257000 -0.997000  0.332140  0.990061   \n",
       "1819 -0.484000  0.996913  0.819436  0.134835 -0.999000  0.054624  0.995002   \n",
       "1820 -0.216000  0.972217  0.975693  0.127694 -1.000000  0.421407  0.985368   \n",
       "1821  0.133085  0.893717  0.473543 -0.034678 -0.999706  0.320707  0.738357   \n",
       "\n",
       "      bert_465  bert_466  bert_467  bert_468  bert_469  bert_470  bert_471  \\\n",
       "0     0.998342  0.963029  0.498420 -0.995366 -0.244770  0.473261 -0.491911   \n",
       "1     0.997373  0.963495  0.998369 -0.951000  0.109453  0.159157 -0.896000   \n",
       "2     0.999615  0.983061  0.097360 -0.929000 -0.084000  0.232363  0.661124   \n",
       "3     0.997985  0.846281  0.999691 -0.997000  0.061677  0.244346 -0.382000   \n",
       "4     0.998313  0.708707  0.995239 -0.939160  0.065530 -0.067404 -0.586424   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.994031  0.443454  0.991865 -0.991000  0.214649  0.286407 -0.946000   \n",
       "1818  0.997665  0.915089  0.437201 -0.976000  0.132573  0.336856 -0.889000   \n",
       "1819  0.999764  0.800812  0.538879 -0.908000 -0.243000  0.444392  0.677627   \n",
       "1820  0.999855  0.820924  0.933697 -0.970000 -0.120000  0.324981 -0.861000   \n",
       "1821  0.996846  0.568701  0.994903 -0.999387  0.383925  0.062153 -0.492315   \n",
       "\n",
       "      bert_472  bert_473  bert_474  bert_475  bert_476  bert_477  bert_478  \\\n",
       "0     0.403359 -0.067090  0.131189 -0.999956 -0.990382 -0.170253 -0.982404   \n",
       "1     0.050089 -0.161000  0.355124 -1.000000 -0.992000 -0.158000 -0.975000   \n",
       "2     0.662587  0.267431  0.068088 -1.000000 -0.996000 -0.022500 -0.939000   \n",
       "3    -0.226000 -0.104000  0.315518 -1.000000 -0.994000 -0.350000 -0.997000   \n",
       "4     0.538685 -0.077752  0.375222 -0.999742 -0.997861  0.058669 -0.994726   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.093300  0.217141  0.578061 -1.000000 -0.998000  0.153605 -0.971000   \n",
       "1818  0.578274  0.007676  0.412364 -0.999000 -0.993000  0.048517 -0.945000   \n",
       "1819  0.871612  0.180869  0.424984 -1.000000 -0.999000  0.040628 -0.929000   \n",
       "1820  0.841761 -0.077300  0.494266 -1.000000 -1.000000  0.148878 -0.934000   \n",
       "1821 -0.287153 -0.244908  0.315129 -0.999380 -0.995197  0.127385 -0.988414   \n",
       "\n",
       "      bert_479  bert_480  bert_481  bert_482  bert_483  bert_484  bert_485  \\\n",
       "0     0.998999 -0.086391  0.298036  0.188611  0.245520 -0.112471 -0.993676   \n",
       "1     0.827316  0.247723  0.181496  0.300091  0.017353  0.082390 -0.996000   \n",
       "2     0.999585  0.108051  0.160533 -0.419000  0.164893  0.020401 -0.994000   \n",
       "3     0.990643  0.495989  0.066373  0.590753  0.714533  0.468489 -1.000000   \n",
       "4     0.957656  0.083517 -0.025152  0.040277  0.299233 -0.347764 -0.928106   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.993360  0.238092  0.110214  0.485985  0.552147 -0.082900 -0.999000   \n",
       "1818  0.966838  0.049834  0.006290  0.219993  0.086624 -0.135000 -0.940000   \n",
       "1819  0.985985 -0.081400 -0.272000  0.131157 -0.164000 -0.272000 -0.998000   \n",
       "1820  0.998717 -0.056300  0.033905  0.413262  0.174543 -0.109000 -0.995000   \n",
       "1821  0.943812 -0.026681 -0.152489  0.615243  0.262883  0.348678 -0.999666   \n",
       "\n",
       "      bert_486  bert_487  bert_488  bert_489  bert_490  bert_491  bert_492  \\\n",
       "0    -0.999007 -0.036317 -0.095883 -0.597524 -0.213376 -0.999985  0.687367   \n",
       "1    -0.998000  0.007749 -0.588000  0.205214 -0.029100 -1.000000 -0.966000   \n",
       "2    -0.999000 -0.050600  0.203212 -0.200000 -0.087100 -1.000000 -0.483000   \n",
       "3    -0.999000 -0.068000 -0.335000  0.081449 -0.387000 -0.998000 -0.994000   \n",
       "4    -0.977835  0.190333 -0.481819 -0.042741  0.139439 -0.999970 -0.134502   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.999000 -0.023200 -0.105000  0.056106  0.232034 -1.000000 -0.598000   \n",
       "1818 -0.999000 -0.157000  0.008617 -0.491000 -0.138000 -1.000000 -0.560000   \n",
       "1819 -0.998000 -0.069800 -0.436000  0.026454 -0.412000 -1.000000 -0.742000   \n",
       "1820 -0.997000  0.315624 -0.039700 -0.359000  0.110618 -1.000000 -0.866000   \n",
       "1821 -0.997261 -0.186937 -0.353943 -0.197295  0.088398 -0.997083 -0.996905   \n",
       "\n",
       "      bert_493  bert_494  bert_495  bert_496  bert_497  bert_498  bert_499  \\\n",
       "0    -0.523864 -0.308346 -0.090320 -0.303900  0.476349 -0.998545  0.994271   \n",
       "1     0.983397  0.071726 -0.394000 -0.103000  0.401782 -0.999000  0.997540   \n",
       "2    -0.752000 -0.169000  0.108694 -0.101000  0.192364 -0.974000  0.996948   \n",
       "3     0.986775 -0.214000 -0.513000 -0.139000  0.261339 -0.913000  0.999950   \n",
       "4     0.650564 -0.003659  0.221336 -0.129485 -0.165533 -0.991738  0.991800   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817  0.841625  0.624556 -0.067000 -0.108000  0.226912 -0.995000  0.989228   \n",
       "1818 -0.517000  0.027885  0.076535 -0.181000  0.289863 -0.998000  0.997953   \n",
       "1819 -0.043600 -0.372000  0.358223 -0.080200  0.383769 -0.993000  0.998174   \n",
       "1820  0.412542 -0.204000 -0.336000  0.087926  0.036314 -0.999000  0.988888   \n",
       "1821  0.987672  0.156175 -0.267036  0.159746  0.322282 -0.996291  0.999796   \n",
       "\n",
       "      bert_500  bert_501  bert_502  bert_503  bert_504  bert_505  bert_506  \\\n",
       "0    -0.328554  0.147006 -0.317300 -0.098805 -0.224524 -0.883997  0.993772   \n",
       "1    -0.349000  0.000312 -0.619000  0.537897  0.342348  0.167375  0.999929   \n",
       "2    -0.980000  0.179926  0.045391 -0.522000 -0.347000 -0.891000  0.957757   \n",
       "3    -0.392000 -0.016300 -0.476000  0.021458  0.336718 -0.354000  0.998700   \n",
       "4    -0.803406 -0.247159 -0.146241  0.149644 -0.149588 -0.248514  0.969256   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1817 -0.220000 -0.020600 -0.372000  0.195752  0.186262 -0.305000  0.998437   \n",
       "1818 -0.992000  0.076742  0.165756 -0.051600 -0.090800 -0.751000  0.975555   \n",
       "1819 -0.982000 -0.047800  0.162663 -0.114000  0.105253 -0.924000  0.900333   \n",
       "1820 -0.967000 -0.096300 -0.173000 -0.001410 -0.081400 -0.886000  0.983224   \n",
       "1821 -0.969733 -0.260363 -0.487101 -0.198966 -0.363342 -0.879410  0.998646   \n",
       "\n",
       "      bert_507  bert_508  bert_509  bert_510  bert_511  \n",
       "0    -0.982530 -0.243203  0.382119 -0.313331 -0.974009  \n",
       "1    -0.994000  0.306038  0.426094 -0.471000 -0.592000  \n",
       "2    -0.817000 -0.148000  0.309138 -0.133000 -0.914000  \n",
       "3    -0.999000  0.091550  0.102501 -0.512000 -0.475000  \n",
       "4    -0.892916 -0.089568  0.287563 -0.195797 -0.422602  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "1817 -0.998000  0.303861  0.210397 -0.453000 -0.517000  \n",
       "1818 -0.931000 -0.225000  0.358259 -0.137000 -0.750000  \n",
       "1819 -0.921000 -0.076900  0.361062 -0.255000 -0.602000  \n",
       "1820 -0.960000 -0.219000 -0.224000 -0.310000 -0.213000  \n",
       "1821 -0.999864 -0.173692  0.204035 -0.570824 -0.437862  \n",
       "\n",
       "[1822 rows x 533 columns]"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utteranceID</th>\n",
       "      <th>Group</th>\n",
       "      <th>CPS_CONST_SharesU_Situation</th>\n",
       "      <th>CPS_CONST_SharesU_CorrectSolutions</th>\n",
       "      <th>CPS_CONST_SharesU_IncorrectSolutions</th>\n",
       "      <th>CPS_CONST_EstablishesCG_Confirms</th>\n",
       "      <th>CPS_CONST_EstablishesCG_Interrupts</th>\n",
       "      <th>CPS_NEG_Responds_Reasons</th>\n",
       "      <th>CPS_NEG_Responds_QuestionsOthers</th>\n",
       "      <th>CPS_NEG_Responds_Responds</th>\n",
       "      <th>CPS_NEG_MonitorsE_Results</th>\n",
       "      <th>CPS_NEG_MonitorsE_Strategizes</th>\n",
       "      <th>CPS_NEG_MonitorsE_Save</th>\n",
       "      <th>CPS_NEG_MonitorsE_GivingUp</th>\n",
       "      <th>CPS_MAINTAIN_Initiative_Suggestions</th>\n",
       "      <th>CPS_MAINTAIN_Initiative_Compliments</th>\n",
       "      <th>CPS_MAINTAIN_Initiative_Criticizes</th>\n",
       "      <th>CPS_MAINTAIN_FulfillsR_Support</th>\n",
       "      <th>CPS_MAINTAIN_FulfillsR_Apologizes</th>\n",
       "      <th>CPS_MAINTAIN_FulfillsR_InitiatesOffTopic</th>\n",
       "      <th>CPS_MAINTAIN_FulfillsR_JoinsOffTopic</th>\n",
       "      <th>bert_0</th>\n",
       "      <th>bert_1</th>\n",
       "      <th>bert_2</th>\n",
       "      <th>bert_3</th>\n",
       "      <th>bert_4</th>\n",
       "      <th>bert_5</th>\n",
       "      <th>bert_6</th>\n",
       "      <th>bert_7</th>\n",
       "      <th>bert_8</th>\n",
       "      <th>bert_9</th>\n",
       "      <th>bert_10</th>\n",
       "      <th>bert_11</th>\n",
       "      <th>bert_12</th>\n",
       "      <th>bert_13</th>\n",
       "      <th>bert_14</th>\n",
       "      <th>bert_15</th>\n",
       "      <th>bert_16</th>\n",
       "      <th>bert_17</th>\n",
       "      <th>bert_18</th>\n",
       "      <th>bert_19</th>\n",
       "      <th>bert_20</th>\n",
       "      <th>bert_21</th>\n",
       "      <th>bert_22</th>\n",
       "      <th>bert_23</th>\n",
       "      <th>bert_24</th>\n",
       "      <th>bert_25</th>\n",
       "      <th>bert_26</th>\n",
       "      <th>bert_27</th>\n",
       "      <th>bert_28</th>\n",
       "      <th>bert_29</th>\n",
       "      <th>bert_30</th>\n",
       "      <th>bert_31</th>\n",
       "      <th>bert_32</th>\n",
       "      <th>bert_33</th>\n",
       "      <th>bert_34</th>\n",
       "      <th>bert_35</th>\n",
       "      <th>bert_36</th>\n",
       "      <th>bert_37</th>\n",
       "      <th>bert_38</th>\n",
       "      <th>bert_39</th>\n",
       "      <th>bert_40</th>\n",
       "      <th>bert_41</th>\n",
       "      <th>bert_42</th>\n",
       "      <th>bert_43</th>\n",
       "      <th>bert_44</th>\n",
       "      <th>bert_45</th>\n",
       "      <th>bert_46</th>\n",
       "      <th>bert_47</th>\n",
       "      <th>bert_48</th>\n",
       "      <th>bert_49</th>\n",
       "      <th>bert_50</th>\n",
       "      <th>bert_51</th>\n",
       "      <th>bert_52</th>\n",
       "      <th>bert_53</th>\n",
       "      <th>bert_54</th>\n",
       "      <th>bert_55</th>\n",
       "      <th>bert_56</th>\n",
       "      <th>bert_57</th>\n",
       "      <th>bert_58</th>\n",
       "      <th>bert_59</th>\n",
       "      <th>bert_60</th>\n",
       "      <th>bert_61</th>\n",
       "      <th>bert_62</th>\n",
       "      <th>bert_63</th>\n",
       "      <th>bert_64</th>\n",
       "      <th>bert_65</th>\n",
       "      <th>bert_66</th>\n",
       "      <th>bert_67</th>\n",
       "      <th>bert_68</th>\n",
       "      <th>bert_69</th>\n",
       "      <th>bert_70</th>\n",
       "      <th>bert_71</th>\n",
       "      <th>bert_72</th>\n",
       "      <th>bert_73</th>\n",
       "      <th>bert_74</th>\n",
       "      <th>bert_75</th>\n",
       "      <th>bert_76</th>\n",
       "      <th>bert_77</th>\n",
       "      <th>bert_78</th>\n",
       "      <th>bert_79</th>\n",
       "      <th>bert_80</th>\n",
       "      <th>bert_81</th>\n",
       "      <th>bert_82</th>\n",
       "      <th>bert_83</th>\n",
       "      <th>bert_84</th>\n",
       "      <th>bert_85</th>\n",
       "      <th>bert_86</th>\n",
       "      <th>bert_87</th>\n",
       "      <th>bert_88</th>\n",
       "      <th>bert_89</th>\n",
       "      <th>bert_90</th>\n",
       "      <th>bert_91</th>\n",
       "      <th>bert_92</th>\n",
       "      <th>bert_93</th>\n",
       "      <th>bert_94</th>\n",
       "      <th>bert_95</th>\n",
       "      <th>bert_96</th>\n",
       "      <th>bert_97</th>\n",
       "      <th>bert_98</th>\n",
       "      <th>bert_99</th>\n",
       "      <th>bert_100</th>\n",
       "      <th>bert_101</th>\n",
       "      <th>bert_102</th>\n",
       "      <th>bert_103</th>\n",
       "      <th>bert_104</th>\n",
       "      <th>bert_105</th>\n",
       "      <th>bert_106</th>\n",
       "      <th>bert_107</th>\n",
       "      <th>bert_108</th>\n",
       "      <th>bert_109</th>\n",
       "      <th>bert_110</th>\n",
       "      <th>bert_111</th>\n",
       "      <th>bert_112</th>\n",
       "      <th>bert_113</th>\n",
       "      <th>bert_114</th>\n",
       "      <th>bert_115</th>\n",
       "      <th>bert_116</th>\n",
       "      <th>bert_117</th>\n",
       "      <th>bert_118</th>\n",
       "      <th>bert_119</th>\n",
       "      <th>bert_120</th>\n",
       "      <th>bert_121</th>\n",
       "      <th>bert_122</th>\n",
       "      <th>bert_123</th>\n",
       "      <th>bert_124</th>\n",
       "      <th>bert_125</th>\n",
       "      <th>bert_126</th>\n",
       "      <th>bert_127</th>\n",
       "      <th>bert_128</th>\n",
       "      <th>bert_129</th>\n",
       "      <th>bert_130</th>\n",
       "      <th>bert_131</th>\n",
       "      <th>bert_132</th>\n",
       "      <th>bert_133</th>\n",
       "      <th>bert_134</th>\n",
       "      <th>bert_135</th>\n",
       "      <th>bert_136</th>\n",
       "      <th>bert_137</th>\n",
       "      <th>bert_138</th>\n",
       "      <th>bert_139</th>\n",
       "      <th>bert_140</th>\n",
       "      <th>bert_141</th>\n",
       "      <th>bert_142</th>\n",
       "      <th>bert_143</th>\n",
       "      <th>bert_144</th>\n",
       "      <th>bert_145</th>\n",
       "      <th>bert_146</th>\n",
       "      <th>bert_147</th>\n",
       "      <th>bert_148</th>\n",
       "      <th>bert_149</th>\n",
       "      <th>bert_150</th>\n",
       "      <th>bert_151</th>\n",
       "      <th>bert_152</th>\n",
       "      <th>bert_153</th>\n",
       "      <th>bert_154</th>\n",
       "      <th>bert_155</th>\n",
       "      <th>bert_156</th>\n",
       "      <th>bert_157</th>\n",
       "      <th>bert_158</th>\n",
       "      <th>bert_159</th>\n",
       "      <th>bert_160</th>\n",
       "      <th>bert_161</th>\n",
       "      <th>bert_162</th>\n",
       "      <th>bert_163</th>\n",
       "      <th>bert_164</th>\n",
       "      <th>bert_165</th>\n",
       "      <th>bert_166</th>\n",
       "      <th>bert_167</th>\n",
       "      <th>bert_168</th>\n",
       "      <th>bert_169</th>\n",
       "      <th>bert_170</th>\n",
       "      <th>bert_171</th>\n",
       "      <th>bert_172</th>\n",
       "      <th>bert_173</th>\n",
       "      <th>bert_174</th>\n",
       "      <th>bert_175</th>\n",
       "      <th>bert_176</th>\n",
       "      <th>bert_177</th>\n",
       "      <th>bert_178</th>\n",
       "      <th>bert_179</th>\n",
       "      <th>bert_180</th>\n",
       "      <th>bert_181</th>\n",
       "      <th>bert_182</th>\n",
       "      <th>bert_183</th>\n",
       "      <th>bert_184</th>\n",
       "      <th>bert_185</th>\n",
       "      <th>bert_186</th>\n",
       "      <th>bert_187</th>\n",
       "      <th>bert_188</th>\n",
       "      <th>bert_189</th>\n",
       "      <th>bert_190</th>\n",
       "      <th>bert_191</th>\n",
       "      <th>bert_192</th>\n",
       "      <th>bert_193</th>\n",
       "      <th>bert_194</th>\n",
       "      <th>bert_195</th>\n",
       "      <th>bert_196</th>\n",
       "      <th>bert_197</th>\n",
       "      <th>bert_198</th>\n",
       "      <th>bert_199</th>\n",
       "      <th>bert_200</th>\n",
       "      <th>bert_201</th>\n",
       "      <th>bert_202</th>\n",
       "      <th>bert_203</th>\n",
       "      <th>bert_204</th>\n",
       "      <th>bert_205</th>\n",
       "      <th>bert_206</th>\n",
       "      <th>bert_207</th>\n",
       "      <th>bert_208</th>\n",
       "      <th>bert_209</th>\n",
       "      <th>bert_210</th>\n",
       "      <th>bert_211</th>\n",
       "      <th>bert_212</th>\n",
       "      <th>bert_213</th>\n",
       "      <th>bert_214</th>\n",
       "      <th>bert_215</th>\n",
       "      <th>bert_216</th>\n",
       "      <th>bert_217</th>\n",
       "      <th>bert_218</th>\n",
       "      <th>bert_219</th>\n",
       "      <th>bert_220</th>\n",
       "      <th>bert_221</th>\n",
       "      <th>bert_222</th>\n",
       "      <th>bert_223</th>\n",
       "      <th>bert_224</th>\n",
       "      <th>bert_225</th>\n",
       "      <th>bert_226</th>\n",
       "      <th>bert_227</th>\n",
       "      <th>bert_228</th>\n",
       "      <th>bert_229</th>\n",
       "      <th>bert_230</th>\n",
       "      <th>bert_231</th>\n",
       "      <th>bert_232</th>\n",
       "      <th>bert_233</th>\n",
       "      <th>bert_234</th>\n",
       "      <th>bert_235</th>\n",
       "      <th>bert_236</th>\n",
       "      <th>bert_237</th>\n",
       "      <th>bert_238</th>\n",
       "      <th>bert_239</th>\n",
       "      <th>bert_240</th>\n",
       "      <th>bert_241</th>\n",
       "      <th>bert_242</th>\n",
       "      <th>bert_243</th>\n",
       "      <th>bert_244</th>\n",
       "      <th>bert_245</th>\n",
       "      <th>bert_246</th>\n",
       "      <th>bert_247</th>\n",
       "      <th>bert_248</th>\n",
       "      <th>bert_249</th>\n",
       "      <th>bert_250</th>\n",
       "      <th>bert_251</th>\n",
       "      <th>bert_252</th>\n",
       "      <th>bert_253</th>\n",
       "      <th>bert_254</th>\n",
       "      <th>bert_255</th>\n",
       "      <th>bert_256</th>\n",
       "      <th>bert_257</th>\n",
       "      <th>bert_258</th>\n",
       "      <th>bert_259</th>\n",
       "      <th>bert_260</th>\n",
       "      <th>bert_261</th>\n",
       "      <th>bert_262</th>\n",
       "      <th>bert_263</th>\n",
       "      <th>bert_264</th>\n",
       "      <th>bert_265</th>\n",
       "      <th>bert_266</th>\n",
       "      <th>bert_267</th>\n",
       "      <th>bert_268</th>\n",
       "      <th>bert_269</th>\n",
       "      <th>bert_270</th>\n",
       "      <th>bert_271</th>\n",
       "      <th>bert_272</th>\n",
       "      <th>bert_273</th>\n",
       "      <th>bert_274</th>\n",
       "      <th>bert_275</th>\n",
       "      <th>bert_276</th>\n",
       "      <th>bert_277</th>\n",
       "      <th>bert_278</th>\n",
       "      <th>bert_279</th>\n",
       "      <th>bert_280</th>\n",
       "      <th>bert_281</th>\n",
       "      <th>bert_282</th>\n",
       "      <th>bert_283</th>\n",
       "      <th>bert_284</th>\n",
       "      <th>bert_285</th>\n",
       "      <th>bert_286</th>\n",
       "      <th>bert_287</th>\n",
       "      <th>bert_288</th>\n",
       "      <th>bert_289</th>\n",
       "      <th>bert_290</th>\n",
       "      <th>bert_291</th>\n",
       "      <th>bert_292</th>\n",
       "      <th>bert_293</th>\n",
       "      <th>bert_294</th>\n",
       "      <th>bert_295</th>\n",
       "      <th>bert_296</th>\n",
       "      <th>bert_297</th>\n",
       "      <th>bert_298</th>\n",
       "      <th>bert_299</th>\n",
       "      <th>bert_300</th>\n",
       "      <th>bert_301</th>\n",
       "      <th>bert_302</th>\n",
       "      <th>bert_303</th>\n",
       "      <th>bert_304</th>\n",
       "      <th>bert_305</th>\n",
       "      <th>bert_306</th>\n",
       "      <th>bert_307</th>\n",
       "      <th>bert_308</th>\n",
       "      <th>bert_309</th>\n",
       "      <th>bert_310</th>\n",
       "      <th>bert_311</th>\n",
       "      <th>bert_312</th>\n",
       "      <th>bert_313</th>\n",
       "      <th>bert_314</th>\n",
       "      <th>bert_315</th>\n",
       "      <th>bert_316</th>\n",
       "      <th>bert_317</th>\n",
       "      <th>bert_318</th>\n",
       "      <th>bert_319</th>\n",
       "      <th>bert_320</th>\n",
       "      <th>bert_321</th>\n",
       "      <th>bert_322</th>\n",
       "      <th>bert_323</th>\n",
       "      <th>bert_324</th>\n",
       "      <th>bert_325</th>\n",
       "      <th>bert_326</th>\n",
       "      <th>bert_327</th>\n",
       "      <th>bert_328</th>\n",
       "      <th>bert_329</th>\n",
       "      <th>bert_330</th>\n",
       "      <th>bert_331</th>\n",
       "      <th>bert_332</th>\n",
       "      <th>bert_333</th>\n",
       "      <th>bert_334</th>\n",
       "      <th>bert_335</th>\n",
       "      <th>bert_336</th>\n",
       "      <th>bert_337</th>\n",
       "      <th>bert_338</th>\n",
       "      <th>bert_339</th>\n",
       "      <th>bert_340</th>\n",
       "      <th>bert_341</th>\n",
       "      <th>bert_342</th>\n",
       "      <th>bert_343</th>\n",
       "      <th>bert_344</th>\n",
       "      <th>bert_345</th>\n",
       "      <th>bert_346</th>\n",
       "      <th>bert_347</th>\n",
       "      <th>bert_348</th>\n",
       "      <th>bert_349</th>\n",
       "      <th>bert_350</th>\n",
       "      <th>bert_351</th>\n",
       "      <th>bert_352</th>\n",
       "      <th>bert_353</th>\n",
       "      <th>bert_354</th>\n",
       "      <th>bert_355</th>\n",
       "      <th>bert_356</th>\n",
       "      <th>bert_357</th>\n",
       "      <th>bert_358</th>\n",
       "      <th>bert_359</th>\n",
       "      <th>bert_360</th>\n",
       "      <th>bert_361</th>\n",
       "      <th>bert_362</th>\n",
       "      <th>bert_363</th>\n",
       "      <th>bert_364</th>\n",
       "      <th>bert_365</th>\n",
       "      <th>bert_366</th>\n",
       "      <th>bert_367</th>\n",
       "      <th>bert_368</th>\n",
       "      <th>bert_369</th>\n",
       "      <th>bert_370</th>\n",
       "      <th>bert_371</th>\n",
       "      <th>bert_372</th>\n",
       "      <th>bert_373</th>\n",
       "      <th>bert_374</th>\n",
       "      <th>bert_375</th>\n",
       "      <th>bert_376</th>\n",
       "      <th>bert_377</th>\n",
       "      <th>bert_378</th>\n",
       "      <th>bert_379</th>\n",
       "      <th>bert_380</th>\n",
       "      <th>bert_381</th>\n",
       "      <th>bert_382</th>\n",
       "      <th>bert_383</th>\n",
       "      <th>bert_384</th>\n",
       "      <th>bert_385</th>\n",
       "      <th>bert_386</th>\n",
       "      <th>bert_387</th>\n",
       "      <th>bert_388</th>\n",
       "      <th>bert_389</th>\n",
       "      <th>bert_390</th>\n",
       "      <th>bert_391</th>\n",
       "      <th>bert_392</th>\n",
       "      <th>bert_393</th>\n",
       "      <th>bert_394</th>\n",
       "      <th>bert_395</th>\n",
       "      <th>bert_396</th>\n",
       "      <th>bert_397</th>\n",
       "      <th>bert_398</th>\n",
       "      <th>bert_399</th>\n",
       "      <th>bert_400</th>\n",
       "      <th>bert_401</th>\n",
       "      <th>bert_402</th>\n",
       "      <th>bert_403</th>\n",
       "      <th>bert_404</th>\n",
       "      <th>bert_405</th>\n",
       "      <th>bert_406</th>\n",
       "      <th>bert_407</th>\n",
       "      <th>bert_408</th>\n",
       "      <th>bert_409</th>\n",
       "      <th>bert_410</th>\n",
       "      <th>bert_411</th>\n",
       "      <th>bert_412</th>\n",
       "      <th>bert_413</th>\n",
       "      <th>bert_414</th>\n",
       "      <th>bert_415</th>\n",
       "      <th>bert_416</th>\n",
       "      <th>bert_417</th>\n",
       "      <th>bert_418</th>\n",
       "      <th>bert_419</th>\n",
       "      <th>bert_420</th>\n",
       "      <th>bert_421</th>\n",
       "      <th>bert_422</th>\n",
       "      <th>bert_423</th>\n",
       "      <th>bert_424</th>\n",
       "      <th>bert_425</th>\n",
       "      <th>bert_426</th>\n",
       "      <th>bert_427</th>\n",
       "      <th>bert_428</th>\n",
       "      <th>bert_429</th>\n",
       "      <th>bert_430</th>\n",
       "      <th>bert_431</th>\n",
       "      <th>bert_432</th>\n",
       "      <th>bert_433</th>\n",
       "      <th>bert_434</th>\n",
       "      <th>bert_435</th>\n",
       "      <th>bert_436</th>\n",
       "      <th>bert_437</th>\n",
       "      <th>bert_438</th>\n",
       "      <th>bert_439</th>\n",
       "      <th>bert_440</th>\n",
       "      <th>bert_441</th>\n",
       "      <th>bert_442</th>\n",
       "      <th>bert_443</th>\n",
       "      <th>bert_444</th>\n",
       "      <th>bert_445</th>\n",
       "      <th>bert_446</th>\n",
       "      <th>bert_447</th>\n",
       "      <th>bert_448</th>\n",
       "      <th>bert_449</th>\n",
       "      <th>bert_450</th>\n",
       "      <th>bert_451</th>\n",
       "      <th>bert_452</th>\n",
       "      <th>bert_453</th>\n",
       "      <th>bert_454</th>\n",
       "      <th>bert_455</th>\n",
       "      <th>bert_456</th>\n",
       "      <th>bert_457</th>\n",
       "      <th>bert_458</th>\n",
       "      <th>bert_459</th>\n",
       "      <th>bert_460</th>\n",
       "      <th>bert_461</th>\n",
       "      <th>bert_462</th>\n",
       "      <th>bert_463</th>\n",
       "      <th>bert_464</th>\n",
       "      <th>bert_465</th>\n",
       "      <th>bert_466</th>\n",
       "      <th>bert_467</th>\n",
       "      <th>bert_468</th>\n",
       "      <th>bert_469</th>\n",
       "      <th>bert_470</th>\n",
       "      <th>bert_471</th>\n",
       "      <th>bert_472</th>\n",
       "      <th>bert_473</th>\n",
       "      <th>bert_474</th>\n",
       "      <th>bert_475</th>\n",
       "      <th>bert_476</th>\n",
       "      <th>bert_477</th>\n",
       "      <th>bert_478</th>\n",
       "      <th>bert_479</th>\n",
       "      <th>bert_480</th>\n",
       "      <th>bert_481</th>\n",
       "      <th>bert_482</th>\n",
       "      <th>bert_483</th>\n",
       "      <th>bert_484</th>\n",
       "      <th>bert_485</th>\n",
       "      <th>bert_486</th>\n",
       "      <th>bert_487</th>\n",
       "      <th>bert_488</th>\n",
       "      <th>bert_489</th>\n",
       "      <th>bert_490</th>\n",
       "      <th>bert_491</th>\n",
       "      <th>bert_492</th>\n",
       "      <th>bert_493</th>\n",
       "      <th>bert_494</th>\n",
       "      <th>bert_495</th>\n",
       "      <th>bert_496</th>\n",
       "      <th>bert_497</th>\n",
       "      <th>bert_498</th>\n",
       "      <th>bert_499</th>\n",
       "      <th>bert_500</th>\n",
       "      <th>bert_501</th>\n",
       "      <th>bert_502</th>\n",
       "      <th>bert_503</th>\n",
       "      <th>bert_504</th>\n",
       "      <th>bert_505</th>\n",
       "      <th>bert_506</th>\n",
       "      <th>bert_507</th>\n",
       "      <th>bert_508</th>\n",
       "      <th>bert_509</th>\n",
       "      <th>bert_510</th>\n",
       "      <th>bert_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1822</td>\n",
       "      <td>1822</td>\n",
       "      <td>145.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "      <td>1822.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1822</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Group_01_0</td>\n",
       "      <td>Group_07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.946037</td>\n",
       "      <td>0.165561</td>\n",
       "      <td>-0.051941</td>\n",
       "      <td>0.057872</td>\n",
       "      <td>0.070738</td>\n",
       "      <td>0.916660</td>\n",
       "      <td>0.919451</td>\n",
       "      <td>-0.928972</td>\n",
       "      <td>-0.252722</td>\n",
       "      <td>-0.987910</td>\n",
       "      <td>0.120923</td>\n",
       "      <td>-0.961912</td>\n",
       "      <td>-0.679360</td>\n",
       "      <td>-0.898137</td>\n",
       "      <td>0.203622</td>\n",
       "      <td>0.033346</td>\n",
       "      <td>-0.051403</td>\n",
       "      <td>0.259174</td>\n",
       "      <td>-0.404026</td>\n",
       "      <td>0.174109</td>\n",
       "      <td>0.066002</td>\n",
       "      <td>-0.241068</td>\n",
       "      <td>0.135173</td>\n",
       "      <td>0.807800</td>\n",
       "      <td>0.970123</td>\n",
       "      <td>0.881433</td>\n",
       "      <td>-0.178827</td>\n",
       "      <td>-0.138162</td>\n",
       "      <td>0.374911</td>\n",
       "      <td>-0.282001</td>\n",
       "      <td>0.961985</td>\n",
       "      <td>0.088193</td>\n",
       "      <td>0.273697</td>\n",
       "      <td>0.142550</td>\n",
       "      <td>-0.960010</td>\n",
       "      <td>0.076955</td>\n",
       "      <td>-0.116922</td>\n",
       "      <td>-0.144843</td>\n",
       "      <td>0.867182</td>\n",
       "      <td>-0.077187</td>\n",
       "      <td>-0.017968</td>\n",
       "      <td>0.028297</td>\n",
       "      <td>0.075952</td>\n",
       "      <td>-0.983347</td>\n",
       "      <td>-0.025132</td>\n",
       "      <td>-0.324281</td>\n",
       "      <td>-0.917980</td>\n",
       "      <td>0.098084</td>\n",
       "      <td>0.371471</td>\n",
       "      <td>-0.293021</td>\n",
       "      <td>0.979269</td>\n",
       "      <td>-0.030408</td>\n",
       "      <td>0.988571</td>\n",
       "      <td>-0.252943</td>\n",
       "      <td>-0.189996</td>\n",
       "      <td>0.237497</td>\n",
       "      <td>-0.050775</td>\n",
       "      <td>-0.222236</td>\n",
       "      <td>-0.999134</td>\n",
       "      <td>-0.979931</td>\n",
       "      <td>0.043167</td>\n",
       "      <td>-0.043959</td>\n",
       "      <td>0.924208</td>\n",
       "      <td>0.160398</td>\n",
       "      <td>0.058396</td>\n",
       "      <td>-0.950925</td>\n",
       "      <td>0.977947</td>\n",
       "      <td>0.310059</td>\n",
       "      <td>-0.305804</td>\n",
       "      <td>0.496088</td>\n",
       "      <td>0.897031</td>\n",
       "      <td>0.997538</td>\n",
       "      <td>-0.669332</td>\n",
       "      <td>-0.566607</td>\n",
       "      <td>-0.674084</td>\n",
       "      <td>-0.113398</td>\n",
       "      <td>0.027881</td>\n",
       "      <td>0.961304</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>-0.152318</td>\n",
       "      <td>-0.983894</td>\n",
       "      <td>0.097894</td>\n",
       "      <td>0.946181</td>\n",
       "      <td>0.152720</td>\n",
       "      <td>0.721157</td>\n",
       "      <td>-0.918708</td>\n",
       "      <td>0.018728</td>\n",
       "      <td>0.222898</td>\n",
       "      <td>-0.215539</td>\n",
       "      <td>0.076479</td>\n",
       "      <td>-0.871660</td>\n",
       "      <td>0.124886</td>\n",
       "      <td>0.295883</td>\n",
       "      <td>-0.888009</td>\n",
       "      <td>-0.814808</td>\n",
       "      <td>0.273138</td>\n",
       "      <td>0.879999</td>\n",
       "      <td>0.045991</td>\n",
       "      <td>-0.944282</td>\n",
       "      <td>-0.167477</td>\n",
       "      <td>-0.573909</td>\n",
       "      <td>-0.909488</td>\n",
       "      <td>-0.968198</td>\n",
       "      <td>0.030439</td>\n",
       "      <td>-0.109264</td>\n",
       "      <td>-0.116169</td>\n",
       "      <td>0.914965</td>\n",
       "      <td>0.118525</td>\n",
       "      <td>-0.282717</td>\n",
       "      <td>-0.815637</td>\n",
       "      <td>-0.129430</td>\n",
       "      <td>-0.187952</td>\n",
       "      <td>0.932387</td>\n",
       "      <td>-0.860871</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.306351</td>\n",
       "      <td>-0.747565</td>\n",
       "      <td>0.396764</td>\n",
       "      <td>-0.067967</td>\n",
       "      <td>0.978838</td>\n",
       "      <td>-0.896517</td>\n",
       "      <td>-0.154594</td>\n",
       "      <td>-0.959698</td>\n",
       "      <td>-0.051883</td>\n",
       "      <td>-0.157756</td>\n",
       "      <td>-0.164137</td>\n",
       "      <td>-0.638297</td>\n",
       "      <td>-0.107944</td>\n",
       "      <td>-0.161449</td>\n",
       "      <td>-0.098453</td>\n",
       "      <td>0.890535</td>\n",
       "      <td>0.880378</td>\n",
       "      <td>0.962899</td>\n",
       "      <td>-0.046206</td>\n",
       "      <td>0.289090</td>\n",
       "      <td>-0.634953</td>\n",
       "      <td>0.993764</td>\n",
       "      <td>-0.947714</td>\n",
       "      <td>-0.944583</td>\n",
       "      <td>0.295958</td>\n",
       "      <td>0.999430</td>\n",
       "      <td>0.096279</td>\n",
       "      <td>-0.237792</td>\n",
       "      <td>0.634575</td>\n",
       "      <td>0.097391</td>\n",
       "      <td>0.973511</td>\n",
       "      <td>-0.884744</td>\n",
       "      <td>0.980302</td>\n",
       "      <td>-0.918051</td>\n",
       "      <td>-0.114075</td>\n",
       "      <td>-0.380873</td>\n",
       "      <td>-0.104129</td>\n",
       "      <td>0.878639</td>\n",
       "      <td>-0.024071</td>\n",
       "      <td>0.145867</td>\n",
       "      <td>-0.085014</td>\n",
       "      <td>0.623671</td>\n",
       "      <td>0.233792</td>\n",
       "      <td>0.097953</td>\n",
       "      <td>0.082725</td>\n",
       "      <td>-0.190465</td>\n",
       "      <td>0.054930</td>\n",
       "      <td>-0.271779</td>\n",
       "      <td>-0.205631</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>-0.191950</td>\n",
       "      <td>-0.314656</td>\n",
       "      <td>-0.228259</td>\n",
       "      <td>0.974945</td>\n",
       "      <td>0.814357</td>\n",
       "      <td>0.160256</td>\n",
       "      <td>-0.880167</td>\n",
       "      <td>-0.665843</td>\n",
       "      <td>0.427383</td>\n",
       "      <td>0.152926</td>\n",
       "      <td>0.326532</td>\n",
       "      <td>-0.211967</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.990698</td>\n",
       "      <td>0.770459</td>\n",
       "      <td>0.898932</td>\n",
       "      <td>-0.164707</td>\n",
       "      <td>0.935275</td>\n",
       "      <td>0.099699</td>\n",
       "      <td>0.389145</td>\n",
       "      <td>-0.820782</td>\n",
       "      <td>-0.959006</td>\n",
       "      <td>-0.545561</td>\n",
       "      <td>0.203437</td>\n",
       "      <td>0.910562</td>\n",
       "      <td>0.856209</td>\n",
       "      <td>-0.845458</td>\n",
       "      <td>-0.494908</td>\n",
       "      <td>-0.195526</td>\n",
       "      <td>0.986115</td>\n",
       "      <td>-0.049906</td>\n",
       "      <td>-0.916084</td>\n",
       "      <td>-0.801557</td>\n",
       "      <td>0.312959</td>\n",
       "      <td>0.077079</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>-0.313749</td>\n",
       "      <td>-0.828024</td>\n",
       "      <td>0.016214</td>\n",
       "      <td>-0.100516</td>\n",
       "      <td>0.969202</td>\n",
       "      <td>-0.269556</td>\n",
       "      <td>0.975216</td>\n",
       "      <td>0.993990</td>\n",
       "      <td>-0.196420</td>\n",
       "      <td>0.158164</td>\n",
       "      <td>0.486724</td>\n",
       "      <td>-0.040859</td>\n",
       "      <td>0.098651</td>\n",
       "      <td>0.882655</td>\n",
       "      <td>-0.958447</td>\n",
       "      <td>-0.630409</td>\n",
       "      <td>0.749204</td>\n",
       "      <td>0.191373</td>\n",
       "      <td>0.112907</td>\n",
       "      <td>-0.977221</td>\n",
       "      <td>-0.169980</td>\n",
       "      <td>-0.512367</td>\n",
       "      <td>0.299388</td>\n",
       "      <td>-0.352558</td>\n",
       "      <td>-0.303270</td>\n",
       "      <td>-0.923774</td>\n",
       "      <td>-0.003049</td>\n",
       "      <td>-0.325274</td>\n",
       "      <td>0.801201</td>\n",
       "      <td>-0.029782</td>\n",
       "      <td>-0.003149</td>\n",
       "      <td>-0.193621</td>\n",
       "      <td>0.140690</td>\n",
       "      <td>0.932453</td>\n",
       "      <td>0.009322</td>\n",
       "      <td>-0.754399</td>\n",
       "      <td>-0.150298</td>\n",
       "      <td>0.234724</td>\n",
       "      <td>-0.061687</td>\n",
       "      <td>0.575646</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>-0.146737</td>\n",
       "      <td>0.982871</td>\n",
       "      <td>-0.216100</td>\n",
       "      <td>0.239689</td>\n",
       "      <td>0.984633</td>\n",
       "      <td>0.125318</td>\n",
       "      <td>0.912275</td>\n",
       "      <td>-0.066660</td>\n",
       "      <td>-0.033241</td>\n",
       "      <td>-0.083062</td>\n",
       "      <td>-0.164972</td>\n",
       "      <td>0.205428</td>\n",
       "      <td>0.998865</td>\n",
       "      <td>-0.083784</td>\n",
       "      <td>-0.090151</td>\n",
       "      <td>-0.909157</td>\n",
       "      <td>-0.120614</td>\n",
       "      <td>0.569791</td>\n",
       "      <td>-0.340646</td>\n",
       "      <td>-0.993234</td>\n",
       "      <td>-0.287275</td>\n",
       "      <td>-0.461420</td>\n",
       "      <td>0.067746</td>\n",
       "      <td>0.893798</td>\n",
       "      <td>0.984143</td>\n",
       "      <td>-0.736876</td>\n",
       "      <td>0.171120</td>\n",
       "      <td>0.018707</td>\n",
       "      <td>0.963371</td>\n",
       "      <td>0.032575</td>\n",
       "      <td>-0.949307</td>\n",
       "      <td>0.999536</td>\n",
       "      <td>-0.339749</td>\n",
       "      <td>-0.921581</td>\n",
       "      <td>0.872988</td>\n",
       "      <td>0.209946</td>\n",
       "      <td>-0.205072</td>\n",
       "      <td>-0.006462</td>\n",
       "      <td>-0.564945</td>\n",
       "      <td>-0.975752</td>\n",
       "      <td>0.489153</td>\n",
       "      <td>0.998882</td>\n",
       "      <td>0.297025</td>\n",
       "      <td>-0.001529</td>\n",
       "      <td>0.125534</td>\n",
       "      <td>0.170281</td>\n",
       "      <td>-0.991666</td>\n",
       "      <td>-0.989481</td>\n",
       "      <td>-0.403833</td>\n",
       "      <td>0.238442</td>\n",
       "      <td>0.150443</td>\n",
       "      <td>0.970652</td>\n",
       "      <td>0.976065</td>\n",
       "      <td>-0.949620</td>\n",
       "      <td>-0.141693</td>\n",
       "      <td>0.702243</td>\n",
       "      <td>-0.155006</td>\n",
       "      <td>0.994330</td>\n",
       "      <td>0.999299</td>\n",
       "      <td>-0.785505</td>\n",
       "      <td>0.081701</td>\n",
       "      <td>0.992855</td>\n",
       "      <td>-0.255933</td>\n",
       "      <td>-0.042672</td>\n",
       "      <td>-0.029664</td>\n",
       "      <td>0.915311</td>\n",
       "      <td>-0.336839</td>\n",
       "      <td>0.178221</td>\n",
       "      <td>0.123379</td>\n",
       "      <td>-0.720830</td>\n",
       "      <td>-0.071718</td>\n",
       "      <td>0.689480</td>\n",
       "      <td>0.919538</td>\n",
       "      <td>0.097846</td>\n",
       "      <td>0.146807</td>\n",
       "      <td>-0.023611</td>\n",
       "      <td>0.273668</td>\n",
       "      <td>0.997687</td>\n",
       "      <td>-0.122799</td>\n",
       "      <td>-0.317663</td>\n",
       "      <td>-0.169167</td>\n",
       "      <td>-0.690747</td>\n",
       "      <td>-0.007389</td>\n",
       "      <td>-0.105326</td>\n",
       "      <td>-0.645451</td>\n",
       "      <td>0.211936</td>\n",
       "      <td>-0.605462</td>\n",
       "      <td>0.406008</td>\n",
       "      <td>0.869109</td>\n",
       "      <td>-0.251858</td>\n",
       "      <td>-0.101048</td>\n",
       "      <td>0.711759</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>0.145720</td>\n",
       "      <td>0.181690</td>\n",
       "      <td>-0.375926</td>\n",
       "      <td>-0.057395</td>\n",
       "      <td>0.024116</td>\n",
       "      <td>0.946504</td>\n",
       "      <td>-0.051931</td>\n",
       "      <td>-0.132038</td>\n",
       "      <td>0.974616</td>\n",
       "      <td>-0.724928</td>\n",
       "      <td>0.608499</td>\n",
       "      <td>0.217611</td>\n",
       "      <td>0.986603</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>0.791111</td>\n",
       "      <td>0.008190</td>\n",
       "      <td>0.169028</td>\n",
       "      <td>0.435247</td>\n",
       "      <td>0.090533</td>\n",
       "      <td>0.054659</td>\n",
       "      <td>-0.025805</td>\n",
       "      <td>-0.747352</td>\n",
       "      <td>-0.063062</td>\n",
       "      <td>-0.158301</td>\n",
       "      <td>0.078462</td>\n",
       "      <td>-0.974978</td>\n",
       "      <td>0.249016</td>\n",
       "      <td>-0.323349</td>\n",
       "      <td>0.013744</td>\n",
       "      <td>0.129302</td>\n",
       "      <td>-0.965607</td>\n",
       "      <td>0.125852</td>\n",
       "      <td>0.375051</td>\n",
       "      <td>0.187334</td>\n",
       "      <td>0.230155</td>\n",
       "      <td>-0.132296</td>\n",
       "      <td>0.891557</td>\n",
       "      <td>-0.223119</td>\n",
       "      <td>-0.014985</td>\n",
       "      <td>0.758897</td>\n",
       "      <td>-0.971322</td>\n",
       "      <td>0.014330</td>\n",
       "      <td>-0.159422</td>\n",
       "      <td>-0.077827</td>\n",
       "      <td>-0.247510</td>\n",
       "      <td>0.755626</td>\n",
       "      <td>0.276677</td>\n",
       "      <td>-0.904853</td>\n",
       "      <td>0.190960</td>\n",
       "      <td>0.986112</td>\n",
       "      <td>-0.568633</td>\n",
       "      <td>0.389392</td>\n",
       "      <td>-0.213662</td>\n",
       "      <td>0.170107</td>\n",
       "      <td>-0.184363</td>\n",
       "      <td>-0.207647</td>\n",
       "      <td>0.811034</td>\n",
       "      <td>-0.997697</td>\n",
       "      <td>-0.065027</td>\n",
       "      <td>-0.057325</td>\n",
       "      <td>-0.067213</td>\n",
       "      <td>-0.085986</td>\n",
       "      <td>-0.253433</td>\n",
       "      <td>0.904121</td>\n",
       "      <td>-0.141577</td>\n",
       "      <td>0.093529</td>\n",
       "      <td>-0.854901</td>\n",
       "      <td>-0.760969</td>\n",
       "      <td>-0.133706</td>\n",
       "      <td>0.990368</td>\n",
       "      <td>-0.306350</td>\n",
       "      <td>0.547217</td>\n",
       "      <td>0.164632</td>\n",
       "      <td>0.103277</td>\n",
       "      <td>-0.945650</td>\n",
       "      <td>0.863793</td>\n",
       "      <td>0.384877</td>\n",
       "      <td>-0.995658</td>\n",
       "      <td>0.092363</td>\n",
       "      <td>-0.833877</td>\n",
       "      <td>0.255387</td>\n",
       "      <td>0.070781</td>\n",
       "      <td>-0.700873</td>\n",
       "      <td>-0.186339</td>\n",
       "      <td>-0.988517</td>\n",
       "      <td>-0.158457</td>\n",
       "      <td>0.908537</td>\n",
       "      <td>-0.099672</td>\n",
       "      <td>0.867975</td>\n",
       "      <td>0.154546</td>\n",
       "      <td>-0.739547</td>\n",
       "      <td>-0.151318</td>\n",
       "      <td>0.094617</td>\n",
       "      <td>0.013066</td>\n",
       "      <td>-0.161965</td>\n",
       "      <td>0.270036</td>\n",
       "      <td>-0.374523</td>\n",
       "      <td>0.927891</td>\n",
       "      <td>-0.997540</td>\n",
       "      <td>-0.794221</td>\n",
       "      <td>0.254529</td>\n",
       "      <td>-0.846749</td>\n",
       "      <td>-0.017562</td>\n",
       "      <td>0.039846</td>\n",
       "      <td>0.158037</td>\n",
       "      <td>-0.042259</td>\n",
       "      <td>-0.957067</td>\n",
       "      <td>-0.403770</td>\n",
       "      <td>0.119934</td>\n",
       "      <td>-0.974910</td>\n",
       "      <td>-0.906360</td>\n",
       "      <td>-0.718764</td>\n",
       "      <td>0.110172</td>\n",
       "      <td>-0.171162</td>\n",
       "      <td>0.062163</td>\n",
       "      <td>0.059076</td>\n",
       "      <td>0.125710</td>\n",
       "      <td>0.018578</td>\n",
       "      <td>0.953473</td>\n",
       "      <td>0.253339</td>\n",
       "      <td>0.894297</td>\n",
       "      <td>-0.044887</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>0.010952</td>\n",
       "      <td>0.939382</td>\n",
       "      <td>0.469945</td>\n",
       "      <td>0.127449</td>\n",
       "      <td>-0.997324</td>\n",
       "      <td>0.263195</td>\n",
       "      <td>0.688327</td>\n",
       "      <td>0.987100</td>\n",
       "      <td>0.668545</td>\n",
       "      <td>0.865766</td>\n",
       "      <td>-0.923011</td>\n",
       "      <td>-0.016541</td>\n",
       "      <td>0.202193</td>\n",
       "      <td>-0.439971</td>\n",
       "      <td>0.146114</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.327744</td>\n",
       "      <td>-0.998401</td>\n",
       "      <td>-0.988314</td>\n",
       "      <td>-0.128386</td>\n",
       "      <td>-0.964940</td>\n",
       "      <td>0.944932</td>\n",
       "      <td>0.263526</td>\n",
       "      <td>0.060183</td>\n",
       "      <td>0.227198</td>\n",
       "      <td>0.351286</td>\n",
       "      <td>0.008082</td>\n",
       "      <td>-0.965911</td>\n",
       "      <td>-0.971794</td>\n",
       "      <td>-0.077067</td>\n",
       "      <td>-0.293372</td>\n",
       "      <td>-0.057711</td>\n",
       "      <td>-0.195597</td>\n",
       "      <td>-0.998782</td>\n",
       "      <td>-0.721853</td>\n",
       "      <td>0.533547</td>\n",
       "      <td>0.006488</td>\n",
       "      <td>-0.126049</td>\n",
       "      <td>-0.080342</td>\n",
       "      <td>0.249518</td>\n",
       "      <td>-0.801895</td>\n",
       "      <td>0.995457</td>\n",
       "      <td>-0.588631</td>\n",
       "      <td>-0.095093</td>\n",
       "      <td>-0.142566</td>\n",
       "      <td>0.004998</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>-0.346613</td>\n",
       "      <td>0.916262</td>\n",
       "      <td>-0.924423</td>\n",
       "      <td>0.027265</td>\n",
       "      <td>0.218671</td>\n",
       "      <td>-0.364465</td>\n",
       "      <td>-0.612300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131988</td>\n",
       "      <td>0.746974</td>\n",
       "      <td>0.270801</td>\n",
       "      <td>0.210620</td>\n",
       "      <td>0.511484</td>\n",
       "      <td>0.168832</td>\n",
       "      <td>0.176573</td>\n",
       "      <td>0.148659</td>\n",
       "      <td>0.236382</td>\n",
       "      <td>0.062450</td>\n",
       "      <td>0.215921</td>\n",
       "      <td>0.079534</td>\n",
       "      <td>0.528609</td>\n",
       "      <td>0.166575</td>\n",
       "      <td>0.481725</td>\n",
       "      <td>0.249977</td>\n",
       "      <td>0.207550</td>\n",
       "      <td>0.192198</td>\n",
       "      <td>0.221625</td>\n",
       "      <td>0.247407</td>\n",
       "      <td>0.211439</td>\n",
       "      <td>0.224413</td>\n",
       "      <td>0.527378</td>\n",
       "      <td>0.349554</td>\n",
       "      <td>0.104405</td>\n",
       "      <td>0.281131</td>\n",
       "      <td>0.208488</td>\n",
       "      <td>0.232752</td>\n",
       "      <td>0.266404</td>\n",
       "      <td>0.645232</td>\n",
       "      <td>0.094955</td>\n",
       "      <td>0.240040</td>\n",
       "      <td>0.194070</td>\n",
       "      <td>0.223362</td>\n",
       "      <td>0.120097</td>\n",
       "      <td>0.236181</td>\n",
       "      <td>0.235679</td>\n",
       "      <td>0.221052</td>\n",
       "      <td>0.285020</td>\n",
       "      <td>0.226246</td>\n",
       "      <td>0.290216</td>\n",
       "      <td>0.219620</td>\n",
       "      <td>0.188017</td>\n",
       "      <td>0.054105</td>\n",
       "      <td>0.220038</td>\n",
       "      <td>0.501254</td>\n",
       "      <td>0.227254</td>\n",
       "      <td>0.296893</td>\n",
       "      <td>0.523594</td>\n",
       "      <td>0.221919</td>\n",
       "      <td>0.074127</td>\n",
       "      <td>0.186976</td>\n",
       "      <td>0.036669</td>\n",
       "      <td>0.216606</td>\n",
       "      <td>0.551529</td>\n",
       "      <td>0.235118</td>\n",
       "      <td>0.224991</td>\n",
       "      <td>0.306101</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.066381</td>\n",
       "      <td>0.267423</td>\n",
       "      <td>0.241880</td>\n",
       "      <td>0.145776</td>\n",
       "      <td>0.206571</td>\n",
       "      <td>0.234597</td>\n",
       "      <td>0.143487</td>\n",
       "      <td>0.078804</td>\n",
       "      <td>0.442185</td>\n",
       "      <td>0.259890</td>\n",
       "      <td>0.588232</td>\n",
       "      <td>0.249133</td>\n",
       "      <td>0.019790</td>\n",
       "      <td>0.363011</td>\n",
       "      <td>0.417209</td>\n",
       "      <td>0.473085</td>\n",
       "      <td>0.258801</td>\n",
       "      <td>0.348019</td>\n",
       "      <td>0.101322</td>\n",
       "      <td>0.227872</td>\n",
       "      <td>0.210014</td>\n",
       "      <td>0.063254</td>\n",
       "      <td>0.238157</td>\n",
       "      <td>0.129468</td>\n",
       "      <td>0.403373</td>\n",
       "      <td>0.466544</td>\n",
       "      <td>0.222000</td>\n",
       "      <td>0.193954</td>\n",
       "      <td>0.223717</td>\n",
       "      <td>0.246428</td>\n",
       "      <td>0.208986</td>\n",
       "      <td>0.315700</td>\n",
       "      <td>0.261386</td>\n",
       "      <td>0.295435</td>\n",
       "      <td>0.249095</td>\n",
       "      <td>0.326460</td>\n",
       "      <td>0.707687</td>\n",
       "      <td>0.252023</td>\n",
       "      <td>0.273560</td>\n",
       "      <td>0.189766</td>\n",
       "      <td>0.218465</td>\n",
       "      <td>0.543619</td>\n",
       "      <td>0.182214</td>\n",
       "      <td>0.100244</td>\n",
       "      <td>0.217392</td>\n",
       "      <td>0.200940</td>\n",
       "      <td>0.246315</td>\n",
       "      <td>0.165128</td>\n",
       "      <td>0.208824</td>\n",
       "      <td>0.185641</td>\n",
       "      <td>0.321650</td>\n",
       "      <td>0.300886</td>\n",
       "      <td>0.401864</td>\n",
       "      <td>0.172875</td>\n",
       "      <td>0.339934</td>\n",
       "      <td>0.223781</td>\n",
       "      <td>0.168618</td>\n",
       "      <td>0.321339</td>\n",
       "      <td>0.645250</td>\n",
       "      <td>0.221451</td>\n",
       "      <td>0.049367</td>\n",
       "      <td>0.185417</td>\n",
       "      <td>0.210948</td>\n",
       "      <td>0.172425</td>\n",
       "      <td>0.762337</td>\n",
       "      <td>0.231979</td>\n",
       "      <td>0.228542</td>\n",
       "      <td>0.448410</td>\n",
       "      <td>0.243596</td>\n",
       "      <td>0.209426</td>\n",
       "      <td>0.223044</td>\n",
       "      <td>0.227811</td>\n",
       "      <td>0.186560</td>\n",
       "      <td>0.133055</td>\n",
       "      <td>0.234388</td>\n",
       "      <td>0.205516</td>\n",
       "      <td>0.489377</td>\n",
       "      <td>0.048959</td>\n",
       "      <td>0.208586</td>\n",
       "      <td>0.140778</td>\n",
       "      <td>0.190333</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>0.192103</td>\n",
       "      <td>0.265222</td>\n",
       "      <td>0.483857</td>\n",
       "      <td>0.238009</td>\n",
       "      <td>0.092170</td>\n",
       "      <td>0.143837</td>\n",
       "      <td>0.069440</td>\n",
       "      <td>0.220640</td>\n",
       "      <td>0.219044</td>\n",
       "      <td>0.236017</td>\n",
       "      <td>0.231470</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>0.333554</td>\n",
       "      <td>0.310897</td>\n",
       "      <td>0.264086</td>\n",
       "      <td>0.561786</td>\n",
       "      <td>0.547924</td>\n",
       "      <td>0.232972</td>\n",
       "      <td>0.226382</td>\n",
       "      <td>0.217062</td>\n",
       "      <td>0.211655</td>\n",
       "      <td>0.228145</td>\n",
       "      <td>0.329693</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.212754</td>\n",
       "      <td>0.299356</td>\n",
       "      <td>0.233352</td>\n",
       "      <td>0.066673</td>\n",
       "      <td>0.331710</td>\n",
       "      <td>0.242903</td>\n",
       "      <td>0.220212</td>\n",
       "      <td>0.508499</td>\n",
       "      <td>0.641449</td>\n",
       "      <td>0.403379</td>\n",
       "      <td>0.261713</td>\n",
       "      <td>0.580331</td>\n",
       "      <td>0.218055</td>\n",
       "      <td>0.056979</td>\n",
       "      <td>0.376675</td>\n",
       "      <td>0.176047</td>\n",
       "      <td>0.223477</td>\n",
       "      <td>0.169643</td>\n",
       "      <td>0.565265</td>\n",
       "      <td>0.549699</td>\n",
       "      <td>0.266290</td>\n",
       "      <td>0.129719</td>\n",
       "      <td>0.520949</td>\n",
       "      <td>0.288229</td>\n",
       "      <td>0.187130</td>\n",
       "      <td>0.291069</td>\n",
       "      <td>0.229212</td>\n",
       "      <td>0.698114</td>\n",
       "      <td>0.231987</td>\n",
       "      <td>0.039085</td>\n",
       "      <td>0.243854</td>\n",
       "      <td>0.155787</td>\n",
       "      <td>0.409059</td>\n",
       "      <td>0.664168</td>\n",
       "      <td>0.265779</td>\n",
       "      <td>0.213894</td>\n",
       "      <td>0.211208</td>\n",
       "      <td>0.298637</td>\n",
       "      <td>0.242533</td>\n",
       "      <td>0.269794</td>\n",
       "      <td>0.094302</td>\n",
       "      <td>0.208374</td>\n",
       "      <td>0.096214</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.211535</td>\n",
       "      <td>0.723345</td>\n",
       "      <td>0.599803</td>\n",
       "      <td>0.213213</td>\n",
       "      <td>0.233202</td>\n",
       "      <td>0.294589</td>\n",
       "      <td>0.145767</td>\n",
       "      <td>0.511153</td>\n",
       "      <td>0.365493</td>\n",
       "      <td>0.613028</td>\n",
       "      <td>0.202610</td>\n",
       "      <td>0.060447</td>\n",
       "      <td>0.284787</td>\n",
       "      <td>0.607241</td>\n",
       "      <td>0.232383</td>\n",
       "      <td>0.620415</td>\n",
       "      <td>0.541593</td>\n",
       "      <td>0.256406</td>\n",
       "      <td>0.285771</td>\n",
       "      <td>0.669362</td>\n",
       "      <td>0.320211</td>\n",
       "      <td>0.219635</td>\n",
       "      <td>0.234896</td>\n",
       "      <td>0.226679</td>\n",
       "      <td>0.225377</td>\n",
       "      <td>0.227470</td>\n",
       "      <td>0.195342</td>\n",
       "      <td>0.364758</td>\n",
       "      <td>0.211682</td>\n",
       "      <td>0.246873</td>\n",
       "      <td>0.293268</td>\n",
       "      <td>0.496085</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.547223</td>\n",
       "      <td>0.073560</td>\n",
       "      <td>0.564426</td>\n",
       "      <td>0.188257</td>\n",
       "      <td>0.072912</td>\n",
       "      <td>0.254912</td>\n",
       "      <td>0.209849</td>\n",
       "      <td>0.212497</td>\n",
       "      <td>0.266502</td>\n",
       "      <td>0.272207</td>\n",
       "      <td>0.222489</td>\n",
       "      <td>0.211745</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>0.324942</td>\n",
       "      <td>0.231811</td>\n",
       "      <td>0.205226</td>\n",
       "      <td>0.442455</td>\n",
       "      <td>0.414975</td>\n",
       "      <td>0.256192</td>\n",
       "      <td>0.017271</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.396312</td>\n",
       "      <td>0.208874</td>\n",
       "      <td>0.139756</td>\n",
       "      <td>0.056364</td>\n",
       "      <td>0.334785</td>\n",
       "      <td>0.225281</td>\n",
       "      <td>0.248871</td>\n",
       "      <td>0.106317</td>\n",
       "      <td>0.186117</td>\n",
       "      <td>0.169987</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.217268</td>\n",
       "      <td>0.135076</td>\n",
       "      <td>0.240297</td>\n",
       "      <td>0.199148</td>\n",
       "      <td>0.659782</td>\n",
       "      <td>0.274101</td>\n",
       "      <td>0.524558</td>\n",
       "      <td>0.086778</td>\n",
       "      <td>0.402413</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0.655606</td>\n",
       "      <td>0.212494</td>\n",
       "      <td>0.361362</td>\n",
       "      <td>0.275984</td>\n",
       "      <td>0.064034</td>\n",
       "      <td>0.047431</td>\n",
       "      <td>0.569357</td>\n",
       "      <td>0.329345</td>\n",
       "      <td>0.295725</td>\n",
       "      <td>0.077684</td>\n",
       "      <td>0.123298</td>\n",
       "      <td>0.165396</td>\n",
       "      <td>0.195147</td>\n",
       "      <td>0.431620</td>\n",
       "      <td>0.222691</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.399771</td>\n",
       "      <td>0.541705</td>\n",
       "      <td>0.025993</td>\n",
       "      <td>0.269140</td>\n",
       "      <td>0.341029</td>\n",
       "      <td>0.196017</td>\n",
       "      <td>0.252337</td>\n",
       "      <td>0.635495</td>\n",
       "      <td>0.208555</td>\n",
       "      <td>0.223043</td>\n",
       "      <td>0.357808</td>\n",
       "      <td>0.260343</td>\n",
       "      <td>0.453387</td>\n",
       "      <td>0.162447</td>\n",
       "      <td>0.215577</td>\n",
       "      <td>0.320594</td>\n",
       "      <td>0.251416</td>\n",
       "      <td>0.209463</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.243180</td>\n",
       "      <td>0.554699</td>\n",
       "      <td>0.200834</td>\n",
       "      <td>0.466317</td>\n",
       "      <td>0.238031</td>\n",
       "      <td>0.225080</td>\n",
       "      <td>0.436207</td>\n",
       "      <td>0.560950</td>\n",
       "      <td>0.527805</td>\n",
       "      <td>0.585483</td>\n",
       "      <td>0.241844</td>\n",
       "      <td>0.230420</td>\n",
       "      <td>0.198146</td>\n",
       "      <td>0.470254</td>\n",
       "      <td>0.210024</td>\n",
       "      <td>0.216192</td>\n",
       "      <td>0.202254</td>\n",
       "      <td>0.519430</td>\n",
       "      <td>0.520455</td>\n",
       "      <td>0.209778</td>\n",
       "      <td>0.161159</td>\n",
       "      <td>0.300271</td>\n",
       "      <td>0.218558</td>\n",
       "      <td>0.084183</td>\n",
       "      <td>0.392113</td>\n",
       "      <td>0.460529</td>\n",
       "      <td>0.520497</td>\n",
       "      <td>0.027315</td>\n",
       "      <td>0.370829</td>\n",
       "      <td>0.311347</td>\n",
       "      <td>0.222514</td>\n",
       "      <td>0.233801</td>\n",
       "      <td>0.519958</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.624659</td>\n",
       "      <td>0.181059</td>\n",
       "      <td>0.377054</td>\n",
       "      <td>0.212471</td>\n",
       "      <td>0.239161</td>\n",
       "      <td>0.217440</td>\n",
       "      <td>0.091597</td>\n",
       "      <td>0.631427</td>\n",
       "      <td>0.230816</td>\n",
       "      <td>0.290473</td>\n",
       "      <td>0.300534</td>\n",
       "      <td>0.088586</td>\n",
       "      <td>0.632820</td>\n",
       "      <td>0.327601</td>\n",
       "      <td>0.310908</td>\n",
       "      <td>0.299089</td>\n",
       "      <td>0.281580</td>\n",
       "      <td>0.138680</td>\n",
       "      <td>0.329867</td>\n",
       "      <td>0.275014</td>\n",
       "      <td>0.350532</td>\n",
       "      <td>0.076473</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>0.232135</td>\n",
       "      <td>0.188977</td>\n",
       "      <td>0.203697</td>\n",
       "      <td>0.328611</td>\n",
       "      <td>0.285248</td>\n",
       "      <td>0.251806</td>\n",
       "      <td>0.215277</td>\n",
       "      <td>0.050499</td>\n",
       "      <td>0.477662</td>\n",
       "      <td>0.193899</td>\n",
       "      <td>0.206237</td>\n",
       "      <td>0.560408</td>\n",
       "      <td>0.190788</td>\n",
       "      <td>0.206606</td>\n",
       "      <td>0.270153</td>\n",
       "      <td>0.034960</td>\n",
       "      <td>0.345114</td>\n",
       "      <td>0.256775</td>\n",
       "      <td>0.346064</td>\n",
       "      <td>0.241341</td>\n",
       "      <td>0.232467</td>\n",
       "      <td>0.177502</td>\n",
       "      <td>0.216880</td>\n",
       "      <td>0.292228</td>\n",
       "      <td>0.253092</td>\n",
       "      <td>0.445457</td>\n",
       "      <td>0.194200</td>\n",
       "      <td>0.030197</td>\n",
       "      <td>0.666579</td>\n",
       "      <td>0.595023</td>\n",
       "      <td>0.229869</td>\n",
       "      <td>0.197021</td>\n",
       "      <td>0.089316</td>\n",
       "      <td>0.268260</td>\n",
       "      <td>0.506214</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>0.274614</td>\n",
       "      <td>0.375950</td>\n",
       "      <td>0.182812</td>\n",
       "      <td>0.192418</td>\n",
       "      <td>0.379642</td>\n",
       "      <td>0.437697</td>\n",
       "      <td>0.052976</td>\n",
       "      <td>0.259200</td>\n",
       "      <td>0.153893</td>\n",
       "      <td>0.197093</td>\n",
       "      <td>0.204154</td>\n",
       "      <td>0.206659</td>\n",
       "      <td>0.424986</td>\n",
       "      <td>0.390015</td>\n",
       "      <td>0.234775</td>\n",
       "      <td>0.234032</td>\n",
       "      <td>0.224203</td>\n",
       "      <td>0.206189</td>\n",
       "      <td>0.627539</td>\n",
       "      <td>0.195136</td>\n",
       "      <td>0.019737</td>\n",
       "      <td>0.334527</td>\n",
       "      <td>0.194917</td>\n",
       "      <td>0.213116</td>\n",
       "      <td>0.605702</td>\n",
       "      <td>0.204200</td>\n",
       "      <td>0.201422</td>\n",
       "      <td>0.197196</td>\n",
       "      <td>0.173776</td>\n",
       "      <td>0.690947</td>\n",
       "      <td>0.269066</td>\n",
       "      <td>0.103834</td>\n",
       "      <td>0.180906</td>\n",
       "      <td>0.400217</td>\n",
       "      <td>0.305185</td>\n",
       "      <td>0.212379</td>\n",
       "      <td>0.241193</td>\n",
       "      <td>0.250816</td>\n",
       "      <td>0.241499</td>\n",
       "      <td>0.273904</td>\n",
       "      <td>0.143323</td>\n",
       "      <td>0.211838</td>\n",
       "      <td>0.226058</td>\n",
       "      <td>0.252827</td>\n",
       "      <td>0.244844</td>\n",
       "      <td>0.296200</td>\n",
       "      <td>0.147078</td>\n",
       "      <td>0.499066</td>\n",
       "      <td>0.305140</td>\n",
       "      <td>0.015154</td>\n",
       "      <td>0.177645</td>\n",
       "      <td>0.493438</td>\n",
       "      <td>0.074934</td>\n",
       "      <td>0.343467</td>\n",
       "      <td>0.269569</td>\n",
       "      <td>0.221490</td>\n",
       "      <td>0.207502</td>\n",
       "      <td>0.191148</td>\n",
       "      <td>0.462214</td>\n",
       "      <td>0.501135</td>\n",
       "      <td>0.223119</td>\n",
       "      <td>0.205660</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.054641</td>\n",
       "      <td>0.237660</td>\n",
       "      <td>0.064294</td>\n",
       "      <td>0.115901</td>\n",
       "      <td>0.240488</td>\n",
       "      <td>0.181986</td>\n",
       "      <td>0.285316</td>\n",
       "      <td>0.275378</td>\n",
       "      <td>0.300803</td>\n",
       "      <td>0.126326</td>\n",
       "      <td>0.112498</td>\n",
       "      <td>0.234109</td>\n",
       "      <td>0.267117</td>\n",
       "      <td>0.235559</td>\n",
       "      <td>0.220349</td>\n",
       "      <td>0.009998</td>\n",
       "      <td>0.438134</td>\n",
       "      <td>0.553381</td>\n",
       "      <td>0.270221</td>\n",
       "      <td>0.278867</td>\n",
       "      <td>0.202949</td>\n",
       "      <td>0.199501</td>\n",
       "      <td>0.439654</td>\n",
       "      <td>0.013650</td>\n",
       "      <td>0.497718</td>\n",
       "      <td>0.182570</td>\n",
       "      <td>0.297224</td>\n",
       "      <td>0.216946</td>\n",
       "      <td>0.281287</td>\n",
       "      <td>0.479710</td>\n",
       "      <td>0.198929</td>\n",
       "      <td>0.190608</td>\n",
       "      <td>0.220105</td>\n",
       "      <td>0.203953</td>\n",
       "      <td>0.197685</td>\n",
       "      <td>0.317891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.589509</td>\n",
       "      <td>-0.983000</td>\n",
       "      <td>-0.618000</td>\n",
       "      <td>-0.551921</td>\n",
       "      <td>-0.871054</td>\n",
       "      <td>-0.584000</td>\n",
       "      <td>-0.411000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.779850</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.524444</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.981000</td>\n",
       "      <td>-0.581000</td>\n",
       "      <td>-0.696000</td>\n",
       "      <td>-0.437847</td>\n",
       "      <td>-0.922178</td>\n",
       "      <td>-0.609694</td>\n",
       "      <td>-0.676000</td>\n",
       "      <td>-0.752000</td>\n",
       "      <td>-0.976022</td>\n",
       "      <td>-0.957996</td>\n",
       "      <td>-0.378153</td>\n",
       "      <td>-0.940000</td>\n",
       "      <td>-0.789000</td>\n",
       "      <td>-0.818930</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.539000</td>\n",
       "      <td>-0.618000</td>\n",
       "      <td>-0.443000</td>\n",
       "      <td>-0.747000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.774785</td>\n",
       "      <td>-0.730294</td>\n",
       "      <td>-0.856233</td>\n",
       "      <td>-0.938274</td>\n",
       "      <td>-0.731146</td>\n",
       "      <td>-0.728815</td>\n",
       "      <td>-0.640025</td>\n",
       "      <td>-0.479312</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.650000</td>\n",
       "      <td>-0.994609</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.630982</td>\n",
       "      <td>-0.962648</td>\n",
       "      <td>-0.803649</td>\n",
       "      <td>-0.168500</td>\n",
       "      <td>-0.655022</td>\n",
       "      <td>0.405081</td>\n",
       "      <td>-0.831601</td>\n",
       "      <td>-0.999914</td>\n",
       "      <td>-0.743000</td>\n",
       "      <td>-0.729118</td>\n",
       "      <td>-0.891847</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.689918</td>\n",
       "      <td>-0.688354</td>\n",
       "      <td>-0.832547</td>\n",
       "      <td>-0.558000</td>\n",
       "      <td>-0.691000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.429005</td>\n",
       "      <td>-0.995955</td>\n",
       "      <td>-0.766000</td>\n",
       "      <td>-0.979971</td>\n",
       "      <td>-0.907588</td>\n",
       "      <td>0.412133</td>\n",
       "      <td>-0.997560</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.999771</td>\n",
       "      <td>-0.771762</td>\n",
       "      <td>-0.797000</td>\n",
       "      <td>-0.521478</td>\n",
       "      <td>-0.619133</td>\n",
       "      <td>-0.757766</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.601000</td>\n",
       "      <td>-0.532759</td>\n",
       "      <td>-0.926745</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.605000</td>\n",
       "      <td>-0.460918</td>\n",
       "      <td>-0.799000</td>\n",
       "      <td>-0.589565</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.594309</td>\n",
       "      <td>-0.581000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.997436</td>\n",
       "      <td>-0.872000</td>\n",
       "      <td>-0.748029</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.741016</td>\n",
       "      <td>-0.997719</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.737357</td>\n",
       "      <td>-0.683757</td>\n",
       "      <td>-0.704590</td>\n",
       "      <td>-0.639016</td>\n",
       "      <td>-0.651983</td>\n",
       "      <td>-0.822000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.758071</td>\n",
       "      <td>-0.968237</td>\n",
       "      <td>-0.871000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.685347</td>\n",
       "      <td>-0.445000</td>\n",
       "      <td>-0.999040</td>\n",
       "      <td>-0.995381</td>\n",
       "      <td>-0.661000</td>\n",
       "      <td>-0.216000</td>\n",
       "      <td>-0.999833</td>\n",
       "      <td>-0.789218</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.829925</td>\n",
       "      <td>-0.802000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.737000</td>\n",
       "      <td>-0.813096</td>\n",
       "      <td>-0.844000</td>\n",
       "      <td>-0.749354</td>\n",
       "      <td>-0.756000</td>\n",
       "      <td>-0.540661</td>\n",
       "      <td>-0.637000</td>\n",
       "      <td>-0.562548</td>\n",
       "      <td>-0.999188</td>\n",
       "      <td>-0.399393</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.524000</td>\n",
       "      <td>0.972746</td>\n",
       "      <td>-0.595000</td>\n",
       "      <td>-0.812000</td>\n",
       "      <td>-0.991224</td>\n",
       "      <td>-0.682054</td>\n",
       "      <td>-0.401385</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.202000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.664000</td>\n",
       "      <td>-0.858954</td>\n",
       "      <td>-0.727000</td>\n",
       "      <td>-0.760000</td>\n",
       "      <td>-0.830000</td>\n",
       "      <td>-0.686975</td>\n",
       "      <td>-0.754000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.996682</td>\n",
       "      <td>-0.678000</td>\n",
       "      <td>-0.744000</td>\n",
       "      <td>-0.821662</td>\n",
       "      <td>-0.515000</td>\n",
       "      <td>-0.826000</td>\n",
       "      <td>-0.801436</td>\n",
       "      <td>0.997876</td>\n",
       "      <td>-0.751031</td>\n",
       "      <td>-0.871032</td>\n",
       "      <td>-0.872618</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.944000</td>\n",
       "      <td>-0.646000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.878450</td>\n",
       "      <td>-0.534000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.596000</td>\n",
       "      <td>-0.877229</td>\n",
       "      <td>-0.980581</td>\n",
       "      <td>-0.430000</td>\n",
       "      <td>-0.834000</td>\n",
       "      <td>-0.936000</td>\n",
       "      <td>-0.994865</td>\n",
       "      <td>-0.979749</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.526567</td>\n",
       "      <td>-0.794485</td>\n",
       "      <td>-0.875000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999374</td>\n",
       "      <td>-0.705887</td>\n",
       "      <td>-0.182975</td>\n",
       "      <td>-0.801532</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.620423</td>\n",
       "      <td>-0.632676</td>\n",
       "      <td>-0.830645</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.777672</td>\n",
       "      <td>-0.831067</td>\n",
       "      <td>-0.622000</td>\n",
       "      <td>-0.796072</td>\n",
       "      <td>-0.230000</td>\n",
       "      <td>0.634311</td>\n",
       "      <td>-0.910000</td>\n",
       "      <td>-0.997904</td>\n",
       "      <td>-0.994661</td>\n",
       "      <td>-0.714000</td>\n",
       "      <td>-0.687000</td>\n",
       "      <td>-0.998177</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999603</td>\n",
       "      <td>-0.949000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.551000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.890000</td>\n",
       "      <td>-0.999539</td>\n",
       "      <td>-0.508000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.999002</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.638848</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.680000</td>\n",
       "      <td>-0.650849</td>\n",
       "      <td>-0.736442</td>\n",
       "      <td>-0.852979</td>\n",
       "      <td>-0.592000</td>\n",
       "      <td>-0.983122</td>\n",
       "      <td>-0.588000</td>\n",
       "      <td>-0.999411</td>\n",
       "      <td>-0.789000</td>\n",
       "      <td>-0.577273</td>\n",
       "      <td>-0.716290</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.981490</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>-0.384037</td>\n",
       "      <td>-0.999389</td>\n",
       "      <td>-0.455000</td>\n",
       "      <td>-0.241426</td>\n",
       "      <td>-0.577000</td>\n",
       "      <td>-0.963000</td>\n",
       "      <td>-0.716481</td>\n",
       "      <td>-0.692514</td>\n",
       "      <td>-0.715000</td>\n",
       "      <td>-0.722000</td>\n",
       "      <td>-0.451000</td>\n",
       "      <td>0.850487</td>\n",
       "      <td>-0.761000</td>\n",
       "      <td>-0.841387</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.996288</td>\n",
       "      <td>-0.950000</td>\n",
       "      <td>-0.913161</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.804000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.770000</td>\n",
       "      <td>-0.460213</td>\n",
       "      <td>-0.257016</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.695628</td>\n",
       "      <td>-0.610000</td>\n",
       "      <td>-0.819000</td>\n",
       "      <td>-0.518000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.883295</td>\n",
       "      <td>-0.903486</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.751000</td>\n",
       "      <td>-0.508292</td>\n",
       "      <td>-0.999100</td>\n",
       "      <td>-0.620690</td>\n",
       "      <td>-0.999080</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.962580</td>\n",
       "      <td>0.882912</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>-0.659266</td>\n",
       "      <td>-0.626000</td>\n",
       "      <td>-0.592000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.621000</td>\n",
       "      <td>-0.753000</td>\n",
       "      <td>0.016488</td>\n",
       "      <td>-0.912137</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.719000</td>\n",
       "      <td>-0.998055</td>\n",
       "      <td>-0.641000</td>\n",
       "      <td>0.383625</td>\n",
       "      <td>0.767087</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>0.413318</td>\n",
       "      <td>-0.827126</td>\n",
       "      <td>-0.822204</td>\n",
       "      <td>-0.698610</td>\n",
       "      <td>-0.978401</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.592000</td>\n",
       "      <td>-0.596412</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.695916</td>\n",
       "      <td>-0.937000</td>\n",
       "      <td>-0.825000</td>\n",
       "      <td>-0.779466</td>\n",
       "      <td>-0.658000</td>\n",
       "      <td>-0.776000</td>\n",
       "      <td>-0.576000</td>\n",
       "      <td>0.824581</td>\n",
       "      <td>-0.753000</td>\n",
       "      <td>-0.997835</td>\n",
       "      <td>-0.773000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.721265</td>\n",
       "      <td>-0.724000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.963358</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.989295</td>\n",
       "      <td>-0.845576</td>\n",
       "      <td>-0.749440</td>\n",
       "      <td>-0.763057</td>\n",
       "      <td>-0.994188</td>\n",
       "      <td>-0.623000</td>\n",
       "      <td>-0.602390</td>\n",
       "      <td>-0.548268</td>\n",
       "      <td>-0.998598</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.608000</td>\n",
       "      <td>-0.958000</td>\n",
       "      <td>-0.685659</td>\n",
       "      <td>-0.730394</td>\n",
       "      <td>-0.293000</td>\n",
       "      <td>-0.999305</td>\n",
       "      <td>-0.987997</td>\n",
       "      <td>-0.999915</td>\n",
       "      <td>0.713126</td>\n",
       "      <td>-0.727397</td>\n",
       "      <td>-0.624000</td>\n",
       "      <td>-0.639000</td>\n",
       "      <td>-0.607000</td>\n",
       "      <td>-0.946000</td>\n",
       "      <td>-0.528897</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.715078</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.724000</td>\n",
       "      <td>-0.818000</td>\n",
       "      <td>-0.687000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.863058</td>\n",
       "      <td>-0.752627</td>\n",
       "      <td>-0.736766</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.688000</td>\n",
       "      <td>-0.719672</td>\n",
       "      <td>-0.639597</td>\n",
       "      <td>-0.717282</td>\n",
       "      <td>-0.255447</td>\n",
       "      <td>-0.840000</td>\n",
       "      <td>-0.634000</td>\n",
       "      <td>-0.952000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.616000</td>\n",
       "      <td>-0.646000</td>\n",
       "      <td>-0.657045</td>\n",
       "      <td>-0.803095</td>\n",
       "      <td>-0.937000</td>\n",
       "      <td>-0.594000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.547508</td>\n",
       "      <td>0.103260</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.346000</td>\n",
       "      <td>-0.801779</td>\n",
       "      <td>-0.963296</td>\n",
       "      <td>-0.709120</td>\n",
       "      <td>-0.761828</td>\n",
       "      <td>-0.977000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.800578</td>\n",
       "      <td>-0.754000</td>\n",
       "      <td>-0.687190</td>\n",
       "      <td>-0.708000</td>\n",
       "      <td>-0.884692</td>\n",
       "      <td>-0.785000</td>\n",
       "      <td>-0.741000</td>\n",
       "      <td>-0.827000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.722603</td>\n",
       "      <td>0.491679</td>\n",
       "      <td>-0.999194</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.568757</td>\n",
       "      <td>-0.523000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.979000</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.476046</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.401000</td>\n",
       "      <td>-0.574000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.998156</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.838000</td>\n",
       "      <td>-0.453000</td>\n",
       "      <td>-0.689512</td>\n",
       "      <td>-0.722479</td>\n",
       "      <td>-0.481127</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.880248</td>\n",
       "      <td>-0.638000</td>\n",
       "      <td>-0.603646</td>\n",
       "      <td>-0.742917</td>\n",
       "      <td>-0.637054</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.685159</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.478560</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.583065</td>\n",
       "      <td>-0.658000</td>\n",
       "      <td>-0.631087</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.710000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999912</td>\n",
       "      <td>-0.685632</td>\n",
       "      <td>-0.837827</td>\n",
       "      <td>-0.612000</td>\n",
       "      <td>-0.690000</td>\n",
       "      <td>-0.506000</td>\n",
       "      <td>-0.675000</td>\n",
       "      <td>-0.916000</td>\n",
       "      <td>-0.543000</td>\n",
       "      <td>-0.649081</td>\n",
       "      <td>-0.752000</td>\n",
       "      <td>-0.779447</td>\n",
       "      <td>-0.742134</td>\n",
       "      <td>-0.752923</td>\n",
       "      <td>-0.974034</td>\n",
       "      <td>-0.651000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.442000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.728000</td>\n",
       "      <td>-0.952000</td>\n",
       "      <td>-0.793000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.727057</td>\n",
       "      <td>-0.530383</td>\n",
       "      <td>-0.999281</td>\n",
       "      <td>-0.999908</td>\n",
       "      <td>-0.613000</td>\n",
       "      <td>-0.471403</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.771475</td>\n",
       "      <td>-0.999703</td>\n",
       "      <td>-0.257039</td>\n",
       "      <td>-0.528000</td>\n",
       "      <td>-0.557000</td>\n",
       "      <td>-0.652500</td>\n",
       "      <td>-0.611277</td>\n",
       "      <td>-0.788156</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.794000</td>\n",
       "      <td>-0.947340</td>\n",
       "      <td>-0.827958</td>\n",
       "      <td>-0.795298</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.958173</td>\n",
       "      <td>-0.749407</td>\n",
       "      <td>-0.706373</td>\n",
       "      <td>-0.711203</td>\n",
       "      <td>-0.458000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.790047</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.707592</td>\n",
       "      <td>-0.763298</td>\n",
       "      <td>-0.668000</td>\n",
       "      <td>-0.707100</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-0.828620</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.678242</td>\n",
       "      <td>-0.459000</td>\n",
       "      <td>-0.823295</td>\n",
       "      <td>-0.999774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954385</td>\n",
       "      <td>-0.601841</td>\n",
       "      <td>-0.253890</td>\n",
       "      <td>-0.137000</td>\n",
       "      <td>-0.336527</td>\n",
       "      <td>0.924386</td>\n",
       "      <td>0.928497</td>\n",
       "      <td>-0.991731</td>\n",
       "      <td>-0.389000</td>\n",
       "      <td>-0.999690</td>\n",
       "      <td>-0.034400</td>\n",
       "      <td>-0.991059</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.994872</td>\n",
       "      <td>-0.284000</td>\n",
       "      <td>-0.231000</td>\n",
       "      <td>-0.197587</td>\n",
       "      <td>0.136608</td>\n",
       "      <td>-0.580000</td>\n",
       "      <td>-0.010299</td>\n",
       "      <td>-0.047611</td>\n",
       "      <td>-0.455000</td>\n",
       "      <td>-0.323000</td>\n",
       "      <td>0.840189</td>\n",
       "      <td>0.988089</td>\n",
       "      <td>0.932027</td>\n",
       "      <td>-0.334091</td>\n",
       "      <td>-0.305000</td>\n",
       "      <td>0.184226</td>\n",
       "      <td>-0.779161</td>\n",
       "      <td>0.965953</td>\n",
       "      <td>-0.062965</td>\n",
       "      <td>0.182856</td>\n",
       "      <td>0.022020</td>\n",
       "      <td>-0.995005</td>\n",
       "      <td>-0.075076</td>\n",
       "      <td>-0.303750</td>\n",
       "      <td>-0.307922</td>\n",
       "      <td>0.895814</td>\n",
       "      <td>-0.297000</td>\n",
       "      <td>-0.328000</td>\n",
       "      <td>-0.140061</td>\n",
       "      <td>-0.050025</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.155000</td>\n",
       "      <td>-0.708500</td>\n",
       "      <td>-0.995974</td>\n",
       "      <td>-0.170000</td>\n",
       "      <td>-0.211000</td>\n",
       "      <td>-0.456707</td>\n",
       "      <td>0.988445</td>\n",
       "      <td>-0.151824</td>\n",
       "      <td>0.992417</td>\n",
       "      <td>-0.405671</td>\n",
       "      <td>-0.671000</td>\n",
       "      <td>0.084413</td>\n",
       "      <td>-0.207554</td>\n",
       "      <td>-0.555000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.998380</td>\n",
       "      <td>-0.212386</td>\n",
       "      <td>-0.184168</td>\n",
       "      <td>0.896221</td>\n",
       "      <td>0.010065</td>\n",
       "      <td>-0.109000</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.988925</td>\n",
       "      <td>0.127169</td>\n",
       "      <td>-0.577000</td>\n",
       "      <td>0.117089</td>\n",
       "      <td>0.922956</td>\n",
       "      <td>0.999493</td>\n",
       "      <td>-0.930922</td>\n",
       "      <td>-0.858960</td>\n",
       "      <td>-0.959000</td>\n",
       "      <td>-0.315912</td>\n",
       "      <td>-0.254966</td>\n",
       "      <td>0.971119</td>\n",
       "      <td>-0.182000</td>\n",
       "      <td>-0.285270</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.041200</td>\n",
       "      <td>0.961995</td>\n",
       "      <td>-0.042199</td>\n",
       "      <td>0.729082</td>\n",
       "      <td>-0.999470</td>\n",
       "      <td>-0.115000</td>\n",
       "      <td>0.019951</td>\n",
       "      <td>-0.474000</td>\n",
       "      <td>-0.045583</td>\n",
       "      <td>-0.989000</td>\n",
       "      <td>-0.082886</td>\n",
       "      <td>0.084144</td>\n",
       "      <td>-0.989000</td>\n",
       "      <td>-0.990000</td>\n",
       "      <td>-0.434118</td>\n",
       "      <td>0.921480</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.997677</td>\n",
       "      <td>-0.333247</td>\n",
       "      <td>-0.978000</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>-0.997507</td>\n",
       "      <td>-0.082137</td>\n",
       "      <td>-0.247938</td>\n",
       "      <td>-0.338000</td>\n",
       "      <td>0.919854</td>\n",
       "      <td>-0.036700</td>\n",
       "      <td>-0.364445</td>\n",
       "      <td>-0.972265</td>\n",
       "      <td>-0.345311</td>\n",
       "      <td>-0.611000</td>\n",
       "      <td>0.967405</td>\n",
       "      <td>-0.989000</td>\n",
       "      <td>-0.146533</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>-0.939806</td>\n",
       "      <td>-0.125804</td>\n",
       "      <td>-0.188288</td>\n",
       "      <td>0.981175</td>\n",
       "      <td>-0.982530</td>\n",
       "      <td>-0.308000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.905833</td>\n",
       "      <td>-0.316905</td>\n",
       "      <td>-0.311000</td>\n",
       "      <td>-0.917000</td>\n",
       "      <td>-0.296000</td>\n",
       "      <td>-0.283227</td>\n",
       "      <td>-0.252841</td>\n",
       "      <td>0.901004</td>\n",
       "      <td>0.844818</td>\n",
       "      <td>0.983580</td>\n",
       "      <td>-0.263903</td>\n",
       "      <td>0.164008</td>\n",
       "      <td>-0.930833</td>\n",
       "      <td>0.998580</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>0.191160</td>\n",
       "      <td>0.999727</td>\n",
       "      <td>-0.024309</td>\n",
       "      <td>-0.446000</td>\n",
       "      <td>0.550524</td>\n",
       "      <td>-0.064700</td>\n",
       "      <td>0.990377</td>\n",
       "      <td>-0.963024</td>\n",
       "      <td>0.987322</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.255000</td>\n",
       "      <td>-0.627841</td>\n",
       "      <td>-0.270655</td>\n",
       "      <td>0.894248</td>\n",
       "      <td>-0.381000</td>\n",
       "      <td>-0.108126</td>\n",
       "      <td>-0.294589</td>\n",
       "      <td>0.461314</td>\n",
       "      <td>-0.120918</td>\n",
       "      <td>-0.059050</td>\n",
       "      <td>-0.037455</td>\n",
       "      <td>-0.338597</td>\n",
       "      <td>-0.121000</td>\n",
       "      <td>-0.443000</td>\n",
       "      <td>-0.446334</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>-0.331728</td>\n",
       "      <td>-0.626250</td>\n",
       "      <td>-0.344000</td>\n",
       "      <td>0.960232</td>\n",
       "      <td>0.822151</td>\n",
       "      <td>-0.021953</td>\n",
       "      <td>-0.984303</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>-0.161000</td>\n",
       "      <td>0.143879</td>\n",
       "      <td>-0.651000</td>\n",
       "      <td>-0.215000</td>\n",
       "      <td>0.992593</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.895484</td>\n",
       "      <td>-0.326452</td>\n",
       "      <td>0.957845</td>\n",
       "      <td>-0.381156</td>\n",
       "      <td>0.015445</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>-0.998997</td>\n",
       "      <td>-0.896000</td>\n",
       "      <td>-0.012741</td>\n",
       "      <td>0.895012</td>\n",
       "      <td>0.884771</td>\n",
       "      <td>-0.988000</td>\n",
       "      <td>-0.982862</td>\n",
       "      <td>-0.406440</td>\n",
       "      <td>0.987072</td>\n",
       "      <td>-0.229000</td>\n",
       "      <td>-0.985000</td>\n",
       "      <td>-0.984516</td>\n",
       "      <td>-0.493000</td>\n",
       "      <td>-0.132861</td>\n",
       "      <td>-0.120412</td>\n",
       "      <td>-0.423000</td>\n",
       "      <td>-0.981000</td>\n",
       "      <td>-0.162000</td>\n",
       "      <td>-0.263663</td>\n",
       "      <td>0.980245</td>\n",
       "      <td>-0.395000</td>\n",
       "      <td>0.990204</td>\n",
       "      <td>0.995676</td>\n",
       "      <td>-0.328750</td>\n",
       "      <td>-0.574686</td>\n",
       "      <td>0.096430</td>\n",
       "      <td>-0.171750</td>\n",
       "      <td>-0.043425</td>\n",
       "      <td>0.931822</td>\n",
       "      <td>-0.998492</td>\n",
       "      <td>-0.981711</td>\n",
       "      <td>0.638038</td>\n",
       "      <td>-0.265935</td>\n",
       "      <td>-0.024550</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.323878</td>\n",
       "      <td>-0.983000</td>\n",
       "      <td>0.136296</td>\n",
       "      <td>-0.939250</td>\n",
       "      <td>-0.822588</td>\n",
       "      <td>-0.995607</td>\n",
       "      <td>-0.306356</td>\n",
       "      <td>-0.919983</td>\n",
       "      <td>0.747293</td>\n",
       "      <td>-0.171014</td>\n",
       "      <td>-0.180615</td>\n",
       "      <td>-0.348000</td>\n",
       "      <td>-0.025426</td>\n",
       "      <td>0.976158</td>\n",
       "      <td>-0.099733</td>\n",
       "      <td>-0.971000</td>\n",
       "      <td>-0.298000</td>\n",
       "      <td>0.053468</td>\n",
       "      <td>-0.293750</td>\n",
       "      <td>0.467398</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>-0.657912</td>\n",
       "      <td>0.993226</td>\n",
       "      <td>-0.606882</td>\n",
       "      <td>0.153364</td>\n",
       "      <td>0.996610</td>\n",
       "      <td>-0.061316</td>\n",
       "      <td>0.945341</td>\n",
       "      <td>-0.216750</td>\n",
       "      <td>-0.240848</td>\n",
       "      <td>-0.358000</td>\n",
       "      <td>-0.305000</td>\n",
       "      <td>0.082125</td>\n",
       "      <td>0.999402</td>\n",
       "      <td>-0.307750</td>\n",
       "      <td>-0.235380</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.493500</td>\n",
       "      <td>0.461058</td>\n",
       "      <td>-0.593000</td>\n",
       "      <td>-0.999163</td>\n",
       "      <td>-0.562000</td>\n",
       "      <td>-0.804045</td>\n",
       "      <td>-0.059500</td>\n",
       "      <td>0.793719</td>\n",
       "      <td>0.993155</td>\n",
       "      <td>-0.961000</td>\n",
       "      <td>0.017694</td>\n",
       "      <td>-0.233000</td>\n",
       "      <td>0.941843</td>\n",
       "      <td>-0.074300</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.999834</td>\n",
       "      <td>-0.472000</td>\n",
       "      <td>-0.986234</td>\n",
       "      <td>0.889758</td>\n",
       "      <td>0.069824</td>\n",
       "      <td>-0.733500</td>\n",
       "      <td>-0.273000</td>\n",
       "      <td>-0.963000</td>\n",
       "      <td>-0.998990</td>\n",
       "      <td>0.294538</td>\n",
       "      <td>0.999408</td>\n",
       "      <td>-0.291571</td>\n",
       "      <td>-0.142651</td>\n",
       "      <td>-0.158295</td>\n",
       "      <td>-0.045172</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.951706</td>\n",
       "      <td>-0.025684</td>\n",
       "      <td>-0.060400</td>\n",
       "      <td>0.981575</td>\n",
       "      <td>0.991131</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.257056</td>\n",
       "      <td>0.686365</td>\n",
       "      <td>-0.358000</td>\n",
       "      <td>0.996616</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>-0.997534</td>\n",
       "      <td>-0.379279</td>\n",
       "      <td>0.995856</td>\n",
       "      <td>-0.534336</td>\n",
       "      <td>-0.281000</td>\n",
       "      <td>-0.147750</td>\n",
       "      <td>0.971418</td>\n",
       "      <td>-0.937139</td>\n",
       "      <td>0.052816</td>\n",
       "      <td>-0.089600</td>\n",
       "      <td>-0.933883</td>\n",
       "      <td>-0.270986</td>\n",
       "      <td>0.623520</td>\n",
       "      <td>0.920975</td>\n",
       "      <td>-0.025350</td>\n",
       "      <td>-0.095950</td>\n",
       "      <td>-0.158000</td>\n",
       "      <td>0.122935</td>\n",
       "      <td>0.998218</td>\n",
       "      <td>-0.367000</td>\n",
       "      <td>-0.712984</td>\n",
       "      <td>-0.298000</td>\n",
       "      <td>-0.991000</td>\n",
       "      <td>-0.182000</td>\n",
       "      <td>-0.215847</td>\n",
       "      <td>-0.922000</td>\n",
       "      <td>-0.260373</td>\n",
       "      <td>-0.948141</td>\n",
       "      <td>-0.010390</td>\n",
       "      <td>0.883986</td>\n",
       "      <td>-0.462955</td>\n",
       "      <td>-0.228195</td>\n",
       "      <td>0.706601</td>\n",
       "      <td>-0.118000</td>\n",
       "      <td>-0.005339</td>\n",
       "      <td>0.053785</td>\n",
       "      <td>-0.853519</td>\n",
       "      <td>-0.516500</td>\n",
       "      <td>-0.083964</td>\n",
       "      <td>0.942181</td>\n",
       "      <td>-0.389000</td>\n",
       "      <td>-0.265000</td>\n",
       "      <td>0.980873</td>\n",
       "      <td>-0.978000</td>\n",
       "      <td>0.484047</td>\n",
       "      <td>-0.172000</td>\n",
       "      <td>0.988264</td>\n",
       "      <td>-0.257454</td>\n",
       "      <td>0.705086</td>\n",
       "      <td>-0.119000</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.133670</td>\n",
       "      <td>-0.038405</td>\n",
       "      <td>-0.477861</td>\n",
       "      <td>-0.114000</td>\n",
       "      <td>-0.989000</td>\n",
       "      <td>-0.222000</td>\n",
       "      <td>-0.326956</td>\n",
       "      <td>-0.052721</td>\n",
       "      <td>-0.999020</td>\n",
       "      <td>-0.257138</td>\n",
       "      <td>-0.506519</td>\n",
       "      <td>-0.311000</td>\n",
       "      <td>-0.171000</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-0.413740</td>\n",
       "      <td>0.156090</td>\n",
       "      <td>-0.054446</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>-0.396000</td>\n",
       "      <td>0.813125</td>\n",
       "      <td>-0.479401</td>\n",
       "      <td>-0.315000</td>\n",
       "      <td>0.715184</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.135000</td>\n",
       "      <td>-0.360226</td>\n",
       "      <td>-0.214294</td>\n",
       "      <td>-0.400929</td>\n",
       "      <td>0.714353</td>\n",
       "      <td>0.056350</td>\n",
       "      <td>-0.998913</td>\n",
       "      <td>0.059877</td>\n",
       "      <td>0.990829</td>\n",
       "      <td>-0.884216</td>\n",
       "      <td>0.280688</td>\n",
       "      <td>-0.345000</td>\n",
       "      <td>-0.498270</td>\n",
       "      <td>-0.287000</td>\n",
       "      <td>-0.322000</td>\n",
       "      <td>0.729921</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.347295</td>\n",
       "      <td>-0.251807</td>\n",
       "      <td>-0.275757</td>\n",
       "      <td>-0.250726</td>\n",
       "      <td>-0.434076</td>\n",
       "      <td>0.813875</td>\n",
       "      <td>-0.264000</td>\n",
       "      <td>-0.091596</td>\n",
       "      <td>-0.988965</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>-0.237000</td>\n",
       "      <td>0.993749</td>\n",
       "      <td>-0.804750</td>\n",
       "      <td>0.289769</td>\n",
       "      <td>-0.000922</td>\n",
       "      <td>-0.026900</td>\n",
       "      <td>-0.996114</td>\n",
       "      <td>0.875521</td>\n",
       "      <td>0.099671</td>\n",
       "      <td>-0.999783</td>\n",
       "      <td>-0.100789</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.151936</td>\n",
       "      <td>-0.024102</td>\n",
       "      <td>-0.931396</td>\n",
       "      <td>-0.468429</td>\n",
       "      <td>-0.999984</td>\n",
       "      <td>-0.359000</td>\n",
       "      <td>0.897098</td>\n",
       "      <td>-0.241994</td>\n",
       "      <td>0.840746</td>\n",
       "      <td>0.023563</td>\n",
       "      <td>-0.982000</td>\n",
       "      <td>-0.507976</td>\n",
       "      <td>-0.069539</td>\n",
       "      <td>-0.113204</td>\n",
       "      <td>-0.376000</td>\n",
       "      <td>0.123467</td>\n",
       "      <td>-0.898200</td>\n",
       "      <td>0.973259</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.991000</td>\n",
       "      <td>0.138315</td>\n",
       "      <td>-0.983000</td>\n",
       "      <td>-0.614766</td>\n",
       "      <td>-0.066200</td>\n",
       "      <td>0.041337</td>\n",
       "      <td>-0.161000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.962180</td>\n",
       "      <td>-0.085562</td>\n",
       "      <td>-0.999939</td>\n",
       "      <td>-0.989598</td>\n",
       "      <td>-0.962000</td>\n",
       "      <td>-0.128428</td>\n",
       "      <td>-0.289807</td>\n",
       "      <td>-0.144000</td>\n",
       "      <td>-0.086200</td>\n",
       "      <td>-0.093945</td>\n",
       "      <td>-0.212395</td>\n",
       "      <td>0.976282</td>\n",
       "      <td>0.125205</td>\n",
       "      <td>0.910419</td>\n",
       "      <td>-0.232497</td>\n",
       "      <td>-0.105000</td>\n",
       "      <td>-0.214054</td>\n",
       "      <td>0.955292</td>\n",
       "      <td>0.321897</td>\n",
       "      <td>-0.088170</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.166574</td>\n",
       "      <td>0.679187</td>\n",
       "      <td>0.996178</td>\n",
       "      <td>0.556878</td>\n",
       "      <td>0.878197</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.162919</td>\n",
       "      <td>0.090027</td>\n",
       "      <td>-0.841072</td>\n",
       "      <td>-0.226000</td>\n",
       "      <td>-0.104000</td>\n",
       "      <td>0.222175</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>0.955317</td>\n",
       "      <td>0.087440</td>\n",
       "      <td>-0.052403</td>\n",
       "      <td>0.025795</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>-0.223062</td>\n",
       "      <td>-0.999444</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.215464</td>\n",
       "      <td>-0.465949</td>\n",
       "      <td>-0.231820</td>\n",
       "      <td>-0.387000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>0.195281</td>\n",
       "      <td>-0.214000</td>\n",
       "      <td>-0.388000</td>\n",
       "      <td>-0.184867</td>\n",
       "      <td>0.139450</td>\n",
       "      <td>-0.997523</td>\n",
       "      <td>0.996744</td>\n",
       "      <td>-0.980000</td>\n",
       "      <td>-0.218092</td>\n",
       "      <td>-0.476000</td>\n",
       "      <td>-0.130000</td>\n",
       "      <td>-0.226527</td>\n",
       "      <td>-0.717840</td>\n",
       "      <td>0.937396</td>\n",
       "      <td>-0.997993</td>\n",
       "      <td>-0.126000</td>\n",
       "      <td>0.102501</td>\n",
       "      <td>-0.512000</td>\n",
       "      <td>-0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989176</td>\n",
       "      <td>0.445204</td>\n",
       "      <td>-0.037074</td>\n",
       "      <td>0.043456</td>\n",
       "      <td>0.179384</td>\n",
       "      <td>0.980881</td>\n",
       "      <td>0.987984</td>\n",
       "      <td>-0.965000</td>\n",
       "      <td>-0.304893</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.111090</td>\n",
       "      <td>-0.987886</td>\n",
       "      <td>-0.945895</td>\n",
       "      <td>-0.981399</td>\n",
       "      <td>0.240158</td>\n",
       "      <td>0.030314</td>\n",
       "      <td>-0.037576</td>\n",
       "      <td>0.297671</td>\n",
       "      <td>-0.451999</td>\n",
       "      <td>0.183631</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>-0.272829</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.957810</td>\n",
       "      <td>0.992193</td>\n",
       "      <td>0.977598</td>\n",
       "      <td>-0.144500</td>\n",
       "      <td>-0.164992</td>\n",
       "      <td>0.392001</td>\n",
       "      <td>-0.645000</td>\n",
       "      <td>0.992193</td>\n",
       "      <td>0.080209</td>\n",
       "      <td>0.245125</td>\n",
       "      <td>0.154092</td>\n",
       "      <td>-0.986000</td>\n",
       "      <td>0.147021</td>\n",
       "      <td>-0.113500</td>\n",
       "      <td>-0.120543</td>\n",
       "      <td>0.981907</td>\n",
       "      <td>-0.072900</td>\n",
       "      <td>-0.038300</td>\n",
       "      <td>0.048378</td>\n",
       "      <td>0.112366</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>-0.058500</td>\n",
       "      <td>-0.387000</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>0.138609</td>\n",
       "      <td>0.499576</td>\n",
       "      <td>-0.265861</td>\n",
       "      <td>0.993463</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.997988</td>\n",
       "      <td>-0.213421</td>\n",
       "      <td>-0.277092</td>\n",
       "      <td>0.283191</td>\n",
       "      <td>-0.010348</td>\n",
       "      <td>-0.239951</td>\n",
       "      <td>-0.999968</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>0.076596</td>\n",
       "      <td>-0.115000</td>\n",
       "      <td>0.985208</td>\n",
       "      <td>0.180975</td>\n",
       "      <td>0.096354</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>0.284351</td>\n",
       "      <td>-0.316668</td>\n",
       "      <td>0.779923</td>\n",
       "      <td>0.986674</td>\n",
       "      <td>0.999724</td>\n",
       "      <td>-0.789119</td>\n",
       "      <td>-0.712000</td>\n",
       "      <td>-0.911503</td>\n",
       "      <td>-0.124922</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.988922</td>\n",
       "      <td>0.014601</td>\n",
       "      <td>-0.154000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>0.071010</td>\n",
       "      <td>0.986258</td>\n",
       "      <td>0.057840</td>\n",
       "      <td>0.927011</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>0.042916</td>\n",
       "      <td>0.202190</td>\n",
       "      <td>-0.232000</td>\n",
       "      <td>0.046255</td>\n",
       "      <td>-0.982176</td>\n",
       "      <td>0.142965</td>\n",
       "      <td>0.287673</td>\n",
       "      <td>-0.979000</td>\n",
       "      <td>-0.964420</td>\n",
       "      <td>0.543565</td>\n",
       "      <td>0.959628</td>\n",
       "      <td>0.006510</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>-0.138848</td>\n",
       "      <td>-0.845000</td>\n",
       "      <td>-0.978000</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>-0.018600</td>\n",
       "      <td>-0.072000</td>\n",
       "      <td>-0.105719</td>\n",
       "      <td>0.979791</td>\n",
       "      <td>0.102340</td>\n",
       "      <td>-0.320725</td>\n",
       "      <td>-0.955680</td>\n",
       "      <td>-0.089613</td>\n",
       "      <td>-0.229906</td>\n",
       "      <td>0.983467</td>\n",
       "      <td>-0.981786</td>\n",
       "      <td>0.056518</td>\n",
       "      <td>0.352925</td>\n",
       "      <td>-0.852000</td>\n",
       "      <td>0.693085</td>\n",
       "      <td>-0.103000</td>\n",
       "      <td>0.993725</td>\n",
       "      <td>-0.966000</td>\n",
       "      <td>-0.186888</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.007433</td>\n",
       "      <td>-0.116634</td>\n",
       "      <td>-0.188512</td>\n",
       "      <td>-0.867117</td>\n",
       "      <td>-0.153000</td>\n",
       "      <td>-0.177000</td>\n",
       "      <td>-0.067939</td>\n",
       "      <td>0.978678</td>\n",
       "      <td>0.948014</td>\n",
       "      <td>0.996208</td>\n",
       "      <td>-0.030550</td>\n",
       "      <td>0.343855</td>\n",
       "      <td>-0.889478</td>\n",
       "      <td>0.999177</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>-0.991000</td>\n",
       "      <td>0.350612</td>\n",
       "      <td>0.999837</td>\n",
       "      <td>0.138156</td>\n",
       "      <td>-0.284000</td>\n",
       "      <td>0.828365</td>\n",
       "      <td>0.072572</td>\n",
       "      <td>0.994742</td>\n",
       "      <td>-0.920000</td>\n",
       "      <td>0.997076</td>\n",
       "      <td>-0.989505</td>\n",
       "      <td>-0.170253</td>\n",
       "      <td>-0.382068</td>\n",
       "      <td>-0.068800</td>\n",
       "      <td>0.974395</td>\n",
       "      <td>-0.010444</td>\n",
       "      <td>0.153136</td>\n",
       "      <td>-0.062325</td>\n",
       "      <td>0.929154</td>\n",
       "      <td>0.311476</td>\n",
       "      <td>0.154330</td>\n",
       "      <td>0.041014</td>\n",
       "      <td>-0.162000</td>\n",
       "      <td>0.028298</td>\n",
       "      <td>-0.247000</td>\n",
       "      <td>-0.152575</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>-0.155000</td>\n",
       "      <td>-0.348961</td>\n",
       "      <td>-0.285774</td>\n",
       "      <td>0.995799</td>\n",
       "      <td>0.959612</td>\n",
       "      <td>0.184579</td>\n",
       "      <td>-0.935000</td>\n",
       "      <td>-0.930000</td>\n",
       "      <td>0.774889</td>\n",
       "      <td>0.175716</td>\n",
       "      <td>0.364825</td>\n",
       "      <td>-0.434500</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.998300</td>\n",
       "      <td>0.954936</td>\n",
       "      <td>0.967094</td>\n",
       "      <td>-0.120752</td>\n",
       "      <td>0.987954</td>\n",
       "      <td>0.260044</td>\n",
       "      <td>0.646168</td>\n",
       "      <td>-0.967000</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-0.820500</td>\n",
       "      <td>0.187129</td>\n",
       "      <td>0.977636</td>\n",
       "      <td>0.978527</td>\n",
       "      <td>-0.948000</td>\n",
       "      <td>-0.931000</td>\n",
       "      <td>-0.186874</td>\n",
       "      <td>0.996075</td>\n",
       "      <td>-0.086408</td>\n",
       "      <td>-0.974000</td>\n",
       "      <td>-0.963000</td>\n",
       "      <td>0.598045</td>\n",
       "      <td>0.041943</td>\n",
       "      <td>-0.054374</td>\n",
       "      <td>-0.375500</td>\n",
       "      <td>-0.952000</td>\n",
       "      <td>0.026259</td>\n",
       "      <td>-0.113000</td>\n",
       "      <td>0.995544</td>\n",
       "      <td>-0.277000</td>\n",
       "      <td>0.998520</td>\n",
       "      <td>0.998737</td>\n",
       "      <td>-0.158000</td>\n",
       "      <td>0.285794</td>\n",
       "      <td>0.777715</td>\n",
       "      <td>0.008459</td>\n",
       "      <td>0.046268</td>\n",
       "      <td>0.982414</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>-0.880367</td>\n",
       "      <td>0.955925</td>\n",
       "      <td>0.265038</td>\n",
       "      <td>0.152273</td>\n",
       "      <td>-0.991000</td>\n",
       "      <td>-0.242962</td>\n",
       "      <td>-0.826500</td>\n",
       "      <td>0.326483</td>\n",
       "      <td>-0.568454</td>\n",
       "      <td>-0.297624</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>0.017097</td>\n",
       "      <td>-0.607839</td>\n",
       "      <td>0.963652</td>\n",
       "      <td>0.036144</td>\n",
       "      <td>-0.009247</td>\n",
       "      <td>-0.131500</td>\n",
       "      <td>0.161214</td>\n",
       "      <td>0.993538</td>\n",
       "      <td>-0.038200</td>\n",
       "      <td>-0.859814</td>\n",
       "      <td>-0.111298</td>\n",
       "      <td>0.249378</td>\n",
       "      <td>-0.106849</td>\n",
       "      <td>0.790405</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>-0.148792</td>\n",
       "      <td>0.998316</td>\n",
       "      <td>-0.489000</td>\n",
       "      <td>0.205691</td>\n",
       "      <td>0.998359</td>\n",
       "      <td>0.149943</td>\n",
       "      <td>0.967772</td>\n",
       "      <td>-0.013533</td>\n",
       "      <td>-0.064875</td>\n",
       "      <td>-0.075315</td>\n",
       "      <td>-0.208000</td>\n",
       "      <td>0.198819</td>\n",
       "      <td>0.999845</td>\n",
       "      <td>-0.051737</td>\n",
       "      <td>-0.113000</td>\n",
       "      <td>-0.991026</td>\n",
       "      <td>-0.017840</td>\n",
       "      <td>0.615349</td>\n",
       "      <td>-0.371000</td>\n",
       "      <td>-0.997178</td>\n",
       "      <td>-0.314243</td>\n",
       "      <td>-0.450332</td>\n",
       "      <td>0.040315</td>\n",
       "      <td>0.956561</td>\n",
       "      <td>0.998444</td>\n",
       "      <td>-0.827997</td>\n",
       "      <td>0.216675</td>\n",
       "      <td>0.011731</td>\n",
       "      <td>0.997530</td>\n",
       "      <td>-0.001650</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>-0.385000</td>\n",
       "      <td>-0.955187</td>\n",
       "      <td>0.968664</td>\n",
       "      <td>0.250652</td>\n",
       "      <td>-0.529708</td>\n",
       "      <td>-0.045705</td>\n",
       "      <td>-0.825000</td>\n",
       "      <td>-0.994674</td>\n",
       "      <td>0.648756</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.517365</td>\n",
       "      <td>0.041391</td>\n",
       "      <td>0.088582</td>\n",
       "      <td>0.175171</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.595846</td>\n",
       "      <td>0.231734</td>\n",
       "      <td>0.165757</td>\n",
       "      <td>0.988693</td>\n",
       "      <td>0.997876</td>\n",
       "      <td>-0.994095</td>\n",
       "      <td>-0.152000</td>\n",
       "      <td>0.905977</td>\n",
       "      <td>-0.185806</td>\n",
       "      <td>0.999212</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>-0.973000</td>\n",
       "      <td>0.183749</td>\n",
       "      <td>0.998932</td>\n",
       "      <td>-0.277500</td>\n",
       "      <td>-0.116000</td>\n",
       "      <td>-0.030100</td>\n",
       "      <td>0.984296</td>\n",
       "      <td>-0.531528</td>\n",
       "      <td>0.218429</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>-0.891000</td>\n",
       "      <td>-0.114680</td>\n",
       "      <td>0.920896</td>\n",
       "      <td>0.975089</td>\n",
       "      <td>0.134503</td>\n",
       "      <td>0.132511</td>\n",
       "      <td>-0.076895</td>\n",
       "      <td>0.261673</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>-0.143188</td>\n",
       "      <td>-0.597000</td>\n",
       "      <td>-0.137000</td>\n",
       "      <td>-0.922000</td>\n",
       "      <td>0.011787</td>\n",
       "      <td>-0.151000</td>\n",
       "      <td>-0.855000</td>\n",
       "      <td>0.221707</td>\n",
       "      <td>-0.805000</td>\n",
       "      <td>0.656440</td>\n",
       "      <td>0.950278</td>\n",
       "      <td>-0.237385</td>\n",
       "      <td>-0.040650</td>\n",
       "      <td>0.941936</td>\n",
       "      <td>-0.023000</td>\n",
       "      <td>0.172994</td>\n",
       "      <td>0.213809</td>\n",
       "      <td>-0.539932</td>\n",
       "      <td>0.086466</td>\n",
       "      <td>-0.032600</td>\n",
       "      <td>0.991273</td>\n",
       "      <td>-0.023403</td>\n",
       "      <td>-0.174675</td>\n",
       "      <td>0.991791</td>\n",
       "      <td>-0.904000</td>\n",
       "      <td>0.772209</td>\n",
       "      <td>0.277082</td>\n",
       "      <td>0.996623</td>\n",
       "      <td>-0.038859</td>\n",
       "      <td>0.951219</td>\n",
       "      <td>-0.048116</td>\n",
       "      <td>0.213946</td>\n",
       "      <td>0.676108</td>\n",
       "      <td>0.118721</td>\n",
       "      <td>0.046060</td>\n",
       "      <td>-0.054279</td>\n",
       "      <td>-0.927000</td>\n",
       "      <td>-0.031693</td>\n",
       "      <td>-0.127000</td>\n",
       "      <td>0.122508</td>\n",
       "      <td>-0.996456</td>\n",
       "      <td>0.541228</td>\n",
       "      <td>-0.324500</td>\n",
       "      <td>-0.003751</td>\n",
       "      <td>0.171511</td>\n",
       "      <td>-0.982079</td>\n",
       "      <td>0.303367</td>\n",
       "      <td>0.444012</td>\n",
       "      <td>0.207530</td>\n",
       "      <td>0.222210</td>\n",
       "      <td>-0.112004</td>\n",
       "      <td>0.961053</td>\n",
       "      <td>-0.199015</td>\n",
       "      <td>-0.016350</td>\n",
       "      <td>0.909687</td>\n",
       "      <td>-0.993845</td>\n",
       "      <td>0.035860</td>\n",
       "      <td>-0.155462</td>\n",
       "      <td>-0.043949</td>\n",
       "      <td>-0.217500</td>\n",
       "      <td>0.916131</td>\n",
       "      <td>0.276865</td>\n",
       "      <td>-0.990000</td>\n",
       "      <td>0.242910</td>\n",
       "      <td>0.997725</td>\n",
       "      <td>-0.808000</td>\n",
       "      <td>0.447064</td>\n",
       "      <td>-0.218000</td>\n",
       "      <td>0.255374</td>\n",
       "      <td>-0.231412</td>\n",
       "      <td>-0.255198</td>\n",
       "      <td>0.906029</td>\n",
       "      <td>-0.999953</td>\n",
       "      <td>-0.099600</td>\n",
       "      <td>-0.060346</td>\n",
       "      <td>-0.000362</td>\n",
       "      <td>-0.055300</td>\n",
       "      <td>-0.223683</td>\n",
       "      <td>0.986055</td>\n",
       "      <td>-0.181981</td>\n",
       "      <td>0.171202</td>\n",
       "      <td>-0.943034</td>\n",
       "      <td>-0.969200</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>0.998354</td>\n",
       "      <td>-0.672214</td>\n",
       "      <td>0.888770</td>\n",
       "      <td>0.170024</td>\n",
       "      <td>0.064967</td>\n",
       "      <td>-0.986000</td>\n",
       "      <td>0.971207</td>\n",
       "      <td>0.583595</td>\n",
       "      <td>-0.998496</td>\n",
       "      <td>0.136594</td>\n",
       "      <td>-0.989000</td>\n",
       "      <td>0.284013</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>-0.852000</td>\n",
       "      <td>-0.306000</td>\n",
       "      <td>-0.998717</td>\n",
       "      <td>-0.204153</td>\n",
       "      <td>0.974323</td>\n",
       "      <td>-0.064350</td>\n",
       "      <td>0.947386</td>\n",
       "      <td>0.217635</td>\n",
       "      <td>-0.943129</td>\n",
       "      <td>-0.100477</td>\n",
       "      <td>0.141079</td>\n",
       "      <td>-0.056525</td>\n",
       "      <td>-0.175500</td>\n",
       "      <td>0.310165</td>\n",
       "      <td>-0.543000</td>\n",
       "      <td>0.987591</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.946000</td>\n",
       "      <td>0.300556</td>\n",
       "      <td>-0.928000</td>\n",
       "      <td>0.062319</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.134225</td>\n",
       "      <td>-0.052300</td>\n",
       "      <td>-0.995165</td>\n",
       "      <td>-0.758735</td>\n",
       "      <td>0.143869</td>\n",
       "      <td>-0.998000</td>\n",
       "      <td>-0.960460</td>\n",
       "      <td>-0.885000</td>\n",
       "      <td>0.142049</td>\n",
       "      <td>-0.236000</td>\n",
       "      <td>0.030745</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>0.149092</td>\n",
       "      <td>0.020349</td>\n",
       "      <td>0.989491</td>\n",
       "      <td>0.313874</td>\n",
       "      <td>0.989648</td>\n",
       "      <td>-0.030026</td>\n",
       "      <td>-0.031300</td>\n",
       "      <td>0.030396</td>\n",
       "      <td>0.988817</td>\n",
       "      <td>0.528637</td>\n",
       "      <td>0.066390</td>\n",
       "      <td>-0.999928</td>\n",
       "      <td>0.261203</td>\n",
       "      <td>0.910099</td>\n",
       "      <td>0.997985</td>\n",
       "      <td>0.830977</td>\n",
       "      <td>0.988346</td>\n",
       "      <td>-0.993000</td>\n",
       "      <td>0.019168</td>\n",
       "      <td>0.244346</td>\n",
       "      <td>-0.429000</td>\n",
       "      <td>0.180847</td>\n",
       "      <td>-0.022238</td>\n",
       "      <td>0.315518</td>\n",
       "      <td>-0.999926</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>-0.144094</td>\n",
       "      <td>-0.985439</td>\n",
       "      <td>0.990643</td>\n",
       "      <td>0.282580</td>\n",
       "      <td>0.066373</td>\n",
       "      <td>0.234510</td>\n",
       "      <td>0.351656</td>\n",
       "      <td>-0.021150</td>\n",
       "      <td>-0.996859</td>\n",
       "      <td>-0.996611</td>\n",
       "      <td>-0.068000</td>\n",
       "      <td>-0.335000</td>\n",
       "      <td>-0.020850</td>\n",
       "      <td>-0.218660</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.938465</td>\n",
       "      <td>0.825024</td>\n",
       "      <td>-0.019347</td>\n",
       "      <td>-0.106346</td>\n",
       "      <td>-0.138382</td>\n",
       "      <td>0.261339</td>\n",
       "      <td>-0.981609</td>\n",
       "      <td>0.999213</td>\n",
       "      <td>-0.825000</td>\n",
       "      <td>-0.057450</td>\n",
       "      <td>-0.135000</td>\n",
       "      <td>0.021458</td>\n",
       "      <td>-0.021597</td>\n",
       "      <td>-0.354000</td>\n",
       "      <td>0.990094</td>\n",
       "      <td>-0.987879</td>\n",
       "      <td>0.079729</td>\n",
       "      <td>0.192325</td>\n",
       "      <td>-0.410675</td>\n",
       "      <td>-0.662256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.996965</td>\n",
       "      <td>0.862085</td>\n",
       "      <td>0.151849</td>\n",
       "      <td>0.217468</td>\n",
       "      <td>0.513341</td>\n",
       "      <td>0.987294</td>\n",
       "      <td>0.998601</td>\n",
       "      <td>-0.937000</td>\n",
       "      <td>-0.092000</td>\n",
       "      <td>-0.996339</td>\n",
       "      <td>0.289331</td>\n",
       "      <td>-0.965764</td>\n",
       "      <td>-0.650824</td>\n",
       "      <td>-0.866538</td>\n",
       "      <td>0.635867</td>\n",
       "      <td>0.218685</td>\n",
       "      <td>0.105658</td>\n",
       "      <td>0.381090</td>\n",
       "      <td>-0.255075</td>\n",
       "      <td>0.431569</td>\n",
       "      <td>0.177924</td>\n",
       "      <td>-0.077741</td>\n",
       "      <td>0.555593</td>\n",
       "      <td>0.978865</td>\n",
       "      <td>0.997929</td>\n",
       "      <td>0.993685</td>\n",
       "      <td>-0.045200</td>\n",
       "      <td>0.015421</td>\n",
       "      <td>0.616405</td>\n",
       "      <td>0.240865</td>\n",
       "      <td>0.997460</td>\n",
       "      <td>0.236947</td>\n",
       "      <td>0.408357</td>\n",
       "      <td>0.280797</td>\n",
       "      <td>-0.973000</td>\n",
       "      <td>0.204207</td>\n",
       "      <td>0.122909</td>\n",
       "      <td>-0.017600</td>\n",
       "      <td>0.997176</td>\n",
       "      <td>0.101946</td>\n",
       "      <td>0.208273</td>\n",
       "      <td>0.205288</td>\n",
       "      <td>0.185189</td>\n",
       "      <td>-0.988471</td>\n",
       "      <td>0.118581</td>\n",
       "      <td>-0.072770</td>\n",
       "      <td>-0.951942</td>\n",
       "      <td>0.327591</td>\n",
       "      <td>0.869873</td>\n",
       "      <td>-0.192000</td>\n",
       "      <td>0.997055</td>\n",
       "      <td>0.066217</td>\n",
       "      <td>0.999516</td>\n",
       "      <td>-0.136091</td>\n",
       "      <td>0.327171</td>\n",
       "      <td>0.425997</td>\n",
       "      <td>0.068917</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.985000</td>\n",
       "      <td>0.260837</td>\n",
       "      <td>0.129498</td>\n",
       "      <td>0.995426</td>\n",
       "      <td>0.333388</td>\n",
       "      <td>0.185355</td>\n",
       "      <td>-0.967654</td>\n",
       "      <td>0.999400</td>\n",
       "      <td>0.649315</td>\n",
       "      <td>-0.105916</td>\n",
       "      <td>0.982717</td>\n",
       "      <td>0.998384</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>-0.589000</td>\n",
       "      <td>-0.411841</td>\n",
       "      <td>-0.614103</td>\n",
       "      <td>0.164697</td>\n",
       "      <td>0.402405</td>\n",
       "      <td>0.997538</td>\n",
       "      <td>0.170162</td>\n",
       "      <td>-0.036005</td>\n",
       "      <td>-0.992000</td>\n",
       "      <td>0.274360</td>\n",
       "      <td>0.995111</td>\n",
       "      <td>0.468813</td>\n",
       "      <td>0.970281</td>\n",
       "      <td>-0.894000</td>\n",
       "      <td>0.183809</td>\n",
       "      <td>0.403920</td>\n",
       "      <td>-0.029962</td>\n",
       "      <td>0.196178</td>\n",
       "      <td>-0.925000</td>\n",
       "      <td>0.408095</td>\n",
       "      <td>0.519803</td>\n",
       "      <td>-0.921195</td>\n",
       "      <td>-0.813339</td>\n",
       "      <td>0.945886</td>\n",
       "      <td>0.991935</td>\n",
       "      <td>0.257227</td>\n",
       "      <td>-0.977000</td>\n",
       "      <td>-0.040300</td>\n",
       "      <td>-0.345250</td>\n",
       "      <td>-0.915968</td>\n",
       "      <td>-0.982000</td>\n",
       "      <td>0.181155</td>\n",
       "      <td>-0.003992</td>\n",
       "      <td>0.071514</td>\n",
       "      <td>0.987081</td>\n",
       "      <td>0.279408</td>\n",
       "      <td>-0.170194</td>\n",
       "      <td>-0.813438</td>\n",
       "      <td>0.102589</td>\n",
       "      <td>0.116902</td>\n",
       "      <td>0.996899</td>\n",
       "      <td>-0.921000</td>\n",
       "      <td>0.116817</td>\n",
       "      <td>0.400971</td>\n",
       "      <td>-0.731718</td>\n",
       "      <td>0.975920</td>\n",
       "      <td>0.072950</td>\n",
       "      <td>0.995597</td>\n",
       "      <td>-0.905305</td>\n",
       "      <td>-0.006172</td>\n",
       "      <td>-0.986434</td>\n",
       "      <td>0.575902</td>\n",
       "      <td>-0.044002</td>\n",
       "      <td>-0.008066</td>\n",
       "      <td>-0.510250</td>\n",
       "      <td>0.064266</td>\n",
       "      <td>-0.041250</td>\n",
       "      <td>-0.001050</td>\n",
       "      <td>0.997550</td>\n",
       "      <td>0.989146</td>\n",
       "      <td>0.998103</td>\n",
       "      <td>0.137799</td>\n",
       "      <td>0.400549</td>\n",
       "      <td>-0.510170</td>\n",
       "      <td>0.999804</td>\n",
       "      <td>-0.980560</td>\n",
       "      <td>-0.961007</td>\n",
       "      <td>0.407133</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.179926</td>\n",
       "      <td>-0.039002</td>\n",
       "      <td>0.951152</td>\n",
       "      <td>0.288511</td>\n",
       "      <td>0.999168</td>\n",
       "      <td>-0.870766</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>-0.952464</td>\n",
       "      <td>0.045158</td>\n",
       "      <td>-0.209188</td>\n",
       "      <td>0.015664</td>\n",
       "      <td>0.995758</td>\n",
       "      <td>0.233753</td>\n",
       "      <td>0.441246</td>\n",
       "      <td>0.126793</td>\n",
       "      <td>0.976722</td>\n",
       "      <td>0.705124</td>\n",
       "      <td>0.216348</td>\n",
       "      <td>0.223171</td>\n",
       "      <td>-0.043500</td>\n",
       "      <td>0.208665</td>\n",
       "      <td>-0.132000</td>\n",
       "      <td>0.051439</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>-0.099149</td>\n",
       "      <td>-0.102535</td>\n",
       "      <td>-0.068600</td>\n",
       "      <td>0.999010</td>\n",
       "      <td>0.988999</td>\n",
       "      <td>0.406056</td>\n",
       "      <td>-0.906158</td>\n",
       "      <td>-0.562750</td>\n",
       "      <td>0.868686</td>\n",
       "      <td>0.592236</td>\n",
       "      <td>0.577762</td>\n",
       "      <td>0.290063</td>\n",
       "      <td>0.179736</td>\n",
       "      <td>0.999477</td>\n",
       "      <td>0.989176</td>\n",
       "      <td>0.992959</td>\n",
       "      <td>-0.056775</td>\n",
       "      <td>0.994883</td>\n",
       "      <td>0.551293</td>\n",
       "      <td>0.769223</td>\n",
       "      <td>-0.714198</td>\n",
       "      <td>-0.984573</td>\n",
       "      <td>-0.290250</td>\n",
       "      <td>0.503032</td>\n",
       "      <td>0.996706</td>\n",
       "      <td>0.988485</td>\n",
       "      <td>-0.714000</td>\n",
       "      <td>0.022402</td>\n",
       "      <td>-0.020710</td>\n",
       "      <td>0.997537</td>\n",
       "      <td>0.128657</td>\n",
       "      <td>-0.923068</td>\n",
       "      <td>-0.866589</td>\n",
       "      <td>0.936345</td>\n",
       "      <td>0.289723</td>\n",
       "      <td>0.143170</td>\n",
       "      <td>-0.192946</td>\n",
       "      <td>-0.829000</td>\n",
       "      <td>0.249658</td>\n",
       "      <td>0.081884</td>\n",
       "      <td>0.998833</td>\n",
       "      <td>-0.161009</td>\n",
       "      <td>0.999176</td>\n",
       "      <td>0.999594</td>\n",
       "      <td>-0.087608</td>\n",
       "      <td>0.924195</td>\n",
       "      <td>0.977444</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>0.250531</td>\n",
       "      <td>0.992128</td>\n",
       "      <td>-0.985885</td>\n",
       "      <td>-0.497885</td>\n",
       "      <td>0.990082</td>\n",
       "      <td>0.703598</td>\n",
       "      <td>0.210359</td>\n",
       "      <td>-0.986252</td>\n",
       "      <td>0.034154</td>\n",
       "      <td>-0.200617</td>\n",
       "      <td>0.520107</td>\n",
       "      <td>0.129291</td>\n",
       "      <td>-0.044375</td>\n",
       "      <td>-0.969000</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.283166</td>\n",
       "      <td>0.993970</td>\n",
       "      <td>0.086338</td>\n",
       "      <td>0.238438</td>\n",
       "      <td>-0.066725</td>\n",
       "      <td>0.352481</td>\n",
       "      <td>0.996944</td>\n",
       "      <td>0.125733</td>\n",
       "      <td>-0.774796</td>\n",
       "      <td>-0.049450</td>\n",
       "      <td>0.478675</td>\n",
       "      <td>0.172777</td>\n",
       "      <td>0.918010</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.188794</td>\n",
       "      <td>0.998977</td>\n",
       "      <td>0.211893</td>\n",
       "      <td>0.366213</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>0.363179</td>\n",
       "      <td>0.991776</td>\n",
       "      <td>0.031416</td>\n",
       "      <td>0.187617</td>\n",
       "      <td>0.134090</td>\n",
       "      <td>-0.009545</td>\n",
       "      <td>0.353225</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.165813</td>\n",
       "      <td>0.044188</td>\n",
       "      <td>-0.932000</td>\n",
       "      <td>0.167349</td>\n",
       "      <td>0.886808</td>\n",
       "      <td>-0.155000</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>-0.094940</td>\n",
       "      <td>-0.288288</td>\n",
       "      <td>0.227546</td>\n",
       "      <td>0.987421</td>\n",
       "      <td>0.999726</td>\n",
       "      <td>-0.707416</td>\n",
       "      <td>0.325266</td>\n",
       "      <td>0.208894</td>\n",
       "      <td>0.999543</td>\n",
       "      <td>0.147346</td>\n",
       "      <td>-0.974000</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>-0.199673</td>\n",
       "      <td>-0.932000</td>\n",
       "      <td>0.989558</td>\n",
       "      <td>0.347250</td>\n",
       "      <td>0.409999</td>\n",
       "      <td>0.197654</td>\n",
       "      <td>-0.330750</td>\n",
       "      <td>-0.982000</td>\n",
       "      <td>0.766516</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.905841</td>\n",
       "      <td>0.102062</td>\n",
       "      <td>0.414465</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>-0.997382</td>\n",
       "      <td>-0.993690</td>\n",
       "      <td>0.010503</td>\n",
       "      <td>0.613621</td>\n",
       "      <td>0.451931</td>\n",
       "      <td>0.997004</td>\n",
       "      <td>0.998647</td>\n",
       "      <td>-0.974000</td>\n",
       "      <td>-0.013000</td>\n",
       "      <td>0.934253</td>\n",
       "      <td>0.009332</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>-0.801772</td>\n",
       "      <td>0.437833</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>-0.056300</td>\n",
       "      <td>0.212601</td>\n",
       "      <td>0.086464</td>\n",
       "      <td>0.996357</td>\n",
       "      <td>0.219126</td>\n",
       "      <td>0.309227</td>\n",
       "      <td>0.300426</td>\n",
       "      <td>-0.643162</td>\n",
       "      <td>0.160198</td>\n",
       "      <td>0.967023</td>\n",
       "      <td>0.995186</td>\n",
       "      <td>0.235309</td>\n",
       "      <td>0.468164</td>\n",
       "      <td>0.149229</td>\n",
       "      <td>0.437507</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.062275</td>\n",
       "      <td>0.054624</td>\n",
       "      <td>-0.080202</td>\n",
       "      <td>-0.606014</td>\n",
       "      <td>0.215898</td>\n",
       "      <td>0.056594</td>\n",
       "      <td>-0.549028</td>\n",
       "      <td>0.745350</td>\n",
       "      <td>-0.533250</td>\n",
       "      <td>0.898583</td>\n",
       "      <td>0.984227</td>\n",
       "      <td>-0.083175</td>\n",
       "      <td>-0.006180</td>\n",
       "      <td>0.964303</td>\n",
       "      <td>0.135159</td>\n",
       "      <td>0.353592</td>\n",
       "      <td>0.275760</td>\n",
       "      <td>0.230965</td>\n",
       "      <td>0.290532</td>\n",
       "      <td>0.155957</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>0.193639</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>0.997678</td>\n",
       "      <td>-0.654064</td>\n",
       "      <td>0.967430</td>\n",
       "      <td>0.698373</td>\n",
       "      <td>0.997699</td>\n",
       "      <td>0.279127</td>\n",
       "      <td>0.995995</td>\n",
       "      <td>0.155006</td>\n",
       "      <td>0.311270</td>\n",
       "      <td>0.796157</td>\n",
       "      <td>0.223559</td>\n",
       "      <td>0.598059</td>\n",
       "      <td>0.095908</td>\n",
       "      <td>-0.682702</td>\n",
       "      <td>0.125186</td>\n",
       "      <td>-0.011900</td>\n",
       "      <td>0.193881</td>\n",
       "      <td>-0.965000</td>\n",
       "      <td>0.761431</td>\n",
       "      <td>-0.103000</td>\n",
       "      <td>0.250799</td>\n",
       "      <td>0.380067</td>\n",
       "      <td>-0.973000</td>\n",
       "      <td>0.663391</td>\n",
       "      <td>0.605459</td>\n",
       "      <td>0.500001</td>\n",
       "      <td>0.488199</td>\n",
       "      <td>0.084666</td>\n",
       "      <td>0.989028</td>\n",
       "      <td>0.033016</td>\n",
       "      <td>0.197144</td>\n",
       "      <td>0.975819</td>\n",
       "      <td>-0.976939</td>\n",
       "      <td>0.157041</td>\n",
       "      <td>0.020087</td>\n",
       "      <td>0.014895</td>\n",
       "      <td>-0.152000</td>\n",
       "      <td>0.936504</td>\n",
       "      <td>0.556555</td>\n",
       "      <td>-0.943000</td>\n",
       "      <td>0.297789</td>\n",
       "      <td>0.998571</td>\n",
       "      <td>-0.408424</td>\n",
       "      <td>0.499746</td>\n",
       "      <td>-0.097987</td>\n",
       "      <td>0.690875</td>\n",
       "      <td>-0.061825</td>\n",
       "      <td>-0.076750</td>\n",
       "      <td>0.976211</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.261849</td>\n",
       "      <td>0.225219</td>\n",
       "      <td>0.197017</td>\n",
       "      <td>0.056265</td>\n",
       "      <td>-0.090300</td>\n",
       "      <td>0.998458</td>\n",
       "      <td>-0.000610</td>\n",
       "      <td>0.253461</td>\n",
       "      <td>-0.819000</td>\n",
       "      <td>-0.786855</td>\n",
       "      <td>-0.022213</td>\n",
       "      <td>0.998855</td>\n",
       "      <td>0.196084</td>\n",
       "      <td>0.943390</td>\n",
       "      <td>0.409910</td>\n",
       "      <td>0.238451</td>\n",
       "      <td>-0.888472</td>\n",
       "      <td>0.985944</td>\n",
       "      <td>0.751351</td>\n",
       "      <td>-0.996000</td>\n",
       "      <td>0.293821</td>\n",
       "      <td>-0.903027</td>\n",
       "      <td>0.360608</td>\n",
       "      <td>0.174672</td>\n",
       "      <td>-0.652647</td>\n",
       "      <td>0.120833</td>\n",
       "      <td>-0.997000</td>\n",
       "      <td>0.029302</td>\n",
       "      <td>0.983934</td>\n",
       "      <td>-0.002925</td>\n",
       "      <td>0.991067</td>\n",
       "      <td>0.266627</td>\n",
       "      <td>-0.710539</td>\n",
       "      <td>0.173688</td>\n",
       "      <td>0.208881</td>\n",
       "      <td>0.173256</td>\n",
       "      <td>-0.019375</td>\n",
       "      <td>0.442581</td>\n",
       "      <td>-0.039273</td>\n",
       "      <td>0.998820</td>\n",
       "      <td>-0.999556</td>\n",
       "      <td>-0.774433</td>\n",
       "      <td>0.351152</td>\n",
       "      <td>-0.810000</td>\n",
       "      <td>0.481305</td>\n",
       "      <td>0.174696</td>\n",
       "      <td>0.292083</td>\n",
       "      <td>0.063023</td>\n",
       "      <td>-0.974000</td>\n",
       "      <td>0.102694</td>\n",
       "      <td>0.382346</td>\n",
       "      <td>-0.984000</td>\n",
       "      <td>-0.913000</td>\n",
       "      <td>-0.682250</td>\n",
       "      <td>0.407996</td>\n",
       "      <td>-0.038625</td>\n",
       "      <td>0.238411</td>\n",
       "      <td>0.206076</td>\n",
       "      <td>0.311333</td>\n",
       "      <td>0.299969</td>\n",
       "      <td>0.997252</td>\n",
       "      <td>0.365457</td>\n",
       "      <td>0.999129</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.178145</td>\n",
       "      <td>0.229443</td>\n",
       "      <td>0.992661</td>\n",
       "      <td>0.892591</td>\n",
       "      <td>0.283471</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>0.361354</td>\n",
       "      <td>0.964800</td>\n",
       "      <td>0.999273</td>\n",
       "      <td>0.876738</td>\n",
       "      <td>0.999192</td>\n",
       "      <td>-0.964000</td>\n",
       "      <td>0.073809</td>\n",
       "      <td>0.311607</td>\n",
       "      <td>-0.247067</td>\n",
       "      <td>0.591078</td>\n",
       "      <td>0.177966</td>\n",
       "      <td>0.458489</td>\n",
       "      <td>-0.999000</td>\n",
       "      <td>-0.994000</td>\n",
       "      <td>0.039327</td>\n",
       "      <td>-0.963423</td>\n",
       "      <td>0.994704</td>\n",
       "      <td>0.495989</td>\n",
       "      <td>0.158718</td>\n",
       "      <td>0.492218</td>\n",
       "      <td>0.596156</td>\n",
       "      <td>0.227827</td>\n",
       "      <td>-0.983986</td>\n",
       "      <td>-0.985070</td>\n",
       "      <td>0.064296</td>\n",
       "      <td>-0.155000</td>\n",
       "      <td>0.081449</td>\n",
       "      <td>-0.029250</td>\n",
       "      <td>-0.998922</td>\n",
       "      <td>-0.628250</td>\n",
       "      <td>0.979321</td>\n",
       "      <td>0.207001</td>\n",
       "      <td>0.080044</td>\n",
       "      <td>0.038998</td>\n",
       "      <td>0.379070</td>\n",
       "      <td>-0.913000</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>-0.392000</td>\n",
       "      <td>-0.007744</td>\n",
       "      <td>0.085176</td>\n",
       "      <td>0.140147</td>\n",
       "      <td>0.300223</td>\n",
       "      <td>-0.131566</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>-0.947566</td>\n",
       "      <td>0.140955</td>\n",
       "      <td>0.361271</td>\n",
       "      <td>-0.242138</td>\n",
       "      <td>-0.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.997837</td>\n",
       "      <td>0.671943</td>\n",
       "      <td>0.626020</td>\n",
       "      <td>0.935983</td>\n",
       "      <td>0.999716</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.676391</td>\n",
       "      <td>0.602718</td>\n",
       "      <td>0.091661</td>\n",
       "      <td>0.679634</td>\n",
       "      <td>0.281411</td>\n",
       "      <td>0.995396</td>\n",
       "      <td>0.601829</td>\n",
       "      <td>0.982631</td>\n",
       "      <td>0.682848</td>\n",
       "      <td>0.651586</td>\n",
       "      <td>0.744034</td>\n",
       "      <td>0.430179</td>\n",
       "      <td>0.763716</td>\n",
       "      <td>0.728381</td>\n",
       "      <td>0.491517</td>\n",
       "      <td>0.998999</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.401849</td>\n",
       "      <td>0.595640</td>\n",
       "      <td>0.895954</td>\n",
       "      <td>0.999815</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.751836</td>\n",
       "      <td>0.744596</td>\n",
       "      <td>0.729174</td>\n",
       "      <td>0.671782</td>\n",
       "      <td>0.738188</td>\n",
       "      <td>0.612540</td>\n",
       "      <td>0.539924</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.613180</td>\n",
       "      <td>0.738640</td>\n",
       "      <td>0.651199</td>\n",
       "      <td>0.672042</td>\n",
       "      <td>0.216598</td>\n",
       "      <td>0.721493</td>\n",
       "      <td>0.991259</td>\n",
       "      <td>0.937540</td>\n",
       "      <td>0.769167</td>\n",
       "      <td>0.998848</td>\n",
       "      <td>0.648846</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.703701</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.510716</td>\n",
       "      <td>0.978054</td>\n",
       "      <td>0.851115</td>\n",
       "      <td>0.605170</td>\n",
       "      <td>0.667320</td>\n",
       "      <td>-0.946422</td>\n",
       "      <td>0.081759</td>\n",
       "      <td>0.738283</td>\n",
       "      <td>0.762552</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.713535</td>\n",
       "      <td>0.727256</td>\n",
       "      <td>0.958031</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.990845</td>\n",
       "      <td>0.429785</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.819408</td>\n",
       "      <td>0.935096</td>\n",
       "      <td>0.992114</td>\n",
       "      <td>0.576817</td>\n",
       "      <td>0.673201</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.704190</td>\n",
       "      <td>0.566030</td>\n",
       "      <td>0.588779</td>\n",
       "      <td>0.769998</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.972120</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.859801</td>\n",
       "      <td>0.583891</td>\n",
       "      <td>0.763630</td>\n",
       "      <td>0.587639</td>\n",
       "      <td>0.715800</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.717388</td>\n",
       "      <td>0.838796</td>\n",
       "      <td>0.884824</td>\n",
       "      <td>0.890215</td>\n",
       "      <td>0.999010</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.718606</td>\n",
       "      <td>0.971097</td>\n",
       "      <td>0.554979</td>\n",
       "      <td>0.988903</td>\n",
       "      <td>0.694197</td>\n",
       "      <td>0.643807</td>\n",
       "      <td>0.730926</td>\n",
       "      <td>0.601847</td>\n",
       "      <td>0.569124</td>\n",
       "      <td>0.999863</td>\n",
       "      <td>0.767157</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.983658</td>\n",
       "      <td>0.612629</td>\n",
       "      <td>0.884718</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>0.622764</td>\n",
       "      <td>0.738473</td>\n",
       "      <td>0.854425</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.605142</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.902698</td>\n",
       "      <td>0.572219</td>\n",
       "      <td>0.977645</td>\n",
       "      <td>0.998886</td>\n",
       "      <td>0.695053</td>\n",
       "      <td>0.586821</td>\n",
       "      <td>0.957029</td>\n",
       "      <td>0.651669</td>\n",
       "      <td>0.572991</td>\n",
       "      <td>0.629019</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.593672</td>\n",
       "      <td>0.834010</td>\n",
       "      <td>0.993441</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.996868</td>\n",
       "      <td>0.554701</td>\n",
       "      <td>0.759327</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.696189</td>\n",
       "      <td>0.544529</td>\n",
       "      <td>0.999800</td>\n",
       "      <td>0.727933</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.483118</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.859085</td>\n",
       "      <td>0.590757</td>\n",
       "      <td>0.421065</td>\n",
       "      <td>0.670165</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>0.798607</td>\n",
       "      <td>0.771748</td>\n",
       "      <td>0.619530</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.997825</td>\n",
       "      <td>0.800006</td>\n",
       "      <td>0.751157</td>\n",
       "      <td>0.498704</td>\n",
       "      <td>0.677544</td>\n",
       "      <td>0.579975</td>\n",
       "      <td>0.611183</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.554241</td>\n",
       "      <td>0.621736</td>\n",
       "      <td>0.562281</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.999594</td>\n",
       "      <td>0.741804</td>\n",
       "      <td>0.733354</td>\n",
       "      <td>0.988643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940032</td>\n",
       "      <td>0.800964</td>\n",
       "      <td>0.991680</td>\n",
       "      <td>0.586660</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.512275</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.994447</td>\n",
       "      <td>0.997777</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.537982</td>\n",
       "      <td>0.975611</td>\n",
       "      <td>0.843762</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.999770</td>\n",
       "      <td>0.838150</td>\n",
       "      <td>0.952593</td>\n",
       "      <td>0.587838</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>0.642208</td>\n",
       "      <td>0.719514</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>0.620217</td>\n",
       "      <td>0.682796</td>\n",
       "      <td>0.397915</td>\n",
       "      <td>0.944433</td>\n",
       "      <td>0.616888</td>\n",
       "      <td>0.736452</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.440738</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.691941</td>\n",
       "      <td>0.995232</td>\n",
       "      <td>0.999830</td>\n",
       "      <td>0.825228</td>\n",
       "      <td>0.865127</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>0.926802</td>\n",
       "      <td>0.991080</td>\n",
       "      <td>0.999747</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.686223</td>\n",
       "      <td>-0.099098</td>\n",
       "      <td>0.706320</td>\n",
       "      <td>0.997745</td>\n",
       "      <td>0.795378</td>\n",
       "      <td>0.982663</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>0.997884</td>\n",
       "      <td>0.751759</td>\n",
       "      <td>0.986310</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>0.611287</td>\n",
       "      <td>0.754084</td>\n",
       "      <td>0.546881</td>\n",
       "      <td>0.775062</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.617104</td>\n",
       "      <td>0.958481</td>\n",
       "      <td>0.590587</td>\n",
       "      <td>0.809676</td>\n",
       "      <td>0.654529</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.995597</td>\n",
       "      <td>0.884240</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.853315</td>\n",
       "      <td>0.999811</td>\n",
       "      <td>0.587880</td>\n",
       "      <td>0.617752</td>\n",
       "      <td>0.674912</td>\n",
       "      <td>0.620381</td>\n",
       "      <td>0.762029</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.663382</td>\n",
       "      <td>0.641025</td>\n",
       "      <td>0.649716</td>\n",
       "      <td>0.923367</td>\n",
       "      <td>0.998270</td>\n",
       "      <td>0.526776</td>\n",
       "      <td>-0.636000</td>\n",
       "      <td>0.652757</td>\n",
       "      <td>0.923299</td>\n",
       "      <td>0.581010</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.959285</td>\n",
       "      <td>0.674402</td>\n",
       "      <td>0.738278</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.722346</td>\n",
       "      <td>0.982296</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.575400</td>\n",
       "      <td>0.445740</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.684487</td>\n",
       "      <td>0.993890</td>\n",
       "      <td>0.730553</td>\n",
       "      <td>0.994929</td>\n",
       "      <td>0.637728</td>\n",
       "      <td>0.992913</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.655948</td>\n",
       "      <td>0.840946</td>\n",
       "      <td>0.809360</td>\n",
       "      <td>0.776875</td>\n",
       "      <td>0.228267</td>\n",
       "      <td>0.991767</td>\n",
       "      <td>0.822828</td>\n",
       "      <td>0.767208</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.859918</td>\n",
       "      <td>0.448626</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.646737</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985196</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.551374</td>\n",
       "      <td>0.874461</td>\n",
       "      <td>0.603023</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.992601</td>\n",
       "      <td>0.711388</td>\n",
       "      <td>0.696453</td>\n",
       "      <td>0.920425</td>\n",
       "      <td>0.760864</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.999809</td>\n",
       "      <td>0.710914</td>\n",
       "      <td>0.830472</td>\n",
       "      <td>0.726189</td>\n",
       "      <td>0.821350</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.604601</td>\n",
       "      <td>0.985699</td>\n",
       "      <td>0.557848</td>\n",
       "      <td>0.988329</td>\n",
       "      <td>0.770670</td>\n",
       "      <td>0.689228</td>\n",
       "      <td>0.968133</td>\n",
       "      <td>0.992074</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.997816</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>0.432930</td>\n",
       "      <td>0.438865</td>\n",
       "      <td>0.999914</td>\n",
       "      <td>0.762199</td>\n",
       "      <td>0.683400</td>\n",
       "      <td>0.735682</td>\n",
       "      <td>0.977445</td>\n",
       "      <td>0.999645</td>\n",
       "      <td>0.707854</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.674455</td>\n",
       "      <td>0.650321</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.996545</td>\n",
       "      <td>0.999914</td>\n",
       "      <td>0.996186</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.645299</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.788425</td>\n",
       "      <td>0.769908</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.676829</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>0.566793</td>\n",
       "      <td>0.853553</td>\n",
       "      <td>0.532153</td>\n",
       "      <td>0.602924</td>\n",
       "      <td>0.840486</td>\n",
       "      <td>0.947838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.541305</td>\n",
       "      <td>0.756643</td>\n",
       "      <td>0.824800</td>\n",
       "      <td>0.706445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991480</td>\n",
       "      <td>0.844673</td>\n",
       "      <td>0.808253</td>\n",
       "      <td>0.552103</td>\n",
       "      <td>0.999688</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.777019</td>\n",
       "      <td>0.999655</td>\n",
       "      <td>-0.058636</td>\n",
       "      <td>0.622074</td>\n",
       "      <td>0.513653</td>\n",
       "      <td>0.620972</td>\n",
       "      <td>0.415663</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>0.772389</td>\n",
       "      <td>0.909495</td>\n",
       "      <td>0.765239</td>\n",
       "      <td>0.999972</td>\n",
       "      <td>0.995207</td>\n",
       "      <td>0.872401</td>\n",
       "      <td>0.520141</td>\n",
       "      <td>0.999029</td>\n",
       "      <td>0.533940</td>\n",
       "      <td>0.571710</td>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.451266</td>\n",
       "      <td>0.676676</td>\n",
       "      <td>0.703847</td>\n",
       "      <td>0.693036</td>\n",
       "      <td>0.609401</td>\n",
       "      <td>0.491953</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.696669</td>\n",
       "      <td>0.800939</td>\n",
       "      <td>0.878015</td>\n",
       "      <td>0.993901</td>\n",
       "      <td>0.573441</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.997224</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.675777</td>\n",
       "      <td>0.725305</td>\n",
       "      <td>0.505148</td>\n",
       "      <td>0.999641</td>\n",
       "      <td>0.998111</td>\n",
       "      <td>-0.814976</td>\n",
       "      <td>0.808821</td>\n",
       "      <td>0.998175</td>\n",
       "      <td>0.738181</td>\n",
       "      <td>0.720517</td>\n",
       "      <td>0.981828</td>\n",
       "      <td>0.923119</td>\n",
       "      <td>-0.161000</td>\n",
       "      <td>0.711740</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.624756</td>\n",
       "      <td>0.999722</td>\n",
       "      <td>0.721183</td>\n",
       "      <td>0.970492</td>\n",
       "      <td>0.685473</td>\n",
       "      <td>0.770404</td>\n",
       "      <td>0.728162</td>\n",
       "      <td>0.762832</td>\n",
       "      <td>0.775758</td>\n",
       "      <td>0.992870</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>-0.406430</td>\n",
       "      <td>0.948278</td>\n",
       "      <td>0.782009</td>\n",
       "      <td>0.450112</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.688133</td>\n",
       "      <td>0.694417</td>\n",
       "      <td>0.570395</td>\n",
       "      <td>0.909562</td>\n",
       "      <td>0.937921</td>\n",
       "      <td>0.725732</td>\n",
       "      <td>0.543364</td>\n",
       "      <td>0.746886</td>\n",
       "      <td>0.959510</td>\n",
       "      <td>0.746191</td>\n",
       "      <td>0.572448</td>\n",
       "      <td>0.806245</td>\n",
       "      <td>0.866998</td>\n",
       "      <td>0.750561</td>\n",
       "      <td>0.665915</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.852328</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.651374</td>\n",
       "      <td>0.654068</td>\n",
       "      <td>0.772500</td>\n",
       "      <td>0.999941</td>\n",
       "      <td>0.999393</td>\n",
       "      <td>0.655903</td>\n",
       "      <td>-0.573000</td>\n",
       "      <td>0.832665</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.993202</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.980243</td>\n",
       "      <td>0.597582</td>\n",
       "      <td>0.761616</td>\n",
       "      <td>0.997880</td>\n",
       "      <td>0.991572</td>\n",
       "      <td>0.724668</td>\n",
       "      <td>0.807812</td>\n",
       "      <td>-0.800068</td>\n",
       "      <td>0.567936</td>\n",
       "      <td>0.650759</td>\n",
       "      <td>0.173877</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.833871</td>\n",
       "      <td>0.724718</td>\n",
       "      <td>0.831223</td>\n",
       "      <td>0.857264</td>\n",
       "      <td>0.562839</td>\n",
       "      <td>0.665869</td>\n",
       "      <td>0.811324</td>\n",
       "      <td>0.627456</td>\n",
       "      <td>0.692022</td>\n",
       "      <td>0.639881</td>\n",
       "      <td>0.512733</td>\n",
       "      <td>-0.726000</td>\n",
       "      <td>0.974046</td>\n",
       "      <td>0.998933</td>\n",
       "      <td>0.726460</td>\n",
       "      <td>0.630337</td>\n",
       "      <td>0.625495</td>\n",
       "      <td>0.807282</td>\n",
       "      <td>0.992221</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.973581</td>\n",
       "      <td>0.688424</td>\n",
       "      <td>0.633263</td>\n",
       "      <td>0.717464</td>\n",
       "      <td>0.836734</td>\n",
       "      <td>0.963574</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.973928</td>\n",
       "      <td>0.672684</td>\n",
       "      <td>0.770595</td>\n",
       "      <td>0.370205</td>\n",
       "      <td>0.797859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       utteranceID     Group  CPS_CONST_SharesU_Situation  \\\n",
       "count         1822      1822                        145.0   \n",
       "unique        1822        10                          NaN   \n",
       "top     Group_01_0  Group_07                          NaN   \n",
       "freq             1       380                          NaN   \n",
       "mean           NaN       NaN                          1.0   \n",
       "std            NaN       NaN                          0.0   \n",
       "min            NaN       NaN                          1.0   \n",
       "25%            NaN       NaN                          1.0   \n",
       "50%            NaN       NaN                          1.0   \n",
       "75%            NaN       NaN                          1.0   \n",
       "max            NaN       NaN                          1.0   \n",
       "\n",
       "        CPS_CONST_SharesU_CorrectSolutions  \\\n",
       "count                                156.0   \n",
       "unique                                 NaN   \n",
       "top                                    NaN   \n",
       "freq                                   NaN   \n",
       "mean                                   1.0   \n",
       "std                                    0.0   \n",
       "min                                    1.0   \n",
       "25%                                    1.0   \n",
       "50%                                    1.0   \n",
       "75%                                    1.0   \n",
       "max                                    1.0   \n",
       "\n",
       "        CPS_CONST_SharesU_IncorrectSolutions  \\\n",
       "count                                   24.0   \n",
       "unique                                   NaN   \n",
       "top                                      NaN   \n",
       "freq                                     NaN   \n",
       "mean                                     1.0   \n",
       "std                                      0.0   \n",
       "min                                      1.0   \n",
       "25%                                      1.0   \n",
       "50%                                      1.0   \n",
       "75%                                      1.0   \n",
       "max                                      1.0   \n",
       "\n",
       "        CPS_CONST_EstablishesCG_Confirms  CPS_CONST_EstablishesCG_Interrupts  \\\n",
       "count                              300.0                               304.0   \n",
       "unique                               NaN                                 NaN   \n",
       "top                                  NaN                                 NaN   \n",
       "freq                                 NaN                                 NaN   \n",
       "mean                                 1.0                                 1.0   \n",
       "std                                  0.0                                 0.0   \n",
       "min                                  1.0                                 1.0   \n",
       "25%                                  1.0                                 1.0   \n",
       "50%                                  1.0                                 1.0   \n",
       "75%                                  1.0                                 1.0   \n",
       "max                                  1.0                                 1.0   \n",
       "\n",
       "        CPS_NEG_Responds_Reasons  CPS_NEG_Responds_QuestionsOthers  \\\n",
       "count                       97.0                              55.0   \n",
       "unique                       NaN                               NaN   \n",
       "top                          NaN                               NaN   \n",
       "freq                         NaN                               NaN   \n",
       "mean                         1.0                               1.0   \n",
       "std                          0.0                               0.0   \n",
       "min                          1.0                               1.0   \n",
       "25%                          1.0                               1.0   \n",
       "50%                          1.0                               1.0   \n",
       "75%                          1.0                               1.0   \n",
       "max                          1.0                               1.0   \n",
       "\n",
       "        CPS_NEG_Responds_Responds  CPS_NEG_MonitorsE_Results  \\\n",
       "count                       265.0                      353.0   \n",
       "unique                        NaN                        NaN   \n",
       "top                           NaN                        NaN   \n",
       "freq                          NaN                        NaN   \n",
       "mean                          1.0                        1.0   \n",
       "std                           0.0                        0.0   \n",
       "min                           1.0                        1.0   \n",
       "25%                           1.0                        1.0   \n",
       "50%                           1.0                        1.0   \n",
       "75%                           1.0                        1.0   \n",
       "max                           1.0                        1.0   \n",
       "\n",
       "        CPS_NEG_MonitorsE_Strategizes  CPS_NEG_MonitorsE_Save  \\\n",
       "count                             2.0                     0.0   \n",
       "unique                            NaN                     NaN   \n",
       "top                               NaN                     NaN   \n",
       "freq                              NaN                     NaN   \n",
       "mean                              1.0                     NaN   \n",
       "std                               0.0                     NaN   \n",
       "min                               1.0                     NaN   \n",
       "25%                               1.0                     NaN   \n",
       "50%                               1.0                     NaN   \n",
       "75%                               1.0                     NaN   \n",
       "max                               1.0                     NaN   \n",
       "\n",
       "        CPS_NEG_MonitorsE_GivingUp  CPS_MAINTAIN_Initiative_Suggestions  \\\n",
       "count                          1.0                                 82.0   \n",
       "unique                         NaN                                  NaN   \n",
       "top                            NaN                                  NaN   \n",
       "freq                           NaN                                  NaN   \n",
       "mean                           1.0                                  1.0   \n",
       "std                            NaN                                  0.0   \n",
       "min                            1.0                                  1.0   \n",
       "25%                            1.0                                  1.0   \n",
       "50%                            1.0                                  1.0   \n",
       "75%                            1.0                                  1.0   \n",
       "max                            1.0                                  1.0   \n",
       "\n",
       "        CPS_MAINTAIN_Initiative_Compliments  \\\n",
       "count                                 114.0   \n",
       "unique                                  NaN   \n",
       "top                                     NaN   \n",
       "freq                                    NaN   \n",
       "mean                                    1.0   \n",
       "std                                     0.0   \n",
       "min                                     1.0   \n",
       "25%                                     1.0   \n",
       "50%                                     1.0   \n",
       "75%                                     1.0   \n",
       "max                                     1.0   \n",
       "\n",
       "        CPS_MAINTAIN_Initiative_Criticizes  CPS_MAINTAIN_FulfillsR_Support  \\\n",
       "count                                  3.0                           191.0   \n",
       "unique                                 NaN                             NaN   \n",
       "top                                    NaN                             NaN   \n",
       "freq                                   NaN                             NaN   \n",
       "mean                                   1.0                             1.0   \n",
       "std                                    0.0                             0.0   \n",
       "min                                    1.0                             1.0   \n",
       "25%                                    1.0                             1.0   \n",
       "50%                                    1.0                             1.0   \n",
       "75%                                    1.0                             1.0   \n",
       "max                                    1.0                             1.0   \n",
       "\n",
       "        CPS_MAINTAIN_FulfillsR_Apologizes  \\\n",
       "count                                13.0   \n",
       "unique                                NaN   \n",
       "top                                   NaN   \n",
       "freq                                  NaN   \n",
       "mean                                  1.0   \n",
       "std                                   0.0   \n",
       "min                                   1.0   \n",
       "25%                                   1.0   \n",
       "50%                                   1.0   \n",
       "75%                                   1.0   \n",
       "max                                   1.0   \n",
       "\n",
       "        CPS_MAINTAIN_FulfillsR_InitiatesOffTopic  \\\n",
       "count                                        6.0   \n",
       "unique                                       NaN   \n",
       "top                                          NaN   \n",
       "freq                                         NaN   \n",
       "mean                                         1.0   \n",
       "std                                          0.0   \n",
       "min                                          1.0   \n",
       "25%                                          1.0   \n",
       "50%                                          1.0   \n",
       "75%                                          1.0   \n",
       "max                                          1.0   \n",
       "\n",
       "        CPS_MAINTAIN_FulfillsR_JoinsOffTopic       bert_0       bert_1  \\\n",
       "count                                    2.0  1822.000000  1822.000000   \n",
       "unique                                   NaN          NaN          NaN   \n",
       "top                                      NaN          NaN          NaN   \n",
       "freq                                     NaN          NaN          NaN   \n",
       "mean                                     1.0     0.946037     0.165561   \n",
       "std                                      0.0     0.131988     0.746974   \n",
       "min                                      1.0    -0.589509    -0.983000   \n",
       "25%                                      1.0     0.954385    -0.601841   \n",
       "50%                                      1.0     0.989176     0.445204   \n",
       "75%                                      1.0     0.996965     0.862085   \n",
       "max                                      1.0     0.999891     0.997837   \n",
       "\n",
       "             bert_2       bert_3       bert_4       bert_5       bert_6  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.051941     0.057872     0.070738     0.916660     0.919451   \n",
       "std        0.270801     0.210620     0.511484     0.168832     0.176573   \n",
       "min       -0.618000    -0.551921    -0.871054    -0.584000    -0.411000   \n",
       "25%       -0.253890    -0.137000    -0.336527     0.924386     0.928497   \n",
       "50%       -0.037074     0.043456     0.179384     0.980881     0.987984   \n",
       "75%        0.151849     0.217468     0.513341     0.987294     0.998601   \n",
       "max        0.671943     0.626020     0.935983     0.999716     0.999957   \n",
       "\n",
       "             bert_7       bert_8       bert_9      bert_10      bert_11  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.928972    -0.252722    -0.987910     0.120923    -0.961912   \n",
       "std        0.148659     0.236382     0.062450     0.215921     0.079534   \n",
       "min       -1.000000    -0.779850    -1.000000    -0.524444    -1.000000   \n",
       "25%       -0.991731    -0.389000    -0.999690    -0.034400    -0.991059   \n",
       "50%       -0.965000    -0.304893    -0.998000     0.111090    -0.987886   \n",
       "75%       -0.937000    -0.092000    -0.996339     0.289331    -0.965764   \n",
       "max        0.676391     0.602718     0.091661     0.679634     0.281411   \n",
       "\n",
       "            bert_12      bert_13      bert_14      bert_15      bert_16  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.679360    -0.898137     0.203622     0.033346    -0.051403   \n",
       "std        0.528609     0.166575     0.481725     0.249977     0.207550   \n",
       "min       -1.000000    -1.000000    -0.981000    -0.581000    -0.696000   \n",
       "25%       -0.997000    -0.994872    -0.284000    -0.231000    -0.197587   \n",
       "50%       -0.945895    -0.981399     0.240158     0.030314    -0.037576   \n",
       "75%       -0.650824    -0.866538     0.635867     0.218685     0.105658   \n",
       "max        0.995396     0.601829     0.982631     0.682848     0.651586   \n",
       "\n",
       "            bert_17      bert_18      bert_19      bert_20      bert_21  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.259174    -0.404026     0.174109     0.066002    -0.241068   \n",
       "std        0.192198     0.221625     0.247407     0.211439     0.224413   \n",
       "min       -0.437847    -0.922178    -0.609694    -0.676000    -0.752000   \n",
       "25%        0.136608    -0.580000    -0.010299    -0.047611    -0.455000   \n",
       "50%        0.297671    -0.451999     0.183631     0.045249    -0.272829   \n",
       "75%        0.381090    -0.255075     0.431569     0.177924    -0.077741   \n",
       "max        0.744034     0.430179     0.763716     0.728381     0.491517   \n",
       "\n",
       "            bert_22      bert_23      bert_24      bert_25      bert_26  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.135173     0.807800     0.970123     0.881433    -0.178827   \n",
       "std        0.527378     0.349554     0.104405     0.281131     0.208488   \n",
       "min       -0.976022    -0.957996    -0.378153    -0.940000    -0.789000   \n",
       "25%       -0.323000     0.840189     0.988089     0.932027    -0.334091   \n",
       "50%        0.259000     0.957810     0.992193     0.977598    -0.144500   \n",
       "75%        0.555593     0.978865     0.997929     0.993685    -0.045200   \n",
       "max        0.998999     0.999868     0.999972     0.999951     0.401849   \n",
       "\n",
       "            bert_27      bert_28      bert_29      bert_30      bert_31  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.138162     0.374911    -0.282001     0.961985     0.088193   \n",
       "std        0.232752     0.266404     0.645232     0.094955     0.240040   \n",
       "min       -0.818930    -0.550000    -1.000000    -0.539000    -0.618000   \n",
       "25%       -0.305000     0.184226    -0.779161     0.965953    -0.062965   \n",
       "50%       -0.164992     0.392001    -0.645000     0.992193     0.080209   \n",
       "75%        0.015421     0.616405     0.240865     0.997460     0.236947   \n",
       "max        0.595640     0.895954     0.999815     0.999971     0.751836   \n",
       "\n",
       "            bert_32      bert_33      bert_34      bert_35      bert_36  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.273697     0.142550    -0.960010     0.076955    -0.116922   \n",
       "std        0.194070     0.223362     0.120097     0.236181     0.235679   \n",
       "min       -0.443000    -0.747000    -1.000000    -0.774785    -0.730294   \n",
       "25%        0.182856     0.022020    -0.995005    -0.075076    -0.303750   \n",
       "50%        0.245125     0.154092    -0.986000     0.147021    -0.113500   \n",
       "75%        0.408357     0.280797    -0.973000     0.204207     0.122909   \n",
       "max        0.744596     0.729174     0.671782     0.738188     0.612540   \n",
       "\n",
       "            bert_37      bert_38      bert_39      bert_40      bert_41  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.144843     0.867182    -0.077187    -0.017968     0.028297   \n",
       "std        0.221052     0.285020     0.226246     0.290216     0.219620   \n",
       "min       -0.856233    -0.938274    -0.731146    -0.728815    -0.640025   \n",
       "25%       -0.307922     0.895814    -0.297000    -0.328000    -0.140061   \n",
       "50%       -0.120543     0.981907    -0.072900    -0.038300     0.048378   \n",
       "75%       -0.017600     0.997176     0.101946     0.208273     0.205288   \n",
       "max        0.539924     0.999964     0.613180     0.738640     0.651199   \n",
       "\n",
       "            bert_42      bert_43      bert_44      bert_45      bert_46  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.075952    -0.983347    -0.025132    -0.324281    -0.917980   \n",
       "std        0.188017     0.054105     0.220038     0.501254     0.227254   \n",
       "min       -0.479312    -1.000000    -0.650000    -0.994609    -1.000000   \n",
       "25%       -0.050025    -0.998000    -0.155000    -0.708500    -0.995974   \n",
       "50%        0.112366    -0.997000    -0.058500    -0.387000    -0.993000   \n",
       "75%        0.185189    -0.988471     0.118581    -0.072770    -0.951942   \n",
       "max        0.672042     0.216598     0.721493     0.991259     0.937540   \n",
       "\n",
       "            bert_47      bert_48      bert_49      bert_50      bert_51  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.098084     0.371471    -0.293021     0.979269    -0.030408   \n",
       "std        0.296893     0.523594     0.221919     0.074127     0.186976   \n",
       "min       -0.630982    -0.962648    -0.803649    -0.168500    -0.655022   \n",
       "25%       -0.170000    -0.211000    -0.456707     0.988445    -0.151824   \n",
       "50%        0.138609     0.499576    -0.265861     0.993463     0.000403   \n",
       "75%        0.327591     0.869873    -0.192000     0.997055     0.066217   \n",
       "max        0.769167     0.998848     0.648846     0.999925     0.703701   \n",
       "\n",
       "            bert_52      bert_53      bert_54      bert_55      bert_56  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.988571    -0.252943    -0.189996     0.237497    -0.050775   \n",
       "std        0.036669     0.216606     0.551529     0.235118     0.224991   \n",
       "min        0.405081    -0.831601    -0.999914    -0.743000    -0.729118   \n",
       "25%        0.992417    -0.405671    -0.671000     0.084413    -0.207554   \n",
       "50%        0.997988    -0.213421    -0.277092     0.283191    -0.010348   \n",
       "75%        0.999516    -0.136091     0.327171     0.425997     0.068917   \n",
       "max        0.999985     0.510716     0.978054     0.851115     0.605170   \n",
       "\n",
       "            bert_57      bert_58      bert_59      bert_60      bert_61  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.222236    -0.999134    -0.979931     0.043167    -0.043959   \n",
       "std        0.306101     0.002914     0.066381     0.267423     0.241880   \n",
       "min       -0.891847    -1.000000    -1.000000    -0.689918    -0.688354   \n",
       "25%       -0.555000    -1.000000    -0.998380    -0.212386    -0.184168   \n",
       "50%       -0.239951    -0.999968    -0.994000     0.076596    -0.115000   \n",
       "75%        0.006949    -0.999000    -0.985000     0.260837     0.129498   \n",
       "max        0.667320    -0.946422     0.081759     0.738283     0.762552   \n",
       "\n",
       "            bert_62      bert_63      bert_64      bert_65      bert_66  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.924208     0.160398     0.058396    -0.950925     0.977947   \n",
       "std        0.145776     0.206571     0.234597     0.143487     0.078804   \n",
       "min       -0.832547    -0.558000    -0.691000    -1.000000    -0.429005   \n",
       "25%        0.896221     0.010065    -0.109000    -0.997000     0.988925   \n",
       "50%        0.985208     0.180975     0.096354    -0.995000     0.997260   \n",
       "75%        0.995426     0.333388     0.185355    -0.967654     0.999400   \n",
       "max        0.999940     0.713535     0.727256     0.958031     0.999988   \n",
       "\n",
       "            bert_67      bert_68      bert_69      bert_70      bert_71  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.310059    -0.305804     0.496088     0.897031     0.997538   \n",
       "std        0.442185     0.259890     0.588232     0.249133     0.019790   \n",
       "min       -0.995955    -0.766000    -0.979971    -0.907588     0.412133   \n",
       "25%        0.127169    -0.577000     0.117089     0.922956     0.999493   \n",
       "50%        0.284351    -0.316668     0.779923     0.986674     0.999724   \n",
       "75%        0.649315    -0.105916     0.982717     0.998384     0.999930   \n",
       "max        0.990845     0.429785     0.999009     0.999910     0.999999   \n",
       "\n",
       "            bert_72      bert_73      bert_74      bert_75      bert_76  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.669332    -0.566607    -0.674084    -0.113398     0.027881   \n",
       "std        0.363011     0.417209     0.473085     0.258801     0.348019   \n",
       "min       -0.997560    -0.999000    -0.999771    -0.771762    -0.797000   \n",
       "25%       -0.930922    -0.858960    -0.959000    -0.315912    -0.254966   \n",
       "50%       -0.789119    -0.712000    -0.911503    -0.124922     0.003993   \n",
       "75%       -0.589000    -0.411841    -0.614103     0.164697     0.402405   \n",
       "max        0.819408     0.935096     0.992114     0.576817     0.673201   \n",
       "\n",
       "            bert_77      bert_78      bert_79      bert_80      bert_81  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.961304     0.000499    -0.152318    -0.983894     0.097894   \n",
       "std        0.101322     0.227872     0.210014     0.063254     0.238157   \n",
       "min       -0.521478    -0.619133    -0.757766    -1.000000    -0.601000   \n",
       "25%        0.971119    -0.182000    -0.285270    -0.999000    -0.041200   \n",
       "50%        0.988922     0.014601    -0.154000    -0.998000     0.071010   \n",
       "75%        0.997538     0.170162    -0.036005    -0.992000     0.274360   \n",
       "max        0.999953     0.704190     0.566030     0.588779     0.769998   \n",
       "\n",
       "            bert_82      bert_83      bert_84      bert_85      bert_86  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.946181     0.152720     0.721157    -0.918708     0.018728   \n",
       "std        0.129468     0.403373     0.466544     0.222000     0.193954   \n",
       "min       -0.532759    -0.926745    -0.999992    -1.000000    -0.605000   \n",
       "25%        0.961995    -0.042199     0.729082    -0.999470    -0.115000   \n",
       "50%        0.986258     0.057840     0.927011    -0.995000     0.042916   \n",
       "75%        0.995111     0.468813     0.970281    -0.894000     0.183809   \n",
       "max        0.999911     0.972120     0.999948     0.859801     0.583891   \n",
       "\n",
       "            bert_87      bert_88      bert_89      bert_90      bert_91  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.222898    -0.215539     0.076479    -0.871660     0.124886   \n",
       "std        0.223717     0.246428     0.208986     0.315700     0.261386   \n",
       "min       -0.460918    -0.799000    -0.589565    -1.000000    -0.594309   \n",
       "25%        0.019951    -0.474000    -0.045583    -0.989000    -0.082886   \n",
       "50%        0.202190    -0.232000     0.046255    -0.982176     0.142965   \n",
       "75%        0.403920    -0.029962     0.196178    -0.925000     0.408095   \n",
       "max        0.763630     0.587639     0.715800     0.999294     0.717388   \n",
       "\n",
       "            bert_92      bert_93      bert_94      bert_95      bert_96  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.295883    -0.888009    -0.814808     0.273138     0.879999   \n",
       "std        0.295435     0.249095     0.326460     0.707687     0.252023   \n",
       "min       -0.581000    -1.000000    -1.000000    -0.997436    -0.872000   \n",
       "25%        0.084144    -0.989000    -0.990000    -0.434118     0.921480   \n",
       "50%        0.287673    -0.979000    -0.964420     0.543565     0.959628   \n",
       "75%        0.519803    -0.921195    -0.813339     0.945886     0.991935   \n",
       "max        0.838796     0.884824     0.890215     0.999010     0.999942   \n",
       "\n",
       "            bert_97      bert_98      bert_99     bert_100     bert_101  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.045991    -0.944282    -0.167477    -0.573909    -0.909488   \n",
       "std        0.273560     0.189766     0.218465     0.543619     0.182214   \n",
       "min       -0.748029    -1.000000    -0.741016    -0.997719    -1.000000   \n",
       "25%       -0.175000    -0.997677    -0.333247    -0.978000    -0.992000   \n",
       "50%        0.006510    -0.994000    -0.138848    -0.845000    -0.978000   \n",
       "75%        0.257227    -0.977000    -0.040300    -0.345250    -0.915968   \n",
       "max        0.718606     0.971097     0.554979     0.988903     0.694197   \n",
       "\n",
       "           bert_102     bert_103     bert_104     bert_105     bert_106  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.968198     0.030439    -0.109264    -0.116169     0.914965   \n",
       "std        0.100244     0.217392     0.200940     0.246315     0.165128   \n",
       "min       -1.000000    -0.737357    -0.683757    -0.704590    -0.639016   \n",
       "25%       -0.997507    -0.082137    -0.247938    -0.338000     0.919854   \n",
       "50%       -0.995000    -0.018600    -0.072000    -0.105719     0.979791   \n",
       "75%       -0.982000     0.181155    -0.003992     0.071514     0.987081   \n",
       "max        0.643807     0.730926     0.601847     0.569124     0.999863   \n",
       "\n",
       "           bert_107     bert_108     bert_109     bert_110     bert_111  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.118525    -0.282717    -0.815637    -0.129430    -0.187952   \n",
       "std        0.208824     0.185641     0.321650     0.300886     0.401864   \n",
       "min       -0.651983    -0.822000    -1.000000    -0.758071    -0.968237   \n",
       "25%       -0.036700    -0.364445    -0.972265    -0.345311    -0.611000   \n",
       "50%        0.102340    -0.320725    -0.955680    -0.089613    -0.229906   \n",
       "75%        0.279408    -0.170194    -0.813438     0.102589     0.116902   \n",
       "max        0.767157     0.418016     0.983658     0.612629     0.884718   \n",
       "\n",
       "           bert_112     bert_113     bert_114     bert_115     bert_116  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.932387    -0.860871     0.000156     0.306351    -0.747565   \n",
       "std        0.172875     0.339934     0.223781     0.168618     0.321339   \n",
       "min       -0.871000    -1.000000    -0.685347    -0.445000    -0.999040   \n",
       "25%        0.967405    -0.989000    -0.146533     0.205882    -0.939806   \n",
       "50%        0.983467    -0.981786     0.056518     0.352925    -0.852000   \n",
       "75%        0.996899    -0.921000     0.116817     0.400971    -0.731718   \n",
       "max        0.999960     0.999763     0.622764     0.738473     0.854425   \n",
       "\n",
       "           bert_117     bert_118     bert_119     bert_120     bert_121  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.396764    -0.067967     0.978838    -0.896517    -0.154594   \n",
       "std        0.645250     0.221451     0.049367     0.185417     0.210948   \n",
       "min       -0.995381    -0.661000    -0.216000    -0.999833    -0.789218   \n",
       "25%       -0.125804    -0.188288     0.981175    -0.982530    -0.308000   \n",
       "50%        0.693085    -0.103000     0.993725    -0.966000    -0.186888   \n",
       "75%        0.975920     0.072950     0.995597    -0.905305    -0.006172   \n",
       "max        0.999941     0.605142     0.999902     0.902698     0.572219   \n",
       "\n",
       "           bert_122     bert_123     bert_124     bert_125     bert_126  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.959698    -0.051883    -0.157756    -0.164137    -0.638297   \n",
       "std        0.172425     0.762337     0.231979     0.228542     0.448410   \n",
       "min       -1.000000    -1.000000    -0.829925    -0.802000    -1.000000   \n",
       "25%       -0.998000    -0.905833    -0.316905    -0.311000    -0.917000   \n",
       "50%       -0.997000     0.007433    -0.116634    -0.188512    -0.867117   \n",
       "75%       -0.986434     0.575902    -0.044002    -0.008066    -0.510250   \n",
       "max        0.977645     0.998886     0.695053     0.586821     0.957029   \n",
       "\n",
       "           bert_127     bert_128     bert_129     bert_130     bert_131  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.107944    -0.161449    -0.098453     0.890535     0.880378   \n",
       "std        0.243596     0.209426     0.223044     0.227811     0.186560   \n",
       "min       -0.737000    -0.813096    -0.844000    -0.749354    -0.756000   \n",
       "25%       -0.296000    -0.283227    -0.252841     0.901004     0.844818   \n",
       "50%       -0.153000    -0.177000    -0.067939     0.978678     0.948014   \n",
       "75%        0.064266    -0.041250    -0.001050     0.997550     0.989146   \n",
       "max        0.651669     0.572991     0.629019     0.999788     0.999874   \n",
       "\n",
       "           bert_132     bert_133     bert_134     bert_135     bert_136  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.962899    -0.046206     0.289090    -0.634953     0.993764   \n",
       "std        0.133055     0.234388     0.205516     0.489377     0.048959   \n",
       "min       -0.540661    -0.637000    -0.562548    -0.999188    -0.399393   \n",
       "25%        0.983580    -0.263903     0.164008    -0.930833     0.998580   \n",
       "50%        0.996208    -0.030550     0.343855    -0.889478     0.999177   \n",
       "75%        0.998103     0.137799     0.400549    -0.510170     0.999804   \n",
       "max        0.999984     0.593672     0.834010     0.993441     0.999998   \n",
       "\n",
       "           bert_137     bert_138     bert_139     bert_140     bert_141  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.947714    -0.944583     0.295958     0.999430     0.096279   \n",
       "std        0.208586     0.140778     0.190333     0.001730     0.192103   \n",
       "min       -1.000000    -1.000000    -0.524000     0.972746    -0.595000   \n",
       "25%       -0.997000    -0.995000     0.191160     0.999727    -0.024309   \n",
       "50%       -0.995000    -0.991000     0.350612     0.999837     0.138156   \n",
       "75%       -0.980560    -0.961007     0.407133     0.999960     0.179926   \n",
       "max        0.996868     0.554701     0.759327     0.999999     0.696189   \n",
       "\n",
       "           bert_142     bert_143     bert_144     bert_145     bert_146  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.237792     0.634575     0.097391     0.973511    -0.884744   \n",
       "std        0.265222     0.483857     0.238009     0.092170     0.143837   \n",
       "min       -0.812000    -0.991224    -0.682054    -0.401385    -0.999000   \n",
       "25%       -0.446000     0.550524    -0.064700     0.990377    -0.963024   \n",
       "50%       -0.284000     0.828365     0.072572     0.994742    -0.920000   \n",
       "75%       -0.039002     0.951152     0.288511     0.999168    -0.870766   \n",
       "max        0.544529     0.999800     0.727933     0.999984     0.483118   \n",
       "\n",
       "           bert_147     bert_148     bert_149     bert_150     bert_151  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.980302    -0.918051    -0.114075    -0.380873    -0.104129   \n",
       "std        0.069440     0.220640     0.219044     0.236017     0.231470   \n",
       "min       -0.202000    -1.000000    -0.664000    -0.858954    -0.727000   \n",
       "25%        0.987322    -0.998000    -0.255000    -0.627841    -0.270655   \n",
       "50%        0.997076    -0.989505    -0.170253    -0.382068    -0.068800   \n",
       "75%        0.999500    -0.952464     0.045158    -0.209188     0.015664   \n",
       "max        0.999993     0.859085     0.590757     0.421065     0.670165   \n",
       "\n",
       "           bert_152     bert_153     bert_154     bert_155     bert_156  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.878639    -0.024071     0.145867    -0.085014     0.623671   \n",
       "std        0.235300     0.333554     0.310897     0.264086     0.561786   \n",
       "min       -0.760000    -0.830000    -0.686975    -0.754000    -0.998000   \n",
       "25%        0.894248    -0.381000    -0.108126    -0.294589     0.461314   \n",
       "50%        0.974395    -0.010444     0.153136    -0.062325     0.929154   \n",
       "75%        0.995758     0.233753     0.441246     0.126793     0.976722   \n",
       "max        0.999833     0.798607     0.771748     0.619530     0.999998   \n",
       "\n",
       "           bert_157     bert_158     bert_159     bert_160     bert_161  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.233792     0.097953     0.082725    -0.190465     0.054930   \n",
       "std        0.547924     0.232972     0.226382     0.217062     0.211655   \n",
       "min       -0.996682    -0.678000    -0.744000    -0.821662    -0.515000   \n",
       "25%       -0.120918    -0.059050    -0.037455    -0.338597    -0.121000   \n",
       "50%        0.311476     0.154330     0.041014    -0.162000     0.028298   \n",
       "75%        0.705124     0.216348     0.223171    -0.043500     0.208665   \n",
       "max        0.997825     0.800006     0.751157     0.498704     0.677544   \n",
       "\n",
       "           bert_162     bert_163     bert_164     bert_165     bert_166  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.271779    -0.205631     0.999956    -0.191950    -0.314656   \n",
       "std        0.228145     0.329693     0.000097     0.212754     0.299356   \n",
       "min       -0.826000    -0.801436     0.997876    -0.751031    -0.871032   \n",
       "25%       -0.443000    -0.446334     0.999957    -0.331728    -0.626250   \n",
       "50%       -0.247000    -0.152575     0.999984    -0.155000    -0.348961   \n",
       "75%       -0.132000     0.051439     0.999996    -0.099149    -0.102535   \n",
       "max        0.579975     0.611183     0.999999     0.554241     0.621736   \n",
       "\n",
       "           bert_167     bert_168     bert_169     bert_170     bert_171  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.228259     0.974945     0.814357     0.160256    -0.880167   \n",
       "std        0.233352     0.066673     0.331710     0.242903     0.220212   \n",
       "min       -0.872618    -0.700000    -0.944000    -0.646000    -1.000000   \n",
       "25%       -0.344000     0.960232     0.822151    -0.021953    -0.984303   \n",
       "50%       -0.285774     0.995799     0.959612     0.184579    -0.935000   \n",
       "75%       -0.068600     0.999010     0.988999     0.406056    -0.906158   \n",
       "max        0.562281     0.999981     0.999594     0.741804     0.733354   \n",
       "\n",
       "           bert_172     bert_173     bert_174     bert_175     bert_176  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.665843     0.427383     0.152926     0.326532    -0.211967   \n",
       "std        0.508499     0.641449     0.403379     0.261713     0.580331   \n",
       "min       -1.000000    -1.000000    -0.878450    -0.534000    -0.999000   \n",
       "25%       -0.994000     0.001683    -0.161000     0.143879    -0.651000   \n",
       "50%       -0.930000     0.774889     0.175716     0.364825    -0.434500   \n",
       "75%       -0.562750     0.868686     0.592236     0.577762     0.290063   \n",
       "max        0.988643     1.000000     0.940032     0.800964     0.991680   \n",
       "\n",
       "           bert_177     bert_178     bert_179     bert_180     bert_181  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.012482     0.990698     0.770459     0.898932    -0.164707   \n",
       "std        0.218055     0.056979     0.376675     0.176047     0.223477   \n",
       "min       -0.596000    -0.877229    -0.980581    -0.430000    -0.834000   \n",
       "25%       -0.215000     0.992593     0.729927     0.895484    -0.326452   \n",
       "50%        0.006165     0.998300     0.954936     0.967094    -0.120752   \n",
       "75%        0.179736     0.999477     0.989176     0.992959    -0.056775   \n",
       "max        0.586660     0.999980     0.999878     0.999915     0.512275   \n",
       "\n",
       "           bert_182     bert_183     bert_184     bert_185     bert_186  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.935275     0.099699     0.389145    -0.820782    -0.959006   \n",
       "std        0.169643     0.565265     0.549699     0.266290     0.129719   \n",
       "min       -0.936000    -0.994865    -0.979749    -1.000000    -1.000000   \n",
       "25%        0.957845    -0.381156     0.015445    -0.992000    -0.998997   \n",
       "50%        0.987954     0.260044     0.646168    -0.967000    -0.996000   \n",
       "75%        0.994883     0.551293     0.769223    -0.714198    -0.984573   \n",
       "max        0.999901     0.994447     0.997777     0.837037     0.537982   \n",
       "\n",
       "           bert_187     bert_188     bert_189     bert_190     bert_191  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.545561     0.203437     0.910562     0.856209    -0.845458   \n",
       "std        0.520949     0.288229     0.187130     0.291069     0.229212   \n",
       "min       -0.998000    -0.526567    -0.794485    -0.875000    -1.000000   \n",
       "25%       -0.896000    -0.012741     0.895012     0.884771    -0.988000   \n",
       "50%       -0.820500     0.187129     0.977636     0.978527    -0.948000   \n",
       "75%       -0.290250     0.503032     0.996706     0.988485    -0.714000   \n",
       "max        0.975611     0.843762     0.999976     0.999770     0.838150   \n",
       "\n",
       "           bert_192     bert_193     bert_194     bert_195     bert_196  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.494908    -0.195526     0.986115    -0.049906    -0.916084   \n",
       "std        0.698114     0.231987     0.039085     0.243854     0.155787   \n",
       "min       -0.999374    -0.705887    -0.182975    -0.801532    -1.000000   \n",
       "25%       -0.982862    -0.406440     0.987072    -0.229000    -0.985000   \n",
       "50%       -0.931000    -0.186874     0.996075    -0.086408    -0.974000   \n",
       "75%        0.022402    -0.020710     0.997537     0.128657    -0.923068   \n",
       "max        0.952593     0.587838     0.999873     0.642208     0.719514   \n",
       "\n",
       "           bert_197     bert_198     bert_199     bert_200     bert_201  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.801557     0.312959     0.077079     0.001514    -0.313749   \n",
       "std        0.409059     0.664168     0.265779     0.213894     0.211208   \n",
       "min       -1.000000    -0.999000    -0.620423    -0.632676    -0.830645   \n",
       "25%       -0.984516    -0.493000    -0.132861    -0.120412    -0.423000   \n",
       "50%       -0.963000     0.598045     0.041943    -0.054374    -0.375500   \n",
       "75%       -0.866589     0.936345     0.289723     0.143170    -0.192946   \n",
       "max        0.999978     0.999532     0.620217     0.682796     0.397915   \n",
       "\n",
       "           bert_202     bert_203     bert_204     bert_205     bert_206  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.828024     0.016214    -0.100516     0.969202    -0.269556   \n",
       "std        0.298637     0.242533     0.269794     0.094302     0.208374   \n",
       "min       -1.000000    -0.777672    -0.831067    -0.622000    -0.796072   \n",
       "25%       -0.981000    -0.162000    -0.263663     0.980245    -0.395000   \n",
       "50%       -0.952000     0.026259    -0.113000     0.995544    -0.277000   \n",
       "75%       -0.829000     0.249658     0.081884     0.998833    -0.161009   \n",
       "max        0.944433     0.616888     0.736452     0.999984     0.440738   \n",
       "\n",
       "           bert_207     bert_208     bert_209     bert_210     bert_211  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.975216     0.993990    -0.196420     0.158164     0.486724   \n",
       "std        0.096214     0.017238     0.211535     0.723345     0.599803   \n",
       "min       -0.230000     0.634311    -0.910000    -0.997904    -0.994661   \n",
       "25%        0.990204     0.995676    -0.328750    -0.574686     0.096430   \n",
       "50%        0.998520     0.998737    -0.158000     0.285794     0.777715   \n",
       "75%        0.999176     0.999594    -0.087608     0.924195     0.977444   \n",
       "max        0.999999     0.999962     0.691941     0.995232     0.999830   \n",
       "\n",
       "           bert_212     bert_213     bert_214     bert_215     bert_216  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.040859     0.098651     0.882655    -0.958447    -0.630409   \n",
       "std        0.213213     0.233202     0.294589     0.145767     0.511153   \n",
       "min       -0.714000    -0.687000    -0.998177    -1.000000    -0.999603   \n",
       "25%       -0.171750    -0.043425     0.931822    -0.998492    -0.981711   \n",
       "50%        0.008459     0.046268     0.982414    -0.992000    -0.880367   \n",
       "75%        0.056500     0.250531     0.992128    -0.985885    -0.497885   \n",
       "max        0.825228     0.865127     0.999908     0.926802     0.991080   \n",
       "\n",
       "           bert_217     bert_218     bert_219     bert_220     bert_221  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.749204     0.191373     0.112907    -0.977221    -0.169980   \n",
       "std        0.365493     0.613028     0.202610     0.060447     0.284787   \n",
       "min       -0.949000    -1.000000    -0.551000    -1.000000    -0.890000   \n",
       "25%        0.638038    -0.265935    -0.024550    -0.997000    -0.323878   \n",
       "50%        0.955925     0.265038     0.152273    -0.991000    -0.242962   \n",
       "75%        0.990082     0.703598     0.210359    -0.986252     0.034154   \n",
       "max        0.999747     0.999861     0.686223    -0.099098     0.706320   \n",
       "\n",
       "           bert_222     bert_223     bert_224     bert_225     bert_226  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.512367     0.299388    -0.352558    -0.303270    -0.923774   \n",
       "std        0.607241     0.232383     0.620415     0.541593     0.256406   \n",
       "min       -0.999539    -0.508000    -0.999000    -0.999002    -1.000000   \n",
       "25%       -0.983000     0.136296    -0.939250    -0.822588    -0.995607   \n",
       "50%       -0.826500     0.326483    -0.568454    -0.297624    -0.993000   \n",
       "75%       -0.200617     0.520107     0.129291    -0.044375    -0.969000   \n",
       "max        0.997745     0.795378     0.982663     0.993056     0.997884   \n",
       "\n",
       "           bert_227     bert_228     bert_229     bert_230     bert_231  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.003049    -0.325274     0.801201    -0.029782    -0.003149   \n",
       "std        0.285771     0.669362     0.320211     0.219635     0.234896   \n",
       "min       -0.638848    -1.000000    -0.680000    -0.650849    -0.736442   \n",
       "25%       -0.306356    -0.919983     0.747293    -0.171014    -0.180615   \n",
       "50%        0.017097    -0.607839     0.963652     0.036144    -0.009247   \n",
       "75%        0.220339     0.283166     0.993970     0.086338     0.238438   \n",
       "max        0.751759     0.986310     0.999886     0.611287     0.754084   \n",
       "\n",
       "           bert_232     bert_233     bert_234     bert_235     bert_236  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.193621     0.140690     0.932453     0.009322    -0.754399   \n",
       "std        0.226679     0.225377     0.227470     0.195342     0.364758   \n",
       "min       -0.852979    -0.592000    -0.983122    -0.588000    -0.999411   \n",
       "25%       -0.348000    -0.025426     0.976158    -0.099733    -0.971000   \n",
       "50%       -0.131500     0.161214     0.993538    -0.038200    -0.859814   \n",
       "75%       -0.066725     0.352481     0.996944     0.125733    -0.774796   \n",
       "max        0.546881     0.775062     0.999931     0.617104     0.958481   \n",
       "\n",
       "           bert_237     bert_238     bert_239     bert_240     bert_241  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.150298     0.234724    -0.061687     0.575646     0.999884   \n",
       "std        0.211682     0.246873     0.293268     0.496085     0.000610   \n",
       "min       -0.789000    -0.577273    -0.716290    -0.998000     0.981490   \n",
       "25%       -0.298000     0.053468    -0.293750     0.467398     0.999947   \n",
       "50%       -0.111298     0.249378    -0.106849     0.790405     0.999984   \n",
       "75%       -0.049450     0.478675     0.172777     0.918010     0.999994   \n",
       "max        0.590587     0.809676     0.654529     0.999725     1.000000   \n",
       "\n",
       "           bert_242     bert_243     bert_244     bert_245     bert_246  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.146737     0.982871    -0.216100     0.239689     0.984633   \n",
       "std        0.547223     0.073560     0.564426     0.188257     0.072912   \n",
       "min       -0.995000    -0.384037    -0.999389    -0.455000    -0.241426   \n",
       "25%       -0.657912     0.993226    -0.606882     0.153364     0.996610   \n",
       "50%       -0.148792     0.998316    -0.489000     0.205691     0.998359   \n",
       "75%        0.188794     0.998977     0.211893     0.366213     0.999825   \n",
       "max        0.999980     0.999986     0.995597     0.884240     0.999998   \n",
       "\n",
       "           bert_247     bert_248     bert_249     bert_250     bert_251  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.125318     0.912275    -0.066660    -0.033241    -0.083062   \n",
       "std        0.254912     0.209849     0.212497     0.266502     0.272207   \n",
       "min       -0.577000    -0.963000    -0.716481    -0.692514    -0.715000   \n",
       "25%       -0.061316     0.945341    -0.216750    -0.240848    -0.358000   \n",
       "50%        0.149943     0.967772    -0.013533    -0.064875    -0.075315   \n",
       "75%        0.363179     0.991776     0.031416     0.187617     0.134090   \n",
       "max        0.853315     0.999811     0.587880     0.617752     0.674912   \n",
       "\n",
       "           bert_252     bert_253     bert_254     bert_255     bert_256  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.164972     0.205428     0.998865    -0.083784    -0.090151   \n",
       "std        0.222489     0.211745     0.005609     0.324942     0.231811   \n",
       "min       -0.722000    -0.451000     0.850487    -0.761000    -0.841387   \n",
       "25%       -0.305000     0.082125     0.999402    -0.307750    -0.235380   \n",
       "50%       -0.208000     0.198819     0.999845    -0.051737    -0.113000   \n",
       "75%       -0.009545     0.353225     0.999923     0.165813     0.044188   \n",
       "max        0.620381     0.762029     0.999995     0.663382     0.641025   \n",
       "\n",
       "           bert_257     bert_258     bert_259     bert_260     bert_261  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.909157    -0.120614     0.569791    -0.340646    -0.993234   \n",
       "std        0.205226     0.442455     0.414975     0.256192     0.017271   \n",
       "min       -1.000000    -0.996288    -0.950000    -0.913161    -1.000000   \n",
       "25%       -0.999000    -0.493500     0.461058    -0.593000    -0.999163   \n",
       "50%       -0.991026    -0.017840     0.615349    -0.371000    -0.997178   \n",
       "75%       -0.932000     0.167349     0.886808    -0.155000    -0.995000   \n",
       "max        0.649716     0.923367     0.998270     0.526776    -0.636000   \n",
       "\n",
       "           bert_262     bert_263     bert_264     bert_265     bert_266  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.287275    -0.461420     0.067746     0.893798     0.984143   \n",
       "std        0.263636     0.396312     0.208874     0.139756     0.056364   \n",
       "min       -0.804000    -1.000000    -0.770000    -0.460213    -0.257016   \n",
       "25%       -0.562000    -0.804045    -0.059500     0.793719     0.993155   \n",
       "50%       -0.314243    -0.450332     0.040315     0.956561     0.998444   \n",
       "75%       -0.094940    -0.288288     0.227546     0.987421     0.999726   \n",
       "max        0.652757     0.923299     0.581010     0.999788     0.999992   \n",
       "\n",
       "           bert_267     bert_268     bert_269     bert_270     bert_271  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.736876     0.171120     0.018707     0.963371     0.032575   \n",
       "std        0.334785     0.225281     0.248871     0.106317     0.186117   \n",
       "min       -1.000000    -0.695628    -0.610000    -0.819000    -0.518000   \n",
       "25%       -0.961000     0.017694    -0.233000     0.941843    -0.074300   \n",
       "50%       -0.827997     0.216675     0.011731     0.997530    -0.001650   \n",
       "75%       -0.707416     0.325266     0.208894     0.999543     0.147346   \n",
       "max        0.959285     0.674402     0.738278     0.999995     0.722346   \n",
       "\n",
       "           bert_272     bert_273     bert_274     bert_275     bert_276  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.949307     0.999536    -0.339749    -0.921581     0.872988   \n",
       "std        0.169987     0.003445     0.217268     0.135076     0.240297   \n",
       "min       -1.000000     0.883295    -0.903486    -1.000000    -0.751000   \n",
       "25%       -0.997000     0.999834    -0.472000    -0.986234     0.889758   \n",
       "50%       -0.994000     0.999954    -0.385000    -0.955187     0.968664   \n",
       "75%       -0.974000     0.999976    -0.199673    -0.932000     0.989558   \n",
       "max        0.982296     0.999999     0.575400     0.445740     0.999974   \n",
       "\n",
       "           bert_277     bert_278     bert_279     bert_280     bert_281  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.209946    -0.205072    -0.006462    -0.564945    -0.975752   \n",
       "std        0.199148     0.659782     0.274101     0.524558     0.086778   \n",
       "min       -0.508292    -0.999100    -0.620690    -0.999080    -1.000000   \n",
       "25%        0.069824    -0.733500    -0.273000    -0.963000    -0.998990   \n",
       "50%        0.250652    -0.529708    -0.045705    -0.825000    -0.994674   \n",
       "75%        0.347250     0.409999     0.197654    -0.330750    -0.982000   \n",
       "max        0.684487     0.993890     0.730553     0.994929     0.637728   \n",
       "\n",
       "           bert_282     bert_283     bert_284     bert_285     bert_286  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.489153     0.998882     0.297025    -0.001529     0.125534   \n",
       "std        0.402413     0.004744     0.655606     0.212494     0.361362   \n",
       "min       -0.962580     0.882912    -0.994000    -0.659266    -0.626000   \n",
       "25%        0.294538     0.999408    -0.291571    -0.142651    -0.158295   \n",
       "50%        0.648756     0.999871     0.517365     0.041391     0.088582   \n",
       "75%        0.766516     0.999979     0.905841     0.102062     0.414465   \n",
       "max        0.992913     0.999998     0.999949     0.655948     0.840946   \n",
       "\n",
       "           bert_287     bert_288     bert_289     bert_290     bert_291  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.170281    -0.991666    -0.989481    -0.403833     0.238442   \n",
       "std        0.275984     0.064034     0.047431     0.569357     0.329345   \n",
       "min       -0.592000    -1.000000    -1.000000    -0.999000    -0.621000   \n",
       "25%       -0.045172    -1.000000    -1.000000    -0.951706    -0.025684   \n",
       "50%        0.175171    -0.999000    -0.998000    -0.595846     0.231734   \n",
       "75%        0.452830    -0.997382    -0.993690     0.010503     0.613621   \n",
       "max        0.809360     0.776875     0.228267     0.991767     0.822828   \n",
       "\n",
       "           bert_292     bert_293     bert_294     bert_295     bert_296  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.150443     0.970652     0.976065    -0.949620    -0.141693   \n",
       "std        0.295725     0.077684     0.123298     0.165396     0.195147   \n",
       "min       -0.753000     0.016488    -0.912137    -1.000000    -0.719000   \n",
       "25%       -0.060400     0.981575     0.991131    -0.998000    -0.257056   \n",
       "50%        0.165757     0.988693     0.997876    -0.994095    -0.152000   \n",
       "75%        0.451931     0.997004     0.998647    -0.974000    -0.013000   \n",
       "max        0.767208     0.999954     0.999979     0.859918     0.448626   \n",
       "\n",
       "           bert_297     bert_298     bert_299     bert_300     bert_301  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.702243    -0.155006     0.994330     0.999299    -0.785505   \n",
       "std        0.431620     0.222691     0.027542     0.005977     0.399771   \n",
       "min       -0.998055    -0.641000     0.383625     0.767087    -1.000000   \n",
       "25%        0.686365    -0.358000     0.996616     0.999767    -0.997534   \n",
       "50%        0.905977    -0.185806     0.999212     0.999940    -0.973000   \n",
       "75%        0.934253     0.009332     0.999898     0.999974    -0.801772   \n",
       "max        0.998859     0.646737     0.999990     1.000000     0.985196   \n",
       "\n",
       "           bert_302     bert_303     bert_304     bert_305     bert_306  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.081701     0.992855    -0.255933    -0.042672    -0.029664   \n",
       "std        0.541705     0.025993     0.269140     0.341029     0.196017   \n",
       "min       -0.993000     0.413318    -0.827126    -0.822204    -0.698610   \n",
       "25%       -0.379279     0.995856    -0.534336    -0.281000    -0.147750   \n",
       "50%        0.183749     0.998932    -0.277500    -0.116000    -0.030100   \n",
       "75%        0.437833     0.999795    -0.056300     0.212601     0.086464   \n",
       "max        0.999942     0.999969     0.551374     0.874461     0.603023   \n",
       "\n",
       "           bert_307     bert_308     bert_309     bert_310     bert_311  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.915311    -0.336839     0.178221     0.123379    -0.720830   \n",
       "std        0.252337     0.635495     0.208555     0.223043     0.357808   \n",
       "min       -0.978401    -0.999000    -0.592000    -0.596412    -0.999000   \n",
       "25%        0.971418    -0.937139     0.052816    -0.089600    -0.933883   \n",
       "50%        0.984296    -0.531528     0.218429     0.101432    -0.891000   \n",
       "75%        0.996357     0.219126     0.309227     0.300426    -0.643162   \n",
       "max        0.999925     0.992601     0.711388     0.696453     0.920425   \n",
       "\n",
       "           bert_312     bert_313     bert_314     bert_315     bert_316  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.071718     0.689480     0.919538     0.097846     0.146807   \n",
       "std        0.260343     0.453387     0.162447     0.215577     0.320594   \n",
       "min       -0.695916    -0.937000    -0.825000    -0.779466    -0.658000   \n",
       "25%       -0.270986     0.623520     0.920975    -0.025350    -0.095950   \n",
       "50%       -0.114680     0.920896     0.975089     0.134503     0.132511   \n",
       "75%        0.160198     0.967023     0.995186     0.235309     0.468164   \n",
       "max        0.760864     0.999895     0.999809     0.710914     0.830472   \n",
       "\n",
       "           bert_317     bert_318     bert_319     bert_320     bert_321  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.023611     0.273668     0.997687    -0.122799    -0.317663   \n",
       "std        0.251416     0.209463     0.006639     0.243180     0.554699   \n",
       "min       -0.776000    -0.576000     0.824581    -0.753000    -0.997835   \n",
       "25%       -0.158000     0.122935     0.998218    -0.367000    -0.712984   \n",
       "50%       -0.076895     0.261673     0.999532    -0.143188    -0.597000   \n",
       "75%        0.149229     0.437507     0.999923     0.062275     0.054624   \n",
       "max        0.726189     0.821350     0.999992     0.604601     0.985699   \n",
       "\n",
       "           bert_322     bert_323     bert_324     bert_325     bert_326  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.169167    -0.690747    -0.007389    -0.105326    -0.645451   \n",
       "std        0.200834     0.466317     0.238031     0.225080     0.436207   \n",
       "min       -0.773000    -1.000000    -0.721265    -0.724000    -0.999000   \n",
       "25%       -0.298000    -0.991000    -0.182000    -0.215847    -0.922000   \n",
       "50%       -0.137000    -0.922000     0.011787    -0.151000    -0.855000   \n",
       "75%       -0.080202    -0.606014     0.215898     0.056594    -0.549028   \n",
       "max        0.557848     0.988329     0.770670     0.689228     0.968133   \n",
       "\n",
       "           bert_327     bert_328     bert_329     bert_330     bert_331  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.211936    -0.605462     0.406008     0.869109    -0.251858   \n",
       "std        0.560950     0.527805     0.585483     0.241844     0.230420   \n",
       "min       -0.963358    -1.000000    -0.989295    -0.845576    -0.749440   \n",
       "25%       -0.260373    -0.948141    -0.010390     0.883986    -0.462955   \n",
       "50%        0.221707    -0.805000     0.656440     0.950278    -0.237385   \n",
       "75%        0.745350    -0.533250     0.898583     0.984227    -0.083175   \n",
       "max        0.992074     0.999999     0.997816     0.999930     0.432930   \n",
       "\n",
       "           bert_332     bert_333     bert_334     bert_335     bert_336  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.101048     0.711759    -0.000426     0.145720     0.181690   \n",
       "std        0.198146     0.470254     0.210024     0.216192     0.202254   \n",
       "min       -0.763057    -0.994188    -0.623000    -0.602390    -0.548268   \n",
       "25%       -0.228195     0.706601    -0.118000    -0.005339     0.053785   \n",
       "50%       -0.040650     0.941936    -0.023000     0.172994     0.213809   \n",
       "75%       -0.006180     0.964303     0.135159     0.353592     0.275760   \n",
       "max        0.438865     0.999914     0.762199     0.683400     0.735682   \n",
       "\n",
       "           bert_337     bert_338     bert_339     bert_340     bert_341  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.375926    -0.057395     0.024116     0.946504    -0.051931   \n",
       "std        0.519430     0.520455     0.209778     0.161159     0.300271   \n",
       "min       -0.998598    -0.997000    -0.608000    -0.958000    -0.685659   \n",
       "25%       -0.853519    -0.516500    -0.083964     0.942181    -0.389000   \n",
       "50%       -0.539932     0.086466    -0.032600     0.991273    -0.023403   \n",
       "75%        0.230965     0.290532     0.155957     0.998573     0.193639   \n",
       "max        0.977445     0.999645     0.707854     0.999982     0.674455   \n",
       "\n",
       "           bert_342     bert_343     bert_344     bert_345     bert_346  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.132038     0.974616    -0.724928     0.608499     0.217611   \n",
       "std        0.218558     0.084183     0.392113     0.460529     0.520497   \n",
       "min       -0.730394    -0.293000    -0.999305    -0.987997    -0.999915   \n",
       "25%       -0.265000     0.980873    -0.978000     0.484047    -0.172000   \n",
       "50%       -0.174675     0.991791    -0.904000     0.772209     0.277082   \n",
       "75%        0.020760     0.997678    -0.654064     0.967430     0.698373   \n",
       "max        0.650321     0.999958     0.996545     0.999914     0.996186   \n",
       "\n",
       "           bert_347     bert_348     bert_349     bert_350     bert_351  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.986603     0.023411     0.791111     0.008190     0.169028   \n",
       "std        0.027315     0.370829     0.311347     0.222514     0.233801   \n",
       "min        0.713126    -0.727397    -0.624000    -0.639000    -0.607000   \n",
       "25%        0.988264    -0.257454     0.705086    -0.119000    -0.002415   \n",
       "50%        0.996623    -0.038859     0.951219    -0.048116     0.213946   \n",
       "75%        0.997699     0.279127     0.995995     0.155006     0.311270   \n",
       "max        0.999959     0.645299     0.999939     0.788425     0.769908   \n",
       "\n",
       "           bert_352     bert_353     bert_354     bert_355     bert_356  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.435247     0.090533     0.054659    -0.025805    -0.747352   \n",
       "std        0.519958     0.194444     0.624659     0.181059     0.377054   \n",
       "min       -0.946000    -0.528897    -1.000000    -0.715078    -1.000000   \n",
       "25%        0.133670    -0.038405    -0.477861    -0.114000    -0.989000   \n",
       "50%        0.676108     0.118721     0.046060    -0.054279    -0.927000   \n",
       "75%        0.796157     0.223559     0.598059     0.095908    -0.682702   \n",
       "max        0.999938     0.676829     0.999888     0.566793     0.853553   \n",
       "\n",
       "           bert_357     bert_358     bert_359     bert_360     bert_361  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.063062    -0.158301     0.078462    -0.974978     0.249016   \n",
       "std        0.212471     0.239161     0.217440     0.091597     0.631427   \n",
       "min       -0.724000    -0.818000    -0.687000    -1.000000    -1.000000   \n",
       "25%       -0.222000    -0.326956    -0.052721    -0.999020    -0.257138   \n",
       "50%       -0.031693    -0.127000     0.122508    -0.996456     0.541228   \n",
       "75%        0.125186    -0.011900     0.193881    -0.965000     0.761431   \n",
       "max        0.532153     0.602924     0.840486     0.947838     1.000000   \n",
       "\n",
       "           bert_362     bert_363     bert_364     bert_365     bert_366  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.323349     0.013744     0.129302    -0.965607     0.125852   \n",
       "std        0.230816     0.290473     0.300534     0.088586     0.632820   \n",
       "min       -0.863058    -0.752627    -0.736766    -1.000000    -1.000000   \n",
       "25%       -0.506519    -0.311000    -0.171000    -0.996000    -0.413740   \n",
       "50%       -0.324500    -0.003751     0.171511    -0.982079     0.303367   \n",
       "75%       -0.103000     0.250799     0.380067    -0.973000     0.663391   \n",
       "max        0.541305     0.756643     0.824800     0.706445     1.000000   \n",
       "\n",
       "           bert_367     bert_368     bert_369     bert_370     bert_371  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.375051     0.187334     0.230155    -0.132296     0.891557   \n",
       "std        0.327601     0.310908     0.299089     0.281580     0.138680   \n",
       "min       -0.688000    -0.719672    -0.639597    -0.717282    -0.255447   \n",
       "25%        0.156090    -0.054446     0.001400    -0.396000     0.813125   \n",
       "50%        0.444012     0.207530     0.222210    -0.112004     0.961053   \n",
       "75%        0.605459     0.500001     0.488199     0.084666     0.989028   \n",
       "max        0.991480     0.844673     0.808253     0.552103     0.999688   \n",
       "\n",
       "           bert_372     bert_373     bert_374     bert_375     bert_376  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.223119    -0.014985     0.758897    -0.971322     0.014330   \n",
       "std        0.329867     0.275014     0.350532     0.076473     0.208300   \n",
       "min       -0.840000    -0.634000    -0.952000    -1.000000    -0.616000   \n",
       "25%       -0.479401    -0.315000     0.715184    -0.999000    -0.135000   \n",
       "50%       -0.199015    -0.016350     0.909687    -0.993845     0.035860   \n",
       "75%        0.033016     0.197144     0.975819    -0.976939     0.157041   \n",
       "max        0.618421     0.777019     0.999655    -0.058636     0.622074   \n",
       "\n",
       "           bert_377     bert_378     bert_379     bert_380     bert_381  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.159422    -0.077827    -0.247510     0.755626     0.276677   \n",
       "std        0.232135     0.188977     0.203697     0.328611     0.285248   \n",
       "min       -0.646000    -0.657045    -0.803095    -0.937000    -0.594000   \n",
       "25%       -0.360226    -0.214294    -0.400929     0.714353     0.056350   \n",
       "50%       -0.155462    -0.043949    -0.217500     0.916131     0.276865   \n",
       "75%        0.020087     0.014895    -0.152000     0.936504     0.556555   \n",
       "max        0.513653     0.620972     0.415663     0.999680     0.772389   \n",
       "\n",
       "           bert_382     bert_383     bert_384     bert_385     bert_386  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.904853     0.190960     0.986112    -0.568633     0.389392   \n",
       "std        0.251806     0.215277     0.050499     0.477662     0.193899   \n",
       "min       -1.000000    -0.547508     0.103260    -0.999000    -0.346000   \n",
       "25%       -0.998913     0.059877     0.990829    -0.884216     0.280688   \n",
       "50%       -0.990000     0.242910     0.997725    -0.808000     0.447064   \n",
       "75%       -0.943000     0.297789     0.998571    -0.408424     0.499746   \n",
       "max        0.909495     0.765239     0.999972     0.995207     0.872401   \n",
       "\n",
       "           bert_387     bert_388     bert_389     bert_390     bert_391  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.213662     0.170107    -0.184363    -0.207647     0.811034   \n",
       "std        0.206237     0.560408     0.190788     0.206606     0.270153   \n",
       "min       -0.801779    -0.963296    -0.709120    -0.761828    -0.977000   \n",
       "25%       -0.345000    -0.498270    -0.287000    -0.322000     0.729921   \n",
       "50%       -0.218000     0.255374    -0.231412    -0.255198     0.906029   \n",
       "75%       -0.097987     0.690875    -0.061825    -0.076750     0.976211   \n",
       "max        0.520141     0.999029     0.533940     0.571710     0.999895   \n",
       "\n",
       "           bert_392     bert_393     bert_394     bert_395     bert_396  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.997697    -0.065027    -0.057325    -0.067213    -0.085986   \n",
       "std        0.034960     0.345114     0.256775     0.346064     0.241341   \n",
       "min       -1.000000    -0.800578    -0.754000    -0.687190    -0.708000   \n",
       "25%       -1.000000    -0.347295    -0.251807    -0.275757    -0.250726   \n",
       "50%       -0.999953    -0.099600    -0.060346    -0.000362    -0.055300   \n",
       "75%       -0.999000     0.261849     0.225219     0.197017     0.056265   \n",
       "max        0.451266     0.676676     0.703847     0.693036     0.609401   \n",
       "\n",
       "           bert_397     bert_398     bert_399     bert_400     bert_401  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.253433     0.904121    -0.141577     0.093529    -0.854901   \n",
       "std        0.232467     0.177502     0.216880     0.292228     0.253092   \n",
       "min       -0.884692    -0.785000    -0.741000    -0.827000    -1.000000   \n",
       "25%       -0.434076     0.813875    -0.264000    -0.091596    -0.988965   \n",
       "50%       -0.223683     0.986055    -0.181981     0.171202    -0.943034   \n",
       "75%       -0.090300     0.998458    -0.000610     0.253461    -0.819000   \n",
       "max        0.491953     0.999997     0.696669     0.800939     0.878015   \n",
       "\n",
       "           bert_402     bert_403     bert_404     bert_405     bert_406  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.760969    -0.133706     0.990368    -0.306350     0.547217   \n",
       "std        0.445457     0.194200     0.030197     0.666579     0.595023   \n",
       "min       -1.000000    -0.722603     0.491679    -0.999194    -0.999000   \n",
       "25%       -0.993000    -0.237000     0.993749    -0.804750     0.289769   \n",
       "50%       -0.969200    -0.160000     0.998354    -0.672214     0.888770   \n",
       "75%       -0.786855    -0.022213     0.998855     0.196084     0.943390   \n",
       "max        0.993901     0.573441     0.999985     0.997224     0.999998   \n",
       "\n",
       "           bert_407     bert_408     bert_409     bert_410     bert_411  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.164632     0.103277    -0.945650     0.863793     0.384877   \n",
       "std        0.229869     0.197021     0.089316     0.268260     0.506214   \n",
       "min       -0.568757    -0.523000    -1.000000    -0.979000    -0.996000   \n",
       "25%       -0.000922    -0.026900    -0.996114     0.875521     0.099671   \n",
       "50%        0.170024     0.064967    -0.986000     0.971207     0.583595   \n",
       "75%        0.409910     0.238451    -0.888472     0.985944     0.751351   \n",
       "max        0.675777     0.725305     0.505148     0.999641     0.998111   \n",
       "\n",
       "           bert_412     bert_413     bert_414     bert_415     bert_416  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.995658     0.092363    -0.833877     0.255387     0.070781   \n",
       "std        0.011682     0.274614     0.375950     0.182812     0.192418   \n",
       "min       -1.000000    -0.476046    -1.000000    -0.401000    -0.574000   \n",
       "25%       -0.999783    -0.100789    -0.999000     0.151936    -0.024102   \n",
       "50%       -0.998496     0.136594    -0.989000     0.284013     0.061404   \n",
       "75%       -0.996000     0.293821    -0.903027     0.360608     0.174672   \n",
       "max       -0.814976     0.808821     0.998175     0.738181     0.720517   \n",
       "\n",
       "           bert_417     bert_418     bert_419     bert_420     bert_421  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.700873    -0.186339    -0.988517    -0.158457     0.908537   \n",
       "std        0.379642     0.437697     0.052976     0.259200     0.153893   \n",
       "min       -1.000000    -0.998156    -1.000000    -0.838000    -0.453000   \n",
       "25%       -0.931396    -0.468429    -0.999984    -0.359000     0.897098   \n",
       "50%       -0.852000    -0.306000    -0.998717    -0.204153     0.974323   \n",
       "75%       -0.652647     0.120833    -0.997000     0.029302     0.983934   \n",
       "max        0.981828     0.923119    -0.161000     0.711740     0.999988   \n",
       "\n",
       "           bert_422     bert_423     bert_424     bert_425     bert_426  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.099672     0.867975     0.154546    -0.739547    -0.151318   \n",
       "std        0.197093     0.204154     0.206659     0.424986     0.390015   \n",
       "min       -0.689512    -0.722479    -0.481127    -1.000000    -0.880248   \n",
       "25%       -0.241994     0.840746     0.023563    -0.982000    -0.507976   \n",
       "50%       -0.064350     0.947386     0.217635    -0.943129    -0.100477   \n",
       "75%       -0.002925     0.991067     0.266627    -0.710539     0.173688   \n",
       "max        0.624756     0.999722     0.721183     0.970492     0.685473   \n",
       "\n",
       "           bert_427     bert_428     bert_429     bert_430     bert_431  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.094617     0.013066    -0.161965     0.270036    -0.374523   \n",
       "std        0.234775     0.234032     0.224203     0.206189     0.627539   \n",
       "min       -0.638000    -0.603646    -0.742917    -0.637054    -1.000000   \n",
       "25%       -0.069539    -0.113204    -0.376000     0.123467    -0.898200   \n",
       "50%        0.141079    -0.056525    -0.175500     0.310165    -0.543000   \n",
       "75%        0.208881     0.173256    -0.019375     0.442581    -0.039273   \n",
       "max        0.770404     0.728162     0.762832     0.775758     0.992870   \n",
       "\n",
       "           bert_432     bert_433     bert_434     bert_435     bert_436  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.927891    -0.997540    -0.794221     0.254529    -0.846749   \n",
       "std        0.195136     0.019737     0.334527     0.194917     0.213116   \n",
       "min       -0.685159    -1.000000    -0.999000    -0.478560    -0.999000   \n",
       "25%        0.973259    -1.000000    -0.991000     0.138315    -0.983000   \n",
       "50%        0.987591    -1.000000    -0.946000     0.300556    -0.928000   \n",
       "75%        0.998820    -0.999556    -0.774433     0.351152    -0.810000   \n",
       "max        0.999980    -0.406430     0.948278     0.782009     0.450112   \n",
       "\n",
       "           bert_437     bert_438     bert_439     bert_440     bert_441  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.017562     0.039846     0.158037    -0.042259    -0.957067   \n",
       "std        0.605702     0.204200     0.201422     0.197196     0.173776   \n",
       "min       -0.998000    -0.583065    -0.658000    -0.631087    -1.000000   \n",
       "25%       -0.614766    -0.066200     0.041337    -0.161000    -0.999000   \n",
       "50%        0.062319     0.007812     0.134225    -0.052300    -0.995165   \n",
       "75%        0.481305     0.174696     0.292083     0.063023    -0.974000   \n",
       "max        0.999994     0.688133     0.694417     0.570395     0.909562   \n",
       "\n",
       "           bert_442     bert_443     bert_444     bert_445     bert_446  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.403770     0.119934    -0.974910    -0.906360    -0.718764   \n",
       "std        0.690947     0.269066     0.103834     0.180906     0.400217   \n",
       "min       -1.000000    -0.710000    -1.000000    -1.000000    -0.999912   \n",
       "25%       -0.962180    -0.085562    -0.999939    -0.989598    -0.962000   \n",
       "50%       -0.758735     0.143869    -0.998000    -0.960460    -0.885000   \n",
       "75%        0.102694     0.382346    -0.984000    -0.913000    -0.682250   \n",
       "max        0.937921     0.725732     0.543364     0.746886     0.959510   \n",
       "\n",
       "           bert_447     bert_448     bert_449     bert_450     bert_451  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.110172    -0.171162     0.062163     0.059076     0.125710   \n",
       "std        0.305185     0.212379     0.241193     0.250816     0.241499   \n",
       "min       -0.685632    -0.837827    -0.612000    -0.690000    -0.506000   \n",
       "25%       -0.128428    -0.289807    -0.144000    -0.086200    -0.093945   \n",
       "50%        0.142049    -0.236000     0.030745     0.012167     0.149092   \n",
       "75%        0.407996    -0.038625     0.238411     0.206076     0.311333   \n",
       "max        0.746191     0.572448     0.806245     0.866998     0.750561   \n",
       "\n",
       "           bert_452     bert_453     bert_454     bert_455     bert_456  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.018578     0.953473     0.253339     0.894297    -0.044887   \n",
       "std        0.273904     0.143323     0.211838     0.226058     0.252827   \n",
       "min       -0.675000    -0.916000    -0.543000    -0.649081    -0.752000   \n",
       "25%       -0.212395     0.976282     0.125205     0.910419    -0.232497   \n",
       "50%        0.020349     0.989491     0.313874     0.989648    -0.030026   \n",
       "75%        0.299969     0.997252     0.365457     0.999129     0.182800   \n",
       "max        0.665915     0.999976     0.852328     0.999977     0.651374   \n",
       "\n",
       "           bert_457     bert_458     bert_459     bert_460     bert_461  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.002875     0.010952     0.939382     0.469945     0.127449   \n",
       "std        0.244844     0.296200     0.147078     0.499066     0.305140   \n",
       "min       -0.779447    -0.742134    -0.752923    -0.974034    -0.651000   \n",
       "25%       -0.105000    -0.214054     0.955292     0.321897    -0.088170   \n",
       "50%       -0.031300     0.030396     0.988817     0.528637     0.066390   \n",
       "75%        0.178145     0.229443     0.992661     0.892591     0.283471   \n",
       "max        0.654068     0.772500     0.999941     0.999393     0.655903   \n",
       "\n",
       "           bert_462     bert_463     bert_464     bert_465     bert_466  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.997324     0.263195     0.688327     0.987100     0.668545   \n",
       "std        0.015154     0.177645     0.493438     0.074934     0.343467   \n",
       "min       -1.000000    -0.442000    -1.000000    -0.728000    -0.952000   \n",
       "25%       -1.000000     0.166574     0.679187     0.996178     0.556878   \n",
       "50%       -0.999928     0.261203     0.910099     0.997985     0.830977   \n",
       "75%       -0.999000     0.361354     0.964800     0.999273     0.876738   \n",
       "max       -0.573000     0.832665     0.999949     0.999981     0.993202   \n",
       "\n",
       "           bert_467     bert_468     bert_469     bert_470     bert_471  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.865766    -0.923011    -0.016541     0.202193    -0.439971   \n",
       "std        0.269569     0.221490     0.207502     0.191148     0.462214   \n",
       "min       -0.793000    -1.000000    -0.727057    -0.530383    -0.999281   \n",
       "25%        0.878197    -0.997000    -0.162919     0.090027    -0.841072   \n",
       "50%        0.988346    -0.993000     0.019168     0.244346    -0.429000   \n",
       "75%        0.999192    -0.964000     0.073809     0.311607    -0.247067   \n",
       "max        0.999949     0.980243     0.597582     0.761616     0.997880   \n",
       "\n",
       "           bert_472     bert_473     bert_474     bert_475     bert_476  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.146114     0.034200     0.327744    -0.998401    -0.988314   \n",
       "std        0.501135     0.223119     0.205660     0.007580     0.054641   \n",
       "min       -0.999908    -0.613000    -0.471403    -1.000000    -1.000000   \n",
       "25%       -0.226000    -0.104000     0.222175    -1.000000    -0.999000   \n",
       "50%        0.180847    -0.022238     0.315518    -0.999926    -0.996000   \n",
       "75%        0.591078     0.177966     0.458489    -0.999000    -0.994000   \n",
       "max        0.991572     0.724668     0.807812    -0.800068     0.567936   \n",
       "\n",
       "           bert_477     bert_478     bert_479     bert_480     bert_481  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.128386    -0.964940     0.944932     0.263526     0.060183   \n",
       "std        0.237660     0.064294     0.115901     0.240488     0.181986   \n",
       "min       -0.771475    -0.999703    -0.257039    -0.528000    -0.557000   \n",
       "25%       -0.350000    -0.996000     0.955317     0.087440    -0.052403   \n",
       "50%       -0.144094    -0.985439     0.990643     0.282580     0.066373   \n",
       "75%        0.039327    -0.963423     0.994704     0.495989     0.158718   \n",
       "max        0.650759     0.173877     0.999947     0.833871     0.724718   \n",
       "\n",
       "           bert_482     bert_483     bert_484     bert_485     bert_486  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.227198     0.351286     0.008082    -0.965911    -0.971794   \n",
       "std        0.285316     0.275378     0.300803     0.126326     0.112498   \n",
       "min       -0.652500    -0.611277    -0.788156    -1.000000    -1.000000   \n",
       "25%        0.025795     0.144000    -0.223062    -0.999444    -0.999000   \n",
       "50%        0.234510     0.351656    -0.021150    -0.996859    -0.996611   \n",
       "75%        0.492218     0.596156     0.227827    -0.983986    -0.985070   \n",
       "max        0.831223     0.857264     0.562839     0.665869     0.811324   \n",
       "\n",
       "           bert_487     bert_488     bert_489     bert_490     bert_491  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.077067    -0.293372    -0.057711    -0.195597    -0.998782   \n",
       "std        0.234109     0.267117     0.235559     0.220349     0.009998   \n",
       "min       -0.794000    -0.947340    -0.827958    -0.795298    -1.000000   \n",
       "25%       -0.215464    -0.465949    -0.231820    -0.387000    -1.000000   \n",
       "50%       -0.068000    -0.335000    -0.020850    -0.218660    -0.999992   \n",
       "75%        0.064296    -0.155000     0.081449    -0.029250    -0.998922   \n",
       "max        0.627456     0.692022     0.639881     0.512733    -0.726000   \n",
       "\n",
       "           bert_492     bert_493     bert_494     bert_495     bert_496  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.721853     0.533547     0.006488    -0.126049    -0.080342   \n",
       "std        0.438134     0.553381     0.270221     0.278867     0.202949   \n",
       "min       -1.000000    -0.958173    -0.749407    -0.706373    -0.711203   \n",
       "25%       -0.994000     0.195281    -0.214000    -0.388000    -0.184867   \n",
       "50%       -0.938465     0.825024    -0.019347    -0.106346    -0.138382   \n",
       "75%       -0.628250     0.979321     0.207001     0.080044     0.038998   \n",
       "max        0.974046     0.998933     0.726460     0.630337     0.625495   \n",
       "\n",
       "           bert_497     bert_498     bert_499     bert_500     bert_501  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.249518    -0.801895     0.995457    -0.588631    -0.095093   \n",
       "std        0.199501     0.439654     0.013650     0.497718     0.182570   \n",
       "min       -0.458000    -1.000000     0.790047    -1.000000    -0.707592   \n",
       "25%        0.139450    -0.997523     0.996744    -0.980000    -0.218092   \n",
       "50%        0.261339    -0.981609     0.999213    -0.825000    -0.057450   \n",
       "75%        0.379070    -0.913000     0.999888    -0.392000    -0.007744   \n",
       "max        0.807282     0.992221     0.999990     0.973581     0.688424   \n",
       "\n",
       "           bert_502     bert_503     bert_504     bert_505     bert_506  \\\n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      -0.142566     0.004998    -0.000069    -0.346613     0.916262   \n",
       "std        0.297224     0.216946     0.281287     0.479710     0.198929   \n",
       "min       -0.763298    -0.668000    -0.707100    -0.996000    -0.828620   \n",
       "25%       -0.476000    -0.130000    -0.226527    -0.717840     0.937396   \n",
       "50%       -0.135000     0.021458    -0.021597    -0.354000     0.990094   \n",
       "75%        0.085176     0.140147     0.300223    -0.131566     0.998700   \n",
       "max        0.633263     0.717464     0.836734     0.963574     0.999975   \n",
       "\n",
       "           bert_507     bert_508     bert_509     bert_510     bert_511  \n",
       "count   1822.000000  1822.000000  1822.000000  1822.000000  1822.000000  \n",
       "unique          NaN          NaN          NaN          NaN          NaN  \n",
       "top             NaN          NaN          NaN          NaN          NaN  \n",
       "freq            NaN          NaN          NaN          NaN          NaN  \n",
       "mean      -0.924423     0.027265     0.218671    -0.364465    -0.612300  \n",
       "std        0.190608     0.220105     0.203953     0.197685     0.317891  \n",
       "min       -1.000000    -0.678242    -0.459000    -0.823295    -0.999774  \n",
       "25%       -0.997993    -0.126000     0.102501    -0.512000    -0.880000  \n",
       "50%       -0.987879     0.079729     0.192325    -0.410675    -0.662256  \n",
       "75%       -0.947566     0.140955     0.361271    -0.242138    -0.475000  \n",
       "max        0.973928     0.672684     0.770595     0.370205     0.797859  "
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bert_0', 'bert_1', 'bert_2', 'bert_3', 'bert_4', 'bert_5', 'bert_6',\n",
      "       'bert_7', 'bert_8', 'bert_9',\n",
      "       ...\n",
      "       'bert_502', 'bert_503', 'bert_504', 'bert_505', 'bert_506', 'bert_507',\n",
      "       'bert_508', 'bert_509', 'bert_510', 'bert_511'],\n",
      "      dtype='object', length=512)\n"
     ]
    }
   ],
   "source": [
    "X_start, X_end = X_column_range.split(\":\")\n",
    "if(len(X_end) == 0): \n",
    "    X = df_dataset.iloc[:, int(X_start):]\n",
    "else:\n",
    "    X = df_dataset.iloc[:, int(X_start):int(X_end)]\n",
    "print(X.columns)\n",
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CPS_CONST_EstablishesCG_Interrupts']\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "Y = df_dataset[Y_column_names].copy(deep=True)\n",
    "num_classes = len(Y_column_names)\n",
    "Y = Y.fillna(0)\n",
    "Y = Y.to_numpy()\n",
    "Y = Y.flatten()\n",
    "print(Y_column_names)\n",
    "print(Y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "utteranceIDs = pd.DataFrame(df_dataset[utteranceID], columns=[utteranceID])\n",
    "utteranceIDs = utteranceIDs.to_numpy()\n",
    "utteranceIDs=utteranceIDs.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Group_01' 'Group_02' 'Group_03' 'Group_04' 'Group_05' 'Group_06'\n",
      " 'Group_07' 'Group_08' 'Group_09' 'Group_10']\n"
     ]
    }
   ],
   "source": [
    "groups = pd.DataFrame(df_dataset[Group], columns=[Group])\n",
    "groups = groups.to_numpy()\n",
    "groups = groups.reshape(-1)\n",
    "unique_groups = np.unique(groups)\n",
    "print(unique_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1822, 512) (1822,)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(resultsDir):\n",
    "        os.mkdir(resultsDir)\n",
    "modelcsv =os.path.join(resultsDir, output_name)\n",
    "if not os.path.exists(modelcsv):\n",
    "        os.mkdir(modelcsv)\n",
    "else:\n",
    "        print(\"WARNING: DIRECTORY ALREADY EXISTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = LeaveOneGroupOut()\n",
    "best = 0\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = hp.choice('classifier_type', [\n",
    "    # {\n",
    "    #     'type': 'AdaBoost',\n",
    "    #     'n_estimators': hp.choice('AdaBoost_n_estimators', list(range(30, 100, 11))),\n",
    "    #     # 'learning_rate': hp.choice('AdaBoost_learning_rate', list(np.linspace(0.1, 4.1, 50))),\n",
    "    #     'learning_rate': hp.choice('AdaBoost_learning_rate', [.001, 0.1, 1.0, 10]),\n",
    "    #     'algorithm': hp.choice('AdaBoost_algorithm', ['SAMME', 'SAMME.R'])\n",
    "    # },\n",
    "    \n",
    "    # {\n",
    "    #     'type': 'naive_bayes',\n",
    "        \n",
    "    # },\n",
    "    # {\n",
    "    #     'type': 'logistic_regression',\n",
    "    #     'penalty' : hp.choice('logistic_regression_penalty', ['l2', 'none']),\n",
    "    #     'solver' : hp.choice('logistic_regression_solver', ['lbfgs', 'newton-cg', 'sag', 'saga'])\n",
    "    # },\n",
    "    # {\n",
    "    #     'type': 'LinSVC',\n",
    "    #     'C': hp.uniform('LinSVC.C', 0, 3.0),\n",
    "\n",
    "    # },\n",
    "    # {\n",
    "    #     'type': 'SVC',\n",
    "    #     'C': hp.choice('C', [0.1, 1, 10, 100, 1000]),\n",
    "    #     'gamma': hp.choice('gamma', [1, 0.1, 0.01, 0.001, 0.0001]),\n",
    "    #     'kernel': hp.choice('kernal', ['rbf', 'sigmoid']),\n",
    "\n",
    "    # },\n",
    "    \n",
    "    # {\n",
    "    #     'type': 'decision_tree',\n",
    "        \n",
    "    #     'criterion': hp.choice('decision_tree.criterion', [\"gini\", \"entropy\"]),\n",
    "    #     'splitter': hp.choice('splitter', [\"best\", \"random\"]),\n",
    "    #     'max_features': hp.choice('decision_tree.max_features', [\"auto\", \"sqrt\", \"log2\"]),\n",
    "\n",
    "    # },\n",
    "    {\n",
    "        'type': 'randomforest',\n",
    "        'n_estimators': hp.choice('n_estimators', list(range(20, 170, 16))),\n",
    "        'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "        'max_features': hp.choice('max_features', [None, \"sqrt\", \"log2\"]),\n",
    "        \n",
    "    # },\n",
    "    # {\n",
    "    #     'type': 'knn',\n",
    "    #     'n_neighbors': hp.choice('knn_n_neighbors', list(range(1, 150, 10)))\n",
    "    }\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_train_test(params, groups, cv):\n",
    "    resultsDict = {}\n",
    "    model_name = params['type']\n",
    "    predictioncsv = model_name\n",
    "    del params['type']\n",
    "    for item in params.values():\n",
    "        predictioncsv += '_' + str(item)\n",
    "    predictioncsv += '.csv'\n",
    "    resultsDict[\"predictioncsv\"] = predictioncsv\n",
    "    \n",
    "    if model_name == 'naive_bayes':\n",
    "        clf = GaussianNB(**params)\n",
    "    elif model_name == 'AdaBoost':\n",
    "        clf = AdaBoostClassifier(**params)\n",
    "    elif model_name == 'LinSVC':\n",
    "        clf = LinearSVC(**params)      \n",
    "    elif model_name == 'decision_tree':\n",
    "        clf = DecisionTreeClassifier(**params, random_state=1) \n",
    "    elif model_name == 'randomforest':\n",
    "        clf = RandomForestClassifier(**params, random_state=1)\n",
    "    elif model_name == 'knn':\n",
    "        clf = KNeighborsClassifier(**params)\n",
    "    elif model_name == 'logistic_regression':\n",
    "        clf = LogisticRegression(**params, random_state=1)\n",
    "    elif model_name == 'SVC':\n",
    "        clf = SVC(**params, probability=True)    \n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    resultsDict[\"model_name\"] = model_name\n",
    "    \n",
    "    # y_pred = cross_val_predict(clf, X, Y, groups=groups, n_jobs=20,cv=cv, verbose=0, method='predict')\n",
    "    # estimator = 'predict_proba'\n",
    "    # if model_name == 'LinSVC':\n",
    "    #     y_score = cross_val_predict(clf, X, Y, groups=groups, n_jobs=20,cv=cv, verbose=0, method='decision_function')\n",
    "    # else:\n",
    "    #     y_score = cross_val_predict(clf, X, Y, groups=groups, n_jobs=20,cv=cv, verbose=0, method=estimator)\n",
    "    #     y_score = np.array(y_score[:, 1])\n",
    "\n",
    "    # y_pred = np.array(y_pred)\n",
    "    # print(Y.shape)\n",
    "    # print(y_pred.shape)\n",
    "    # print(y_score.shape)\n",
    "\n",
    "    # resultsDict[\"y_pred\"] = y_pred\n",
    "    # resultsDict[\"f1\"] = f1_score(Y, y_pred)\n",
    "    # resultsDict[\"accuracy\"] = accuracy_score(Y, y_pred)\n",
    "    # try:\n",
    "    #     resultsDict[\"auroc\"] = roc_auc_score(Y, y_score)\n",
    "    #     print(resultsDict[\"auroc\"])\n",
    "    # except:\n",
    "    #     print(f\"ROC_AUC Issue with class\")\n",
    "    #     resultsDict[\"auroc\"] = -1\n",
    "    # try:\n",
    "    #     resultsDict[\"kappa\"] = cohen_kappa_score(Y, y_pred)\n",
    "    # except:\n",
    "    #     print(f\"Kappa issue with class\")\n",
    "    #     resultsDict[\"kappa\"] = -1\n",
    "    # resultsDict[\"matthews_cc\"] = matthews_corrcoef(Y, y_pred)\n",
    "    # resultsDict[\"confusion_matrix\"] = multilabel_confusion_matrix(Y, y_pred)\n",
    "    # return resultsDict[guide_metric_name], resultsDict\n",
    "\n",
    "    scoring = {\n",
    "    'f1': make_scorer(f1_score, average='weighted'),  # You can adjust 'average' as needed\n",
    "    'kappa': make_scorer(cohen_kappa_score),\n",
    "    'accuracy': make_scorer(accuracy_score)\n",
    "    }\n",
    "\n",
    "    listOfScores = []\n",
    "    scores = cross_validate(clf, X, Y,groups=groups, n_jobs=20,cv=cv,scoring=scoring)\n",
    "    print(\"Mean F1 Score:\", scores['test_f1'].mean())\n",
    "    print(\"Mean Kappa Score:\", scores['test_kappa'].mean())\n",
    "    print(\"Mean Accuracy Score:\", scores['test_accuracy'].mean())\n",
    "    resultsDict[\"averageF1\"] = scores['test_f1'].mean()\n",
    "    resultsDict[\"averageKappa\"] = scores['test_kappa'].mean()\n",
    "    resultsDict[\"averageAccuracy\"] = scores['test_accuracy'].mean()\n",
    "    resultsDict[\"stdF1\"] = scores['test_f1'].std()\n",
    "    resultsDict[\"stdKappa\"] = scores['test_kappa'].std()\n",
    "    resultsDict[\"stdAccuracy\"] = scores['test_accuracy'].std()\n",
    "    listOfScores.append(scores)\n",
    "    return resultsDict[guide_metric_name], resultsDict \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "def f(params):\n",
    "    global best, count, avg\n",
    "    count += 1\n",
    "\n",
    "    guide_metric, scores = hyperopt_train_test(params.copy(), groups, cv)\n",
    "    results.append(scores)\n",
    "    # with open(os.path.join(modelcsv,scores[\"predictioncsv\"]), 'w', newline = '') as modelCSV:\n",
    "    #     writer = csv.writer(modelCSV)\n",
    "    #     print(\"model: \", scores[\"predictioncsv\"])\n",
    "    #     writer.writerow(['utteranceID', 'True Label', 'Pred Label'])\n",
    "    #     for pred in range(len(scores[\"y_pred\"])):\n",
    "    #         writer.writerow([utteranceIDs[pred], Y[pred], scores[\"y_pred\"][pred]])\n",
    "    if guide_metric > best:\n",
    "        print (scores)\n",
    "        best = guide_metric\n",
    "    else: \n",
    "        print (scores)\n",
    "        \n",
    "    return {'loss': -guide_metric, 'status': STATUS_OK, 'eval_time': time.time(), \n",
    "            'other_stuff': {'model':scores[\"model_name\"],'f1_0':scores[\"averageF1\"] ,'accuracy': scores[\"averageAccuracy\"],\n",
    "                           'kappa':scores[\"averageKappa\"]}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1822,)                                                \n",
      "(1822,)                                                \n",
      "(1822,)                                                \n",
      "0.7251415037098675                                     \n",
      "model:                                                 \n",
      "AdaBoost_SAMME.R_1.0_96.csv                            \n",
      "{'predictioncsv': 'AdaBoost_SAMME.R_1.0_96.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.3481481481481482, 'accuracy': 0.8068057080131723, 'auroc': 0.7251415037098675, 'kappa': 0.2368513741206485, 'matthews_cc': 0.23946803581226594, 'confusion_matrix': array([[[  94,  210],\n",
      "        [ 142, 1376]],\n",
      "\n",
      "       [[1376,  142],\n",
      "        [ 210,   94]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8037844116219403                                                                  \n",
      "model:                                                                              \n",
      "knn_121.csv                                                                         \n",
      "{'predictioncsv': 'knn_121.csv', 'model_name': 'knn', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.006535947712418301, 'accuracy': 0.8331503841931943, 'auroc': 0.8037844116219403, 'kappa': 0.004364425973727326, 'matthews_cc': 0.02962069998116901, 'confusion_matrix': array([[[   1,  303],\n",
      "        [   1, 1517]],\n",
      "\n",
      "       [[1517,    1],\n",
      "        [ 303,    1]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                           \n",
      "(1822,)                                                                           \n",
      "0.5272952638513279                                                                \n",
      "model:                                                                            \n",
      "decision_tree_gini_auto_random.csv                                                \n",
      "{'predictioncsv': 'decision_tree_gini_auto_random.csv', 'model_name': 'decision_tree', 'y_pred': array([0., 0., 0., ..., 0., 1., 1.]), 'f1': 0.3185298621745789, 'accuracy': 0.7557628979143798, 'auroc': 0.5272952638513279, 'kappa': 0.1706101021508346, 'matthews_cc': 0.1712133501393376, 'confusion_matrix': array([[[ 104,  200],\n",
      "        [ 245, 1273]],\n",
      "\n",
      "       [[1273,  245],\n",
      "        [ 200,  104]]], dtype=int64)}\n",
      "(1822,)                                                                           \n",
      "(1822,)                                                                           \n",
      "(1822,)                                                                           \n",
      "0.7295068823243882                                                                \n",
      "model:                                                                            \n",
      "AdaBoost_SAMME.R_0.001_52.csv                                                     \n",
      "{'predictioncsv': 'AdaBoost_SAMME.R_0.001_52.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.7295068823243882, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                           \n",
      "(1822,)                                                                           \n",
      "(1822,)                                                                           \n",
      "0.6866516278344081                                                                \n",
      "model:                                                                            \n",
      "LinSVC_2.4541075847322134.csv                                                     \n",
      "{'predictioncsv': 'LinSVC_2.4541075847322134.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.36966824644549756, 'accuracy': 0.7810098792535675, 'auroc': 0.6866516278344081, 'kappa': 0.23740420059289158, 'matthews_cc': 0.23767567311399704, 'confusion_matrix': array([[[ 117,  187],\n",
      "        [ 212, 1306]],\n",
      "\n",
      "       [[1306,  212],\n",
      "        [ 187,  117]]], dtype=int64)}\n",
      "(1822,)                                                                           \n",
      "(1822,)                                                                           \n",
      "(1822,)                                                                           \n",
      "0.5170617068857916                                                                \n",
      "model:                                                                            \n",
      "AdaBoost_SAMME_0.001_74.csv                                                       \n",
      "{'predictioncsv': 'AdaBoost_SAMME_0.001_74.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.5170617068857916, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                           \n",
      "(1822,)                                                                           \n",
      "(1822,)                                                                           \n",
      "0.7763818823243879                                                                \n",
      "model:                                                                            \n",
      "LinSVC_0.04968704653346778.csv                                                    \n",
      "{'predictioncsv': 'LinSVC_0.04968704653346778.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.3768115942028986, 'accuracy': 0.8347969264544457, 'auroc': 0.7763818823243879, 'kappa': 0.28886635528803384, 'matthews_cc': 0.30235185219307464, 'confusion_matrix': array([[[  91,  213],\n",
      "        [  88, 1430]],\n",
      "\n",
      "       [[1430,   88],\n",
      "        [ 213,   91]]], dtype=int64)}\n",
      "(1822,)                                                                           \n",
      "(1822,)                                                                           \n",
      "(1822,)                                                                           \n",
      "0.7768976232577491                                                                \n",
      "model:                                                                            \n",
      "SVC_0.1_0.001_sigmoid.csv                                                         \n",
      "{'predictioncsv': 'SVC_0.1_0.001_sigmoid.csv', 'model_name': 'SVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.7768976232577491, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                           \n",
      "(1822,)                                                                           \n",
      "(1822,)                                                                           \n",
      "0.49405597739407814                                                               \n",
      "model:                                                                            \n",
      "decision_tree_gini_log2_best.csv                                                  \n",
      "{'predictioncsv': 'decision_tree_gini_log2_best.csv', 'model_name': 'decision_tree', 'y_pred': array([1., 0., 0., ..., 0., 0., 0.]), 'f1': 0.2728785357737105, 'accuracy': 0.7601536772777168, 'auroc': 0.49405597739407814, 'kappa': 0.129293583218692, 'matthews_cc': 0.12930616050765115, 'confusion_matrix': array([[[  82,  222],\n",
      "        [ 215, 1303]],\n",
      "\n",
      "       [[1303,  215],\n",
      "        [ 222,   82]]], dtype=int64)}\n",
      "(1822,)                                                                           \n",
      "(1822,)                                                                           \n",
      "(1822,)                                                                           \n",
      "0.736004567991124                                                                 \n",
      "model:                                                                            \n",
      "LinSVC_0.37763446315774096.csv                                                    \n",
      "{'predictioncsv': 'LinSVC_0.37763446315774096.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.38245614035087716, 'accuracy': 0.8068057080131723, 'auroc': 0.736004567991124, 'kappa': 0.2685501567040598, 'matthews_cc': 0.26939132548846245, 'confusion_matrix': array([[[ 109,  195],\n",
      "        [ 157, 1361]],\n",
      "\n",
      "       [[1361,  157],\n",
      "        [ 195,  109]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7945910044379723                                                                 \n",
      "model:                                                                             \n",
      "SVC_1_0.1_rbf.csv                                                                  \n",
      "{'predictioncsv': 'SVC_1_0.1_rbf.csv', 'model_name': 'SVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.7945910044379723, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.5299909853685597                                                                 \n",
      "model:                                                                             \n",
      "AdaBoost_SAMME_10_41.csv                                                           \n",
      "{'predictioncsv': 'AdaBoost_SAMME_10_41.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.5299909853685597, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.49405597739407814                                                                \n",
      "model:                                                                             \n",
      "decision_tree_gini_log2_best.csv                                                   \n",
      "{'predictioncsv': 'decision_tree_gini_log2_best.csv', 'model_name': 'decision_tree', 'y_pred': array([1., 0., 0., ..., 0., 0., 0.]), 'f1': 0.2728785357737105, 'accuracy': 0.7601536772777168, 'auroc': 0.49405597739407814, 'kappa': 0.129293583218692, 'matthews_cc': 0.12930616050765115, 'confusion_matrix': array([[[  82,  222],\n",
      "        [ 215, 1303]],\n",
      "\n",
      "       [[1303,  215],\n",
      "        [ 222,   82]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.6763259742736288                                                                 \n",
      "model:                                                                             \n",
      "LinSVC_2.888068854941908.csv                                                       \n",
      "{'predictioncsv': 'LinSVC_2.888068854941908.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 1., ..., 0., 0., 0.]), 'f1': 0.3850931677018633, 'accuracy': 0.7826564215148188, 'auroc': 0.6763259742736288, 'kappa': 0.2535938625021724, 'matthews_cc': 0.2541796993331428, 'confusion_matrix': array([[[ 124,  180],\n",
      "        [ 216, 1302]],\n",
      "\n",
      "       [[1302,  216],\n",
      "        [ 180,  124]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.755785833159975                                                                  \n",
      "model:                                                                             \n",
      "naive_bayes.csv                                                                    \n",
      "{'predictioncsv': 'naive_bayes.csv', 'model_name': 'naive_bayes', 'y_pred': array([1., 0., 1., ..., 1., 1., 0.]), 'f1': 0.4318181818181818, 'accuracy': 0.6432491767288694, 'auroc': 0.755785833159975, 'kappa': 0.24741746565941036, 'matthews_cc': 0.31552944095924307, 'confusion_matrix': array([[[247,  57],\n",
      "        [593, 925]],\n",
      "\n",
      "       [[925, 593],\n",
      "        [ 57, 247]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7970082691907634                                                                 \n",
      "model:                                                                             \n",
      "AdaBoost_SAMME.R_0.1_41.csv                                                        \n",
      "{'predictioncsv': 'AdaBoost_SAMME.R_0.1_41.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.02572347266881029, 'accuracy': 0.8336992316136114, 'auroc': 0.7970082691907634, 'kappa': 0.01835038567816394, 'matthews_cc': 0.06738910513019522, 'confusion_matrix': array([[[   4,  300],\n",
      "        [   3, 1515]],\n",
      "\n",
      "       [[1515,    3],\n",
      "        [ 300,    4]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7925930500658761                                                                 \n",
      "model:                                                                             \n",
      "logistic_regression_none_saga.csv                                                  \n",
      "{'predictioncsv': 'logistic_regression_none_saga.csv', 'model_name': 'logistic_regression', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.40377358490566045, 'accuracy': 0.8265642151481888, 'auroc': 0.7925930500658761, 'kappa': 0.30485890767544177, 'matthews_cc': 0.30944826077596155, 'confusion_matrix': array([[[ 107,  197],\n",
      "        [ 119, 1399]],\n",
      "\n",
      "       [[1399,  119],\n",
      "        [ 197,  107]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7280084165453159                                                                 \n",
      "model:                                                                             \n",
      "SVC_1000_0.001_sigmoid.csv                                                         \n",
      "{'predictioncsv': 'SVC_1000_0.001_sigmoid.csv', 'model_name': 'SVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.3851590106007068, 'accuracy': 0.8090010976948409, 'auroc': 0.7280084165453159, 'kappa': 0.2728348678144309, 'matthews_cc': 0.2738916699405024, 'confusion_matrix': array([[[ 109,  195],\n",
      "        [ 153, 1365]],\n",
      "\n",
      "       [[1365,  153],\n",
      "        [ 195,  109]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7493748266417031                                                                 \n",
      "model:                                                                             \n",
      "logistic_regression_none_lbfgs.csv                                                 \n",
      "{'predictioncsv': 'logistic_regression_none_lbfgs.csv', 'model_name': 'logistic_regression', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.372093023255814, 'accuracy': 0.7925356750823271, 'auroc': 0.7493748266417031, 'kappa': 0.24784745429526245, 'matthews_cc': 0.24786512002809344, 'confusion_matrix': array([[[ 112,  192],\n",
      "        [ 186, 1332]],\n",
      "\n",
      "       [[1332,  186],\n",
      "        [ 192,  112]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.6867968154080855                                                                 \n",
      "model:                                                                             \n",
      "LinSVC_1.5900621226461849.csv                                                      \n",
      "{'predictioncsv': 'LinSVC_1.5900621226461849.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 1., ..., 0., 0., 0.]), 'f1': 0.3824451410658308, 'accuracy': 0.7837541163556532, 'auroc': 0.6867968154080855, 'kappa': 0.2517251012128868, 'matthews_cc': 0.25213467096241426, 'confusion_matrix': array([[[ 122,  182],\n",
      "        [ 212, 1306]],\n",
      "\n",
      "       [[1306,  212],\n",
      "        [ 182,  122]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8037844116219403                                                                 \n",
      "model:                                                                             \n",
      "knn_121.csv                                                                        \n",
      "{'predictioncsv': 'knn_121.csv', 'model_name': 'knn', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.006535947712418301, 'accuracy': 0.8331503841931943, 'auroc': 0.8037844116219403, 'kappa': 0.004364425973727326, 'matthews_cc': 0.02962069998116901, 'confusion_matrix': array([[[   1,  303],\n",
      "        [   1, 1517]],\n",
      "\n",
      "       [[1517,    1],\n",
      "        [ 303,    1]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8037844116219403                                                                 \n",
      "model:                                                                             \n",
      "knn_121.csv                                                                        \n",
      "{'predictioncsv': 'knn_121.csv', 'model_name': 'knn', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.006535947712418301, 'accuracy': 0.8331503841931943, 'auroc': 0.8037844116219403, 'kappa': 0.004364425973727326, 'matthews_cc': 0.02962069998116901, 'confusion_matrix': array([[[   1,  303],\n",
      "        [   1, 1517]],\n",
      "\n",
      "       [[1517,    1],\n",
      "        [ 303,    1]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8037844116219403                                                                 \n",
      "model:                                                                             \n",
      "knn_121.csv                                                                        \n",
      "{'predictioncsv': 'knn_121.csv', 'model_name': 'knn', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.006535947712418301, 'accuracy': 0.8331503841931943, 'auroc': 0.8037844116219403, 'kappa': 0.004364425973727326, 'matthews_cc': 0.02962069998116901, 'confusion_matrix': array([[[   1,  303],\n",
      "        [   1, 1517]],\n",
      "\n",
      "       [[1517,    1],\n",
      "        [ 303,    1]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8098844566950973                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_None_84.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_None_84.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.24040920716112532, 'accuracy': 0.8369923161361141, 'auroc': 0.8098844566950973, 'kappa': 0.17948585759644342, 'matthews_cc': 0.22425232083419983, 'confusion_matrix': array([[[  47,  257],\n",
      "        [  40, 1478]],\n",
      "\n",
      "       [[1478,   40],\n",
      "        [ 257,   47]]], dtype=int64)}\n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "0.8098844566950973                                                                   \n",
      "model:                                                                               \n",
      "randomforest_entropy_None_84.csv                                                     \n",
      "{'predictioncsv': 'randomforest_entropy_None_84.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.24040920716112532, 'accuracy': 0.8369923161361141, 'auroc': 0.8098844566950973, 'kappa': 0.17948585759644342, 'matthews_cc': 0.22425232083419983, 'confusion_matrix': array([[[  47,  257],\n",
      "        [  40, 1478]],\n",
      "\n",
      "       [[1478,   40],\n",
      "        [ 257,   47]]], dtype=int64)}\n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "0.8098844566950973                                                                   \n",
      "model:                                                                               \n",
      "randomforest_entropy_None_84.csv                                                     \n",
      "{'predictioncsv': 'randomforest_entropy_None_84.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.24040920716112532, 'accuracy': 0.8369923161361141, 'auroc': 0.8098844566950973, 'kappa': 0.17948585759644342, 'matthews_cc': 0.22425232083419983, 'confusion_matrix': array([[[  47,  257],\n",
      "        [  40, 1478]],\n",
      "\n",
      "       [[1478,   40],\n",
      "        [ 257,   47]]], dtype=int64)}\n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "0.8098844566950973                                                                   \n",
      "model:                                                                               \n",
      "randomforest_entropy_None_84.csv                                                     \n",
      "{'predictioncsv': 'randomforest_entropy_None_84.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.24040920716112532, 'accuracy': 0.8369923161361141, 'auroc': 0.8098844566950973, 'kappa': 0.17948585759644342, 'matthews_cc': 0.22425232083419983, 'confusion_matrix': array([[[  47,  257],\n",
      "        [  40, 1478]],\n",
      "\n",
      "       [[1478,   40],\n",
      "        [ 257,   47]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.788127990430622                                                                     \n",
      "model:                                                                                \n",
      "randomforest_entropy_sqrt_20.csv                                                      \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_20.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.22857142857142856, 'accuracy': 0.8369923161361141, 'auroc': 0.788127990430622, 'kappa': 0.17032237489689106, 'matthews_cc': 0.2177321593370539, 'confusion_matrix': array([[[  44,  260],\n",
      "        [  37, 1481]],\n",
      "\n",
      "       [[1481,   37],\n",
      "        [ 260,   44]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "0.8046750398724083                                                                   \n",
      "model:                                                                               \n",
      "randomforest_gini_log2_84.csv                                                        \n",
      "{'predictioncsv': 'randomforest_gini_log2_84.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.11594202898550725, 'accuracy': 0.8326015367727772, 'auroc': 0.8046750398724083, 'kappa': 0.07943518061431731, 'matthews_cc': 0.13061112321312557, 'confusion_matrix': array([[[  20,  284],\n",
      "        [  21, 1497]],\n",
      "\n",
      "       [[1497,   21],\n",
      "        [ 284,   20]]], dtype=int64)}\n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "0.7994872928368353                                                                   \n",
      "model:                                                                               \n",
      "randomforest_entropy_None_36.csv                                                     \n",
      "{'predictioncsv': 'randomforest_entropy_None_36.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 1., 0.]), 'f1': 0.25, 'accuracy': 0.8287596048298573, 'auroc': 0.7994872928368353, 'kappa': 0.17596715836348453, 'matthews_cc': 0.20416454582956287, 'confusion_matrix': array([[[  52,  252],\n",
      "        [  60, 1458]],\n",
      "\n",
      "       [[1458,   60],\n",
      "        [ 252,   52]]], dtype=int64)}\n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "0.755785833159975                                                                    \n",
      "model:                                                                               \n",
      "naive_bayes.csv                                                                      \n",
      "{'predictioncsv': 'naive_bayes.csv', 'model_name': 'naive_bayes', 'y_pred': array([1., 0., 1., ..., 1., 1., 0.]), 'f1': 0.4318181818181818, 'accuracy': 0.6432491767288694, 'auroc': 0.755785833159975, 'kappa': 0.24741746565941036, 'matthews_cc': 0.31552944095924307, 'confusion_matrix': array([[[247,  57],\n",
      "        [593, 925]],\n",
      "\n",
      "       [[925, 593],\n",
      "        [ 57, 247]]], dtype=int64)}\n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "0.8139497087580612                                                                   \n",
      "model:                                                                               \n",
      "randomforest_entropy_None_148.csv                                                    \n",
      "{'predictioncsv': 'randomforest_entropy_None_148.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.2532299741602067, 'accuracy': 0.8413830954994511, 'auroc': 0.8139497087580612, 'kappa': 0.1956648590850072, 'matthews_cc': 0.24815926618260922, 'confusion_matrix': array([[[  49,  255],\n",
      "        [  34, 1484]],\n",
      "\n",
      "       [[1484,   34],\n",
      "        [ 255,   49]]], dtype=int64)}\n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "0.8139497087580612                                                                   \n",
      "model:                                                                               \n",
      "randomforest_entropy_None_148.csv                                                    \n",
      "{'predictioncsv': 'randomforest_entropy_None_148.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.2532299741602067, 'accuracy': 0.8413830954994511, 'auroc': 0.8139497087580612, 'kappa': 0.1956648590850072, 'matthews_cc': 0.24815926618260922, 'confusion_matrix': array([[[  49,  255],\n",
      "        [  34, 1484]],\n",
      "\n",
      "       [[1484,   34],\n",
      "        [ 255,   49]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.8066036509257332                                                                    \n",
      "model:                                                                                \n",
      "randomforest_gini_None_148.csv                                                        \n",
      "{'predictioncsv': 'randomforest_gini_None_148.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 1., 0.]), 'f1': 0.24806201550387597, 'accuracy': 0.8402854006586169, 'auroc': 0.8066036509257332, 'kappa': 0.19009852592988608, 'matthews_cc': 0.24109955623999432, 'confusion_matrix': array([[[  48,  256],\n",
      "        [  35, 1483]],\n",
      "\n",
      "       [[1483,   35],\n",
      "        [ 256,   48]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.755785833159975                                                                     \n",
      "model:                                                                                \n",
      "naive_bayes.csv                                                                       \n",
      "{'predictioncsv': 'naive_bayes.csv', 'model_name': 'naive_bayes', 'y_pred': array([1., 0., 1., ..., 1., 1., 0.]), 'f1': 0.4318181818181818, 'accuracy': 0.6432491767288694, 'auroc': 0.755785833159975, 'kappa': 0.24741746565941036, 'matthews_cc': 0.31552944095924307, 'confusion_matrix': array([[[247,  57],\n",
      "        [593, 925]],\n",
      "\n",
      "       [[925, 593],\n",
      "        [ 57, 247]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.7979801591429166                                                                    \n",
      "model:                                                                                \n",
      "logistic_regression_l2_sag.csv                                                        \n",
      "{'predictioncsv': 'logistic_regression_l2_sag.csv', 'model_name': 'logistic_regression', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.3937007874015748, 'accuracy': 0.8309549945115258, 'auroc': 0.7979801591429166, 'kappa': 0.29988122922759086, 'matthews_cc': 0.30794250217983793, 'confusion_matrix': array([[[ 100,  204],\n",
      "        [ 104, 1414]],\n",
      "\n",
      "       [[1414,  104],\n",
      "        [ 204,  100]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "0.8188958376672908                                                                   \n",
      "model:                                                                               \n",
      "randomforest_entropy_log2_148.csv                                                    \n",
      "{'predictioncsv': 'randomforest_entropy_log2_148.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.11143695014662756, 'accuracy': 0.8336992316136114, 'auroc': 0.8188958376672908, 'kappa': 0.0780553301069129, 'matthews_cc': 0.13386469799721376, 'confusion_matrix': array([[[  19,  285],\n",
      "        [  18, 1500]],\n",
      "\n",
      "       [[1500,   18],\n",
      "        [ 285,   19]]], dtype=int64)}\n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "0.815482846196519                                                                    \n",
      "model:                                                                               \n",
      "randomforest_entropy_log2_132.csv                                                    \n",
      "{'predictioncsv': 'randomforest_entropy_log2_132.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.13793103448275862, 'accuracy': 0.8353457738748628, 'auroc': 0.815482846196519, 'kappa': 0.09995652918472464, 'matthews_cc': 0.15974321447888246, 'confusion_matrix': array([[[  24,  280],\n",
      "        [  20, 1498]],\n",
      "\n",
      "       [[1498,   20],\n",
      "        [ 280,   24]]], dtype=int64)}\n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "0.5211995527355939                                                                   \n",
      "model:                                                                               \n",
      "decision_tree_entropy_sqrt_random.csv                                                \n",
      "{'predictioncsv': 'decision_tree_entropy_sqrt_random.csv', 'model_name': 'decision_tree', 'y_pred': array([0., 0., 1., ..., 1., 0., 1.]), 'f1': 0.31229235880398676, 'accuracy': 0.7727771679473107, 'auroc': 0.5211995527355939, 'kappa': 0.17621387851385883, 'matthews_cc': 0.17622643844636973, 'confusion_matrix': array([[[  94,  210],\n",
      "        [ 204, 1314]],\n",
      "\n",
      "       [[1314,  204],\n",
      "        [ 210,   94]]], dtype=int64)}\n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "0.7745442843769501                                                                   \n",
      "model:                                                                               \n",
      "SVC_100_0.0001_rbf.csv                                                               \n",
      "{'predictioncsv': 'SVC_100_0.0001_rbf.csv', 'model_name': 'SVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.10179640718562874, 'accuracy': 0.8353457738748628, 'auroc': 0.7745442843769501, 'kappa': 0.07404270313124661, 'matthews_cc': 0.13874860684694737, 'confusion_matrix': array([[[  17,  287],\n",
      "        [  13, 1505]],\n",
      "\n",
      "       [[1505,   13],\n",
      "        [ 287,   17]]], dtype=int64)}\n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                              \n",
      "0.7780298696345607                                                                   \n",
      "model:                                                                               \n",
      "AdaBoost_SAMME_1.0_30.csv                                                            \n",
      "{'predictioncsv': 'AdaBoost_SAMME_1.0_30.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.2819956616052061, 'accuracy': 0.818331503841932, 'auroc': 0.7780298696345607, 'kappa': 0.1899350692961319, 'matthews_cc': 0.20356451576953005, 'confusion_matrix': array([[[  65,  239],\n",
      "        [  92, 1426]],\n",
      "\n",
      "       [[1426,   92],\n",
      "        [ 239,   65]]], dtype=int64)}\n",
      "(1822,)                                                                              \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8090100807849665                                                                 \n",
      "model:                                                                             \n",
      "randomforest_gini_log2_132.csv                                                     \n",
      "{'predictioncsv': 'randomforest_gini_log2_132.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.12244897959183676, 'accuracy': 0.8347969264544457, 'auroc': 0.8090100807849665, 'kappa': 0.08783934374968805, 'matthews_cc': 0.1474083097012042, 'confusion_matrix': array([[[  21,  283],\n",
      "        [  18, 1500]],\n",
      "\n",
      "       [[1500,   18],\n",
      "        [ 283,   21]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.5369903266070314                                                                 \n",
      "model:                                                                             \n",
      "decision_tree_entropy_auto_best.csv                                                \n",
      "{'predictioncsv': 'decision_tree_entropy_auto_best.csv', 'model_name': 'decision_tree', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.33497536945812806, 'accuracy': 0.7777167947310648, 'auroc': 0.5369903266070314, 'kappa': 0.20153263835837598, 'matthews_cc': 0.20153303002895626, 'confusion_matrix': array([[[ 102,  202],\n",
      "        [ 203, 1315]],\n",
      "\n",
      "       [[1315,  203],\n",
      "        [ 202,  102]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.755785833159975                                                                  \n",
      "model:                                                                             \n",
      "naive_bayes.csv                                                                    \n",
      "{'predictioncsv': 'naive_bayes.csv', 'model_name': 'naive_bayes', 'y_pred': array([1., 0., 1., ..., 1., 1., 0.]), 'f1': 0.4318181818181818, 'accuracy': 0.6432491767288694, 'auroc': 0.755785833159975, 'kappa': 0.24741746565941036, 'matthews_cc': 0.31552944095924307, 'confusion_matrix': array([[[247,  57],\n",
      "        [593, 925]],\n",
      "\n",
      "       [[925, 593],\n",
      "        [ 57, 247]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7967189775327647                                                                 \n",
      "model:                                                                             \n",
      "logistic_regression_l2_newton-cg.csv                                               \n",
      "{'predictioncsv': 'logistic_regression_l2_newton-cg.csv', 'model_name': 'logistic_regression', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.3968871595330739, 'accuracy': 0.8298572996706916, 'auroc': 0.7967189775327647, 'kappa': 0.3016809507089271, 'matthews_cc': 0.3086805219421984, 'confusion_matrix': array([[[ 102,  202],\n",
      "        [ 108, 1410]],\n",
      "\n",
      "       [[1410,  108],\n",
      "        [ 202,  102]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7029061351501283                                                                 \n",
      "model:                                                                             \n",
      "LinSVC_1.0817674320733788.csv                                                      \n",
      "{'predictioncsv': 'LinSVC_1.0817674320733788.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 1., ..., 0., 0., 0.]), 'f1': 0.3800322061191626, 'accuracy': 0.7886937431394072, 'auroc': 0.7029061351501283, 'kappa': 0.2527425468134471, 'matthews_cc': 0.25282304045052867, 'confusion_matrix': array([[[ 118,  186],\n",
      "        [ 199, 1319]],\n",
      "\n",
      "       [[1319,  199],\n",
      "        [ 186,  118]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7191411396574441                                                                 \n",
      "model:                                                                             \n",
      "SVC_10_0.01_rbf.csv                                                                \n",
      "{'predictioncsv': 'SVC_10_0.01_rbf.csv', 'model_name': 'SVC', 'y_pred': array([0., 0., 1., ..., 0., 1., 0.]), 'f1': 0.35785288270377735, 'accuracy': 0.822722283205269, 'auroc': 0.7191411396574441, 'kappa': 0.2601819795493002, 'matthews_cc': 0.268049333433807, 'confusion_matrix': array([[[  90,  214],\n",
      "        [ 109, 1409]],\n",
      "\n",
      "       [[1409,  109],\n",
      "        [ 214,   90]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.5299909853685597                                                                 \n",
      "model:                                                                             \n",
      "AdaBoost_SAMME_10_63.csv                                                           \n",
      "{'predictioncsv': 'AdaBoost_SAMME_10_63.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.5299909853685597, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8115551972817417                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_log2_100.csv                                                  \n",
      "{'predictioncsv': 'randomforest_entropy_log2_100.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.12138728323699424, 'accuracy': 0.8331503841931943, 'auroc': 0.8115551972817417, 'kappa': 0.08429496293455174, 'matthews_cc': 0.13725578486212625, 'confusion_matrix': array([[[  21,  283],\n",
      "        [  21, 1497]],\n",
      "\n",
      "       [[1497,   21],\n",
      "        [ 283,   21]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8023823763955342                                                                 \n",
      "model:                                                                             \n",
      "knn_111.csv                                                                        \n",
      "{'predictioncsv': 'knn_111.csv', 'model_name': 'knn', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8309549945115258, 'auroc': 0.8023823763955342, 'kappa': -0.004352619446472916, 'matthews_cc': -0.020991040291566773, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   4, 1514]],\n",
      "\n",
      "       [[1514,    4],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.815482846196519                                                                  \n",
      "model:                                                                             \n",
      "randomforest_entropy_log2_132.csv                                                  \n",
      "{'predictioncsv': 'randomforest_entropy_log2_132.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.13793103448275862, 'accuracy': 0.8353457738748628, 'auroc': 0.815482846196519, 'kappa': 0.09995652918472464, 'matthews_cc': 0.15974321447888246, 'confusion_matrix': array([[[  24,  280],\n",
      "        [  20, 1498]],\n",
      "\n",
      "       [[1498,   20],\n",
      "        [ 280,   24]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.5211995527355939                                                                 \n",
      "model:                                                                             \n",
      "decision_tree_entropy_sqrt_random.csv                                              \n",
      "{'predictioncsv': 'decision_tree_entropy_sqrt_random.csv', 'model_name': 'decision_tree', 'y_pred': array([0., 0., 1., ..., 1., 0., 1.]), 'f1': 0.31229235880398676, 'accuracy': 0.7727771679473107, 'auroc': 0.5211995527355939, 'kappa': 0.17621387851385883, 'matthews_cc': 0.17622643844636973, 'confusion_matrix': array([[[  94,  210],\n",
      "        [ 204, 1314]],\n",
      "\n",
      "       [[1314,  204],\n",
      "        [ 210,   94]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.6901014579432772                                                                 \n",
      "model:                                                                             \n",
      "LinSVC_1.971270215556077.csv                                                       \n",
      "{'predictioncsv': 'LinSVC_1.971270215556077.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 1., ..., 0., 0., 0.]), 'f1': 0.37239165329052965, 'accuracy': 0.7854006586169044, 'auroc': 0.6901014579432772, 'kappa': 0.24305480293342008, 'matthews_cc': 0.24315734613239628, 'confusion_matrix': array([[[ 116,  188],\n",
      "        [ 203, 1315]],\n",
      "\n",
      "       [[1315,  203],\n",
      "        [ 188,  116]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7967189775327647                                                                 \n",
      "model:                                                                             \n",
      "logistic_regression_l2_newton-cg.csv                                               \n",
      "{'predictioncsv': 'logistic_regression_l2_newton-cg.csv', 'model_name': 'logistic_regression', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.3968871595330739, 'accuracy': 0.8298572996706916, 'auroc': 0.7967189775327647, 'kappa': 0.3016809507089271, 'matthews_cc': 0.3086805219421984, 'confusion_matrix': array([[[ 102,  202],\n",
      "        [ 108, 1410]],\n",
      "\n",
      "       [[1410,  108],\n",
      "        [ 202,  102]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.4260085118923792                                                                 \n",
      "model:                                                                             \n",
      "SVC_10_1_sigmoid.csv                                                               \n",
      "{'predictioncsv': 'SVC_10_1_sigmoid.csv', 'model_name': 'SVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.4260085118923792, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8035048713681436                                                                 \n",
      "model:                                                                             \n",
      "knn_71.csv                                                                         \n",
      "{'predictioncsv': 'knn_71.csv', 'model_name': 'knn', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0787878787878788, 'accuracy': 0.8331503841931943, 'auroc': 0.8035048713681436, 'kappa': 0.05391389900452992, 'matthews_cc': 0.10751016324795976, 'confusion_matrix': array([[[  13,  291],\n",
      "        [  13, 1505]],\n",
      "\n",
      "       [[1505,   13],\n",
      "        [ 291,   13]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7926678108314263                                                                 \n",
      "model:                                                                             \n",
      "AdaBoost_SAMME.R_0.1_85.csv                                                        \n",
      "{'predictioncsv': 'AdaBoost_SAMME.R_0.1_85.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.18282548476454297, 'accuracy': 0.8380900109769485, 'auroc': 0.7926678108314263, 'kappa': 0.13737429504113385, 'matthews_cc': 0.19862824900511253, 'confusion_matrix': array([[[  33,  271],\n",
      "        [  24, 1494]],\n",
      "\n",
      "       [[1494,   24],\n",
      "        [ 271,   33]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8178892760557519                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_log2_164.csv                                                  \n",
      "{'predictioncsv': 'randomforest_entropy_log2_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.10059171597633136, 'accuracy': 0.8331503841931943, 'auroc': 0.8178892760557519, 'kappa': 0.06935231297591937, 'matthews_cc': 0.12321730757576992, 'confusion_matrix': array([[[  17,  287],\n",
      "        [  17, 1501]],\n",
      "\n",
      "       [[1501,   17],\n",
      "        [ 287,   17]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.755785833159975                                                                  \n",
      "model:                                                                             \n",
      "naive_bayes.csv                                                                    \n",
      "{'predictioncsv': 'naive_bayes.csv', 'model_name': 'naive_bayes', 'y_pred': array([1., 0., 1., ..., 1., 1., 0.]), 'f1': 0.4318181818181818, 'accuracy': 0.6432491767288694, 'auroc': 0.755785833159975, 'kappa': 0.24741746565941036, 'matthews_cc': 0.31552944095924307, 'confusion_matrix': array([[[247,  57],\n",
      "        [593, 925]],\n",
      "\n",
      "       [[925, 593],\n",
      "        [ 57, 247]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8196293599611677                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_sqrt_164.csv                                                  \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.708665964565564                                                                  \n",
      "model:                                                                             \n",
      "LinSVC_0.8229535017145568.csv                                                      \n",
      "{'predictioncsv': 'LinSVC_0.8229535017145568.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.3846153846153846, 'accuracy': 0.7980241492864983, 'auroc': 0.708665964565564, 'kappa': 0.2638416168571943, 'matthews_cc': 0.26389442374332744, 'confusion_matrix': array([[[ 115,  189],\n",
      "        [ 179, 1339]],\n",
      "\n",
      "       [[1339,  179],\n",
      "        [ 189,  115]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.5152208584702864                                                                 \n",
      "model:                                                                             \n",
      "decision_tree_entropy_log2_random.csv                                              \n",
      "{'predictioncsv': 'decision_tree_entropy_log2_random.csv', 'model_name': 'decision_tree', 'y_pred': array([1., 0., 1., ..., 0., 0., 0.]), 'f1': 0.30333333333333334, 'accuracy': 0.7705817782656421, 'auroc': 0.5152208584702864, 'kappa': 0.16604323983390856, 'matthews_cc': 0.1660643936472369, 'confusion_matrix': array([[[  91,  213],\n",
      "        [ 205, 1313]],\n",
      "\n",
      "       [[1313,  205],\n",
      "        [ 213,   91]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8158414811732889                                                                 \n",
      "model:                                                                             \n",
      "randomforest_gini_sqrt_164.csv                                                     \n",
      "{'predictioncsv': 'randomforest_gini_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17094017094017092, 'accuracy': 0.8402854006586169, 'auroc': 0.8158414811732889, 'kappa': 0.13216225329243503, 'matthews_cc': 0.20575930263958453, 'confusion_matrix': array([[[  30,  274],\n",
      "        [  17, 1501]],\n",
      "\n",
      "       [[1501,   17],\n",
      "        [ 274,   30]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7964827768532002                                                                 \n",
      "model:                                                                             \n",
      "knn_41.csv                                                                         \n",
      "{'predictioncsv': 'knn_41.csv', 'model_name': 'knn', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.13256484149855907, 'accuracy': 0.8347969264544457, 'auroc': 0.7964827768532002, 'kappa': 0.09514758534211099, 'matthews_cc': 0.15346523710274507, 'confusion_matrix': array([[[  23,  281],\n",
      "        [  20, 1498]],\n",
      "\n",
      "       [[1498,   20],\n",
      "        [ 281,   23]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8189673479647736                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_sqrt_116.csv                                                  \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_116.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.18282548476454297, 'accuracy': 0.8380900109769485, 'auroc': 0.8189673479647736, 'kappa': 0.13737429504113385, 'matthews_cc': 0.19862824900511253, 'confusion_matrix': array([[[  33,  271],\n",
      "        [  24, 1494]],\n",
      "\n",
      "       [[1494,   24],\n",
      "        [ 271,   33]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8189673479647736                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_sqrt_116.csv                                                  \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_116.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.18282548476454297, 'accuracy': 0.8380900109769485, 'auroc': 0.8189673479647736, 'kappa': 0.13737429504113385, 'matthews_cc': 0.19862824900511253, 'confusion_matrix': array([[[  33,  271],\n",
      "        [  24, 1494]],\n",
      "\n",
      "       [[1494,   24],\n",
      "        [ 271,   33]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8189673479647736                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_sqrt_116.csv                                                  \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_116.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.18282548476454297, 'accuracy': 0.8380900109769485, 'auroc': 0.8189673479647736, 'kappa': 0.13737429504113385, 'matthews_cc': 0.19862824900511253, 'confusion_matrix': array([[[  33,  271],\n",
      "        [  24, 1494]],\n",
      "\n",
      "       [[1494,   24],\n",
      "        [ 271,   33]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8189673479647736                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_sqrt_116.csv                                                  \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_116.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.18282548476454297, 'accuracy': 0.8380900109769485, 'auroc': 0.8189673479647736, 'kappa': 0.13737429504113385, 'matthews_cc': 0.19862824900511253, 'confusion_matrix': array([[[  33,  271],\n",
      "        [  24, 1494]],\n",
      "\n",
      "       [[1494,   24],\n",
      "        [ 271,   33]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8117708116635463                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_sqrt_52.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_52.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.16574585635359115, 'accuracy': 0.8342480790340285, 'auroc': 0.8117708116635463, 'kappa': 0.11862245715201036, 'matthews_cc': 0.1704096915262207, 'confusion_matrix': array([[[  30,  274],\n",
      "        [  28, 1490]],\n",
      "\n",
      "       [[1490,   28],\n",
      "        [ 274,   30]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8135455672283476                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_sqrt_68.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_68.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.18181818181818182, 'accuracy': 0.8369923161361141, 'auroc': 0.8135455672283476, 'kappa': 0.13489706065731544, 'matthews_cc': 0.19256825094778848, 'confusion_matrix': array([[[  33,  271],\n",
      "        [  26, 1492]],\n",
      "\n",
      "       [[1492,   26],\n",
      "        [ 271,   33]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8189673479647736                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_sqrt_116.csv                                                  \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_116.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.18282548476454297, 'accuracy': 0.8380900109769485, 'auroc': 0.8189673479647736, 'kappa': 0.13737429504113385, 'matthews_cc': 0.19862824900511253, 'confusion_matrix': array([[[  33,  271],\n",
      "        [  24, 1494]],\n",
      "\n",
      "       [[1494,   24],\n",
      "        [ 271,   33]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7828936533527494                                                                 \n",
      "model:                                                                             \n",
      "logistic_regression_none_sag.csv                                                   \n",
      "{'predictioncsv': 'logistic_regression_none_sag.csv', 'model_name': 'logistic_regression', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.3926605504587156, 'accuracy': 0.818331503841932, 'auroc': 0.7828936533527494, 'kappa': 0.28752619727760953, 'matthews_cc': 0.29020691549962435, 'confusion_matrix': array([[[ 107,  197],\n",
      "        [ 134, 1384]],\n",
      "\n",
      "       [[1384,  134],\n",
      "        [ 197,  107]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7946029228208862                                                                 \n",
      "model:                                                                             \n",
      "SVC_0.1_0.1_rbf.csv                                                                \n",
      "{'predictioncsv': 'SVC_0.1_0.1_rbf.csv', 'model_name': 'SVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.7946029228208862, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8189673479647736                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_sqrt_116.csv                                                  \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_116.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.18282548476454297, 'accuracy': 0.8380900109769485, 'auroc': 0.8189673479647736, 'kappa': 0.13737429504113385, 'matthews_cc': 0.19862824900511253, 'confusion_matrix': array([[[  33,  271],\n",
      "        [  24, 1494]],\n",
      "\n",
      "       [[1494,   24],\n",
      "        [ 271,   33]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.746479743083004                                                                  \n",
      "model:                                                                             \n",
      "AdaBoost_SAMME.R_1.0_63.csv                                                        \n",
      "{'predictioncsv': 'AdaBoost_SAMME.R_1.0_63.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.3761638733705773, 'accuracy': 0.8161361141602634, 'auroc': 0.746479743083004, 'kappa': 0.27054675829100694, 'matthews_cc': 0.27383910910533565, 'confusion_matrix': array([[[ 101,  203],\n",
      "        [ 132, 1386]],\n",
      "\n",
      "       [[1386,  132],\n",
      "        [ 203,  101]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.755785833159975                                                                  \n",
      "model:                                                                             \n",
      "naive_bayes.csv                                                                    \n",
      "{'predictioncsv': 'naive_bayes.csv', 'model_name': 'naive_bayes', 'y_pred': array([1., 0., 1., ..., 1., 1., 0.]), 'f1': 0.4318181818181818, 'accuracy': 0.6432491767288694, 'auroc': 0.755785833159975, 'kappa': 0.24741746565941036, 'matthews_cc': 0.31552944095924307, 'confusion_matrix': array([[[247,  57],\n",
      "        [593, 925]],\n",
      "\n",
      "       [[925, 593],\n",
      "        [ 57, 247]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8196293599611677                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_sqrt_164.csv                                                  \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.6816675767977256                                                                 \n",
      "model:                                                                             \n",
      "LinSVC_2.9879060507864184.csv                                                      \n",
      "{'predictioncsv': 'LinSVC_2.9879060507864184.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 1., ..., 0., 0., 0.]), 'f1': 0.3525535420098847, 'accuracy': 0.7843029637760702, 'auroc': 0.6816675767977256, 'kappa': 0.22314994629663787, 'matthews_cc': 0.22315038226739833, 'confusion_matrix': array([[[ 107,  197],\n",
      "        [ 196, 1322]],\n",
      "\n",
      "       [[1322,  196],\n",
      "        [ 197,  107]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8158414811732889                                                                 \n",
      "model:                                                                             \n",
      "randomforest_gini_sqrt_164.csv                                                     \n",
      "{'predictioncsv': 'randomforest_gini_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17094017094017092, 'accuracy': 0.8402854006586169, 'auroc': 0.8158414811732889, 'kappa': 0.13216225329243503, 'matthews_cc': 0.20575930263958453, 'confusion_matrix': array([[[  30,  274],\n",
      "        [  17, 1501]],\n",
      "\n",
      "       [[1501,   17],\n",
      "        [ 274,   30]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8196293599611677                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_sqrt_164.csv                                                  \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.5447134387351779                                                                 \n",
      "model:                                                                             \n",
      "decision_tree_gini_auto_best.csv                                                   \n",
      "{'predictioncsv': 'decision_tree_gini_auto_best.csv', 'model_name': 'decision_tree', 'y_pred': array([0., 0., 0., ..., 1., 0., 0.]), 'f1': 0.3408071748878923, 'accuracy': 0.7579582875960483, 'auroc': 0.5447134387351779, 'kappa': 0.19407862402933618, 'matthews_cc': 0.1952958929571285, 'confusion_matrix': array([[[ 114,  190],\n",
      "        [ 251, 1267]],\n",
      "\n",
      "       [[1267,  251],\n",
      "        [ 190,  114]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7493748266417031                                                                 \n",
      "model:                                                                             \n",
      "logistic_regression_none_lbfgs.csv                                                 \n",
      "{'predictioncsv': 'logistic_regression_none_lbfgs.csv', 'model_name': 'logistic_regression', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.372093023255814, 'accuracy': 0.7925356750823271, 'auroc': 0.7493748266417031, 'kappa': 0.24784745429526245, 'matthews_cc': 0.24786512002809344, 'confusion_matrix': array([[[ 112,  192],\n",
      "        [ 186, 1332]],\n",
      "\n",
      "       [[1332,  186],\n",
      "        [ 192,  112]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7915843214756257                                                                 \n",
      "model:                                                                             \n",
      "knn_31.csv                                                                         \n",
      "{'predictioncsv': 'knn_31.csv', 'model_name': 'knn', 'y_pred': array([0., 0., 0., ..., 0., 1., 0.]), 'f1': 0.17728531855955676, 'accuracy': 0.8369923161361141, 'auroc': 0.7915843214756257, 'kappa': 0.13152598517700598, 'matthews_cc': 0.19017223074053674, 'confusion_matrix': array([[[  32,  272],\n",
      "        [  25, 1493]],\n",
      "\n",
      "       [[1493,   25],\n",
      "        [ 272,   32]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.4260085118923792                                                                 \n",
      "model:                                                                             \n",
      "SVC_1000_1_sigmoid.csv                                                             \n",
      "{'predictioncsv': 'SVC_1000_1_sigmoid.csv', 'model_name': 'SVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.4260085118923792, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.755785833159975                                                                  \n",
      "model:                                                                             \n",
      "naive_bayes.csv                                                                    \n",
      "{'predictioncsv': 'naive_bayes.csv', 'model_name': 'naive_bayes', 'y_pred': array([1., 0., 1., ..., 1., 1., 0.]), 'f1': 0.4318181818181818, 'accuracy': 0.6432491767288694, 'auroc': 0.755785833159975, 'kappa': 0.24741746565941036, 'matthews_cc': 0.31552944095924307, 'confusion_matrix': array([[[247,  57],\n",
      "        [593, 925]],\n",
      "\n",
      "       [[925, 593],\n",
      "        [ 57, 247]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8196293599611677                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_sqrt_164.csv                                                  \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.4978016000970806                                                                 \n",
      "model:                                                                             \n",
      "AdaBoost_SAMME_0.001_85.csv                                                        \n",
      "{'predictioncsv': 'AdaBoost_SAMME_0.001_85.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.4978016000970806, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8196293599611677                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_sqrt_164.csv                                                  \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.6842094428264337                                                                 \n",
      "model:                                                                             \n",
      "LinSVC_2.2773930400132265.csv                                                      \n",
      "{'predictioncsv': 'LinSVC_2.2773930400132265.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 1., ..., 0., 0., 0.]), 'f1': 0.3599374021909233, 'accuracy': 0.7755214050493963, 'auroc': 0.6842094428264337, 'kappa': 0.22421916804257436, 'matthews_cc': 0.224607788404437, 'confusion_matrix': array([[[ 115,  189],\n",
      "        [ 220, 1298]],\n",
      "\n",
      "       [[1298,  220],\n",
      "        [ 189,  115]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8196293599611677                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_sqrt_164.csv                                                  \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.5211995527355939                                                                 \n",
      "model:                                                                             \n",
      "decision_tree_entropy_sqrt_random.csv                                              \n",
      "{'predictioncsv': 'decision_tree_entropy_sqrt_random.csv', 'model_name': 'decision_tree', 'y_pred': array([0., 0., 1., ..., 1., 0., 1.]), 'f1': 0.31229235880398676, 'accuracy': 0.7727771679473107, 'auroc': 0.5211995527355939, 'kappa': 0.17621387851385883, 'matthews_cc': 0.17622643844636973, 'confusion_matrix': array([[[  94,  210],\n",
      "        [ 204, 1314]],\n",
      "\n",
      "       [[1314,  204],\n",
      "        [ 210,   94]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8004721846612579                                                                 \n",
      "model:                                                                             \n",
      "logistic_regression_l2_saga.csv                                                    \n",
      "{'predictioncsv': 'logistic_regression_l2_saga.csv', 'model_name': 'logistic_regression', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.391304347826087, 'accuracy': 0.8309549945115258, 'auroc': 0.8004721846612579, 'kappa': 0.29775401819010006, 'matthews_cc': 0.3061481165814115, 'confusion_matrix': array([[[  99,  205],\n",
      "        [ 103, 1415]],\n",
      "\n",
      "       [[1415,  103],\n",
      "        [ 205,   99]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8196293599611677                                                                 \n",
      "model:                                                                             \n",
      "randomforest_entropy_sqrt_164.csv                                                  \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.8036013019208098                                                                 \n",
      "model:                                                                             \n",
      "knn_51.csv                                                                         \n",
      "{'predictioncsv': 'knn_51.csv', 'model_name': 'knn', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.11695906432748537, 'accuracy': 0.8342480790340285, 'auroc': 0.8036013019208098, 'kappa': 0.08295723475884142, 'matthews_cc': 0.1407110154578351, 'confusion_matrix': array([[[  20,  284],\n",
      "        [  18, 1500]],\n",
      "\n",
      "       [[1500,   18],\n",
      "        [ 284,   20]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7338007506414257                                                                 \n",
      "model:                                                                             \n",
      "SVC_1_0.01_rbf.csv                                                                 \n",
      "{'predictioncsv': 'SVC_1_0.01_rbf.csv', 'model_name': 'SVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.11834319526627217, 'accuracy': 0.8364434687156971, 'auroc': 0.7338007506414257, 'kappa': 0.08772035943034207, 'matthews_cc': 0.15585156492673213, 'confusion_matrix': array([[[  20,  284],\n",
      "        [  14, 1504]],\n",
      "\n",
      "       [[1504,   14],\n",
      "        [ 284,   20]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.755785833159975                                                                  \n",
      "model:                                                                             \n",
      "naive_bayes.csv                                                                    \n",
      "{'predictioncsv': 'naive_bayes.csv', 'model_name': 'naive_bayes', 'y_pred': array([1., 0., 1., ..., 1., 1., 0.]), 'f1': 0.4318181818181818, 'accuracy': 0.6432491767288694, 'auroc': 0.755785833159975, 'kappa': 0.24741746565941036, 'matthews_cc': 0.31552944095924307, 'confusion_matrix': array([[[247,  57],\n",
      "        [593, 925]],\n",
      "\n",
      "       [[925, 593],\n",
      "        [ 57, 247]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7915149781568546                                                                 \n",
      "model:                                                                             \n",
      "AdaBoost_SAMME_0.1_74.csv                                                          \n",
      "{'predictioncsv': 'AdaBoost_SAMME_0.1_74.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.7915149781568546, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.803747572983843                                                                  \n",
      "model:                                                                             \n",
      "randomforest_entropy_sqrt_36.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_36.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.20163487738419617, 'accuracy': 0.8391877058177827, 'auroc': 0.803747572983843, 'kappa': 0.1531227691673146, 'matthews_cc': 0.21341721255169302, 'confusion_matrix': array([[[  37,  267],\n",
      "        [  26, 1492]],\n",
      "\n",
      "       [[1492,   26],\n",
      "        [ 267,   37]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.787372798349629                                                                  \n",
      "model:                                                                             \n",
      "randomforest_gini_sqrt_20.csv                                                      \n",
      "{'predictioncsv': 'randomforest_gini_sqrt_20.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17112299465240638, 'accuracy': 0.8298572996706916, 'auroc': 0.787372798349629, 'kappa': 0.11590500698109785, 'matthews_cc': 0.15563045557712452, 'confusion_matrix': array([[[  32,  272],\n",
      "        [  38, 1480]],\n",
      "\n",
      "       [[1480,   38],\n",
      "        [ 272,   32]]], dtype=int64)}\n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "(1822,)                                                                            \n",
      "0.7032831894459469                                                                 \n",
      "model:                                                                             \n",
      "LinSVC_1.2046932586206014.csv                                                      \n",
      "{'predictioncsv': 'LinSVC_1.2046932586206014.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.3884430176565008, 'accuracy': 0.7908891328210758, 'auroc': 0.7032831894459469, 'kappa': 0.2624140151346114, 'matthews_cc': 0.2625247258559933, 'confusion_matrix': array([[[ 121,  183],\n",
      "        [ 198, 1320]],\n",
      "\n",
      "       [[1320,  198],\n",
      "        [ 183,  121]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8117708116635463                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_52.csv                                                    \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_52.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.16574585635359115, 'accuracy': 0.8342480790340285, 'auroc': 0.8117708116635463, 'kappa': 0.11862245715201036, 'matthews_cc': 0.1704096915262207, 'confusion_matrix': array([[[  30,  274],\n",
      "        [  28, 1490]],\n",
      "\n",
      "       [[1490,   28],\n",
      "        [ 274,   30]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.49405597739407814                                                                 \n",
      "model:                                                                              \n",
      "decision_tree_gini_log2_best.csv                                                    \n",
      "{'predictioncsv': 'decision_tree_gini_log2_best.csv', 'model_name': 'decision_tree', 'y_pred': array([1., 0., 0., ..., 0., 0., 0.]), 'f1': 0.2728785357737105, 'accuracy': 0.7601536772777168, 'auroc': 0.49405597739407814, 'kappa': 0.129293583218692, 'matthews_cc': 0.12930616050765115, 'confusion_matrix': array([[[  82,  222],\n",
      "        [ 215, 1303]],\n",
      "\n",
      "       [[1303,  215],\n",
      "        [ 222,   82]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8177462554607864                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_100.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_100.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.1787709497206704, 'accuracy': 0.8386388583973655, 'auroc': 0.8177462554607864, 'kappa': 0.13524386385209952, 'matthews_cc': 0.199562500529825, 'confusion_matrix': array([[[  32,  272],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 272,   32]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.802949041328618                                                                   \n",
      "model:                                                                              \n",
      "knn_101.csv                                                                         \n",
      "{'predictioncsv': 'knn_101.csv', 'model_name': 'knn', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.019169329073482427, 'accuracy': 0.8315038419319429, 'auroc': 0.802949041328618, 'kappa': 0.009666899191592249, 'matthews_cc': 0.031460803681277294, 'confusion_matrix': array([[[   3,  301],\n",
      "        [   6, 1512]],\n",
      "\n",
      "       [[1512,    6],\n",
      "        [ 301,    3]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.7979801591429166                                                                  \n",
      "model:                                                                              \n",
      "logistic_regression_l2_sag.csv                                                      \n",
      "{'predictioncsv': 'logistic_regression_l2_sag.csv', 'model_name': 'logistic_regression', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.3937007874015748, 'accuracy': 0.8309549945115258, 'auroc': 0.7979801591429166, 'kappa': 0.29988122922759086, 'matthews_cc': 0.30794250217983793, 'confusion_matrix': array([[[ 100,  204],\n",
      "        [ 104, 1414]],\n",
      "\n",
      "       [[1414,  104],\n",
      "        [ 204,  100]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8135455672283476                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_68.csv                                                    \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_68.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.18181818181818182, 'accuracy': 0.8369923161361141, 'auroc': 0.8135455672283476, 'kappa': 0.13489706065731544, 'matthews_cc': 0.19256825094778848, 'confusion_matrix': array([[[  33,  271],\n",
      "        [  26, 1492]],\n",
      "\n",
      "       [[1492,   26],\n",
      "        [ 271,   33]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.6594300412592746                                                                  \n",
      "model:                                                                              \n",
      "AdaBoost_SAMME.R_10_30.csv                                                          \n",
      "{'predictioncsv': 'AdaBoost_SAMME.R_10_30.csv', 'model_name': 'AdaBoost', 'y_pred': array([1., 1., 1., ..., 1., 1., 1.]), 'f1': 0.28653569717297556, 'accuracy': 0.18276619099890232, 'auroc': 0.6594300412592746, 'kappa': 0.002020268903235145, 'matthews_cc': 0.015329213755945871, 'confusion_matrix': array([[[ 299,    5],\n",
      "        [1484,   34]],\n",
      "\n",
      "       [[  34, 1484],\n",
      "        [   5,  299]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.7765205689619304                                                                  \n",
      "model:                                                                              \n",
      "SVC_100_0.0001_sigmoid.csv                                                          \n",
      "{'predictioncsv': 'SVC_100_0.0001_sigmoid.csv', 'model_name': 'SVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.7765205689619304, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8154384231329311                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_None_164.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_None_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.25906735751295334, 'accuracy': 0.8430296377607025, 'auroc': 0.8154384231329311, 'kappa': 0.20253551992850105, 'matthews_cc': 0.25788140824766564, 'confusion_matrix': array([[[  50,  254],\n",
      "        [  32, 1486]],\n",
      "\n",
      "       [[1486,   32],\n",
      "        [ 254,   50]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.755785833159975                                                                     \n",
      "model:                                                                                \n",
      "naive_bayes.csv                                                                       \n",
      "{'predictioncsv': 'naive_bayes.csv', 'model_name': 'naive_bayes', 'y_pred': array([1., 0., 1., ..., 1., 1., 0.]), 'f1': 0.4318181818181818, 'accuracy': 0.6432491767288694, 'auroc': 0.755785833159975, 'kappa': 0.24741746565941036, 'matthews_cc': 0.31552944095924307, 'confusion_matrix': array([[[247,  57],\n",
      "        [593, 925]],\n",
      "\n",
      "       [[925, 593],\n",
      "        [ 57, 247]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.8158414811732889                                                                    \n",
      "model:                                                                                \n",
      "randomforest_gini_sqrt_164.csv                                                        \n",
      "{'predictioncsv': 'randomforest_gini_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17094017094017092, 'accuracy': 0.8402854006586169, 'auroc': 0.8158414811732889, 'kappa': 0.13216225329243503, 'matthews_cc': 0.20575930263958453, 'confusion_matrix': array([[[  30,  274],\n",
      "        [  17, 1501]],\n",
      "\n",
      "       [[1501,   17],\n",
      "        [ 274,   30]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.7427958792732821                                                                    \n",
      "model:                                                                                \n",
      "LinSVC_0.2856557843378438.csv                                                         \n",
      "{'predictioncsv': 'LinSVC_0.2856557843378438.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.3857142857142857, 'accuracy': 0.8111964873765093, 'auroc': 0.7427958792732821, 'kappa': 0.27513785574183036, 'matthews_cc': 0.27655607911215946, 'confusion_matrix': array([[[ 108,  196],\n",
      "        [ 148, 1370]],\n",
      "\n",
      "       [[1370,  148],\n",
      "        [ 196,  108]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.5211995527355939                                                                  \n",
      "model:                                                                              \n",
      "decision_tree_entropy_auto_random.csv                                               \n",
      "{'predictioncsv': 'decision_tree_entropy_auto_random.csv', 'model_name': 'decision_tree', 'y_pred': array([0., 0., 1., ..., 1., 0., 1.]), 'f1': 0.31229235880398676, 'accuracy': 0.7727771679473107, 'auroc': 0.5211995527355939, 'kappa': 0.17621387851385883, 'matthews_cc': 0.17622643844636973, 'confusion_matrix': array([[[  94,  210],\n",
      "        [ 204, 1314]],\n",
      "\n",
      "       [[1314,  204],\n",
      "        [ 210,   94]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8157428836419113                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_84.csv                                                    \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_84.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.1680672268907563, 'accuracy': 0.8369923161361141, 'auroc': 0.8157428836419113, 'kappa': 0.12470439803956457, 'matthews_cc': 0.18532214636421004, 'confusion_matrix': array([[[  30,  274],\n",
      "        [  23, 1495]],\n",
      "\n",
      "       [[1495,   23],\n",
      "        [ 274,   30]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.6240584477498092                                                                  \n",
      "model:                                                                              \n",
      "logistic_regression_none_newton-cg.csv                                              \n",
      "{'predictioncsv': 'logistic_regression_none_newton-cg.csv', 'model_name': 'logistic_regression', 'y_pred': array([0., 0., 1., ..., 0., 0., 0.]), 'f1': 0.39039039039039036, 'accuracy': 0.7771679473106476, 'auroc': 0.6240584477498092, 'kappa': 0.2553203483947347, 'matthews_cc': 0.2567774970762753, 'confusion_matrix': array([[[ 130,  174],\n",
      "        [ 232, 1286]],\n",
      "\n",
      "       [[1286,  232],\n",
      "        [ 174,  130]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.7926938145759654                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_None_20.csv                                                    \n",
      "{'predictioncsv': 'randomforest_entropy_None_20.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.22828784119106701, 'accuracy': 0.8293084522502744, 'auroc': 0.7926938145759654, 'kappa': 0.1593771603711166, 'matthews_cc': 0.19145678046497194, 'confusion_matrix': array([[[  46,  258],\n",
      "        [  53, 1465]],\n",
      "\n",
      "       [[1465,   53],\n",
      "        [ 258,   46]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.6101215241661465                                                                  \n",
      "model:                                                                              \n",
      "knn_1.csv                                                                           \n",
      "{'predictioncsv': 'knn_1.csv', 'model_name': 'knn', 'y_pred': array([0., 0., 1., ..., 0., 1., 0.]), 'f1': 0.35111876075731496, 'accuracy': 0.7930845225027442, 'auroc': 0.6101215241661465, 'kappa': 0.2283529139508812, 'matthews_cc': 0.22870242025063386, 'confusion_matrix': array([[[ 102,  202],\n",
      "        [ 175, 1343]],\n",
      "\n",
      "       [[1343,  175],\n",
      "        [ 202,  102]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.681838768115942                                                                   \n",
      "model:                                                                              \n",
      "SVC_1000_0.01_sigmoid.csv                                                           \n",
      "{'predictioncsv': 'SVC_1000_0.01_sigmoid.csv', 'model_name': 'SVC', 'y_pred': array([0., 0., 1., ..., 0., 1., 1.]), 'f1': 0.3064250411861615, 'accuracy': 0.7689352360043907, 'auroc': 0.681838768115942, 'kappa': 0.16780185086739063, 'matthews_cc': 0.16780217870390485, 'confusion_matrix': array([[[  93,  211],\n",
      "        [ 210, 1308]],\n",
      "\n",
      "       [[1308,  210],\n",
      "        [ 211,   93]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.755785833159975                                                                   \n",
      "model:                                                                              \n",
      "naive_bayes.csv                                                                     \n",
      "{'predictioncsv': 'naive_bayes.csv', 'model_name': 'naive_bayes', 'y_pred': array([1., 0., 1., ..., 1., 1., 0.]), 'f1': 0.4318181818181818, 'accuracy': 0.6432491767288694, 'auroc': 0.755785833159975, 'kappa': 0.24741746565941036, 'matthews_cc': 0.31552944095924307, 'confusion_matrix': array([[[247,  57],\n",
      "        [593, 925]],\n",
      "\n",
      "       [[925, 593],\n",
      "        [ 57, 247]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.4799727827473823                                                                  \n",
      "model:                                                                              \n",
      "AdaBoost_SAMME_0.001_96.csv                                                         \n",
      "{'predictioncsv': 'AdaBoost_SAMME_0.001_96.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.4799727827473823, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.803747572983843                                                                   \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_36.csv                                                    \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_36.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.20163487738419617, 'accuracy': 0.8391877058177827, 'auroc': 0.803747572983843, 'kappa': 0.1531227691673146, 'matthews_cc': 0.21341721255169302, 'confusion_matrix': array([[[  37,  267],\n",
      "        [  26, 1492]],\n",
      "\n",
      "       [[1492,   26],\n",
      "        [ 267,   37]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8067412540739199                                                                  \n",
      "model:                                                                              \n",
      "randomforest_gini_None_164.csv                                                      \n",
      "{'predictioncsv': 'randomforest_gini_None_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 1., 0.]), 'f1': 0.24935064935064932, 'accuracy': 0.8413830954994511, 'auroc': 0.8067412540739199, 'kappa': 0.19267059375488726, 'matthews_cc': 0.24630107726245445, 'confusion_matrix': array([[[  48,  256],\n",
      "        [  33, 1485]],\n",
      "\n",
      "       [[1485,   33],\n",
      "        [ 256,   48]]], dtype=int64)}\n",
      "(1822,)                                                                                \n",
      "(1822,)                                                                                \n",
      "(1822,)                                                                                \n",
      "0.691982395464947                                                                      \n",
      "model:                                                                                 \n",
      "LinSVC_1.7354775706205965.csv                                                          \n",
      "{'predictioncsv': 'LinSVC_1.7354775706205965.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.3890577507598784, 'accuracy': 0.7793633369923162, 'auroc': 0.691982395464947, 'kappa': 0.2553769453176149, 'matthews_cc': 0.2564792901418284, 'confusion_matrix': array([[[ 128,  176],\n",
      "        [ 226, 1292]],\n",
      "\n",
      "       [[1292,  226],\n",
      "        [ 176,  128]]], dtype=int64)}\n",
      "(1822,)                                                                                \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.5447134387351779                                                                    \n",
      "model:                                                                                \n",
      "decision_tree_gini_sqrt_best.csv                                                      \n",
      "{'predictioncsv': 'decision_tree_gini_sqrt_best.csv', 'model_name': 'decision_tree', 'y_pred': array([0., 0., 0., ..., 1., 0., 0.]), 'f1': 0.3408071748878923, 'accuracy': 0.7579582875960483, 'auroc': 0.5447134387351779, 'kappa': 0.19407862402933618, 'matthews_cc': 0.1952958929571285, 'confusion_matrix': array([[[ 114,  190],\n",
      "        [ 251, 1267]],\n",
      "\n",
      "       [[1267,  251],\n",
      "        [ 190,  114]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.8196293599611677                                                                    \n",
      "model:                                                                                \n",
      "randomforest_entropy_sqrt_164.csv                                                     \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.7763309583246655                                                                  \n",
      "model:                                                                              \n",
      "knn_21.csv                                                                          \n",
      "{'predictioncsv': 'knn_21.csv', 'model_name': 'knn', 'y_pred': array([0., 0., 0., ..., 0., 1., 0.]), 'f1': 0.20833333333333334, 'accuracy': 0.8331503841931943, 'auroc': 0.7763309583246655, 'kappa': 0.14918403460479734, 'matthews_cc': 0.1914859578908568, 'confusion_matrix': array([[[  40,  264],\n",
      "        [  40, 1478]],\n",
      "\n",
      "       [[1478,   40],\n",
      "        [ 264,   40]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.7493748266417031                                                                  \n",
      "model:                                                                              \n",
      "logistic_regression_none_lbfgs.csv                                                  \n",
      "{'predictioncsv': 'logistic_regression_none_lbfgs.csv', 'model_name': 'logistic_regression', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.372093023255814, 'accuracy': 0.7925356750823271, 'auroc': 0.7493748266417031, 'kappa': 0.24784745429526245, 'matthews_cc': 0.24786512002809344, 'confusion_matrix': array([[[ 112,  192],\n",
      "        [ 186, 1332]],\n",
      "\n",
      "       [[1332,  186],\n",
      "        [ 192,  112]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8097110983981695                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_log2_84.csv                                                    \n",
      "{'predictioncsv': 'randomforest_entropy_log2_84.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.13753581661891118, 'accuracy': 0.8347969264544457, 'auroc': 0.8097110983981695, 'kappa': 0.0987579660749558, 'matthews_cc': 0.1564202307467742, 'confusion_matrix': array([[[  24,  280],\n",
      "        [  21, 1497]],\n",
      "\n",
      "       [[1497,   21],\n",
      "        [ 280,   24]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.7930426981485333                                                                  \n",
      "model:                                                                              \n",
      "SVC_10_0.1_rbf.csv                                                                  \n",
      "{'predictioncsv': 'SVC_10_0.1_rbf.csv', 'model_name': 'SVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.025806451612903226, 'accuracy': 0.8342480790340285, 'auroc': 0.7930426981485333, 'kappa': 0.019473530397097538, 'matthews_cc': 0.07705564601409587, 'confusion_matrix': array([[[   4,  300],\n",
      "        [   2, 1516]],\n",
      "\n",
      "       [[1516,    2],\n",
      "        [ 300,    4]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.755785833159975                                                                   \n",
      "model:                                                                              \n",
      "naive_bayes.csv                                                                     \n",
      "{'predictioncsv': 'naive_bayes.csv', 'model_name': 'naive_bayes', 'y_pred': array([1., 0., 1., ..., 1., 1., 0.]), 'f1': 0.4318181818181818, 'accuracy': 0.6432491767288694, 'auroc': 0.755785833159975, 'kappa': 0.24741746565941036, 'matthews_cc': 0.31552944095924307, 'confusion_matrix': array([[[247,  57],\n",
      "        [593, 925]],\n",
      "\n",
      "       [[925, 593],\n",
      "        [ 57, 247]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8177462554607864                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_100.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_100.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.1787709497206704, 'accuracy': 0.8386388583973655, 'auroc': 0.8177462554607864, 'kappa': 0.13524386385209952, 'matthews_cc': 0.199562500529825, 'confusion_matrix': array([[[  32,  272],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 272,   32]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.7387696328271272                                                                  \n",
      "model:                                                                              \n",
      "AdaBoost_SAMME.R_1.0_52.csv                                                         \n",
      "{'predictioncsv': 'AdaBoost_SAMME.R_1.0_52.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.37847866419294995, 'accuracy': 0.8161361141602634, 'auroc': 0.7387696328271272, 'kappa': 0.2726572908250693, 'matthews_cc': 0.27576944000792, 'confusion_matrix': array([[[ 102,  202],\n",
      "        [ 133, 1385]],\n",
      "\n",
      "       [[1385,  133],\n",
      "        [ 202,  102]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8154384231329311                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_None_164.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_None_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.25906735751295334, 'accuracy': 0.8430296377607025, 'auroc': 0.8154384231329311, 'kappa': 0.20253551992850105, 'matthews_cc': 0.25788140824766564, 'confusion_matrix': array([[[  50,  254],\n",
      "        [  32, 1486]],\n",
      "\n",
      "       [[1486,   32],\n",
      "        [ 254,   50]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.6899519364121767                                                                    \n",
      "model:                                                                                \n",
      "LinSVC_2.621408563528484.csv                                                          \n",
      "{'predictioncsv': 'LinSVC_2.621408563528484.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.3741935483870968, 'accuracy': 0.7870472008781558, 'auroc': 0.6899519364121767, 'kappa': 0.2459445852426423, 'matthews_cc': 0.2460114950893326, 'confusion_matrix': array([[[ 116,  188],\n",
      "        [ 200, 1318]],\n",
      "\n",
      "       [[1318,  200],\n",
      "        [ 188,  116]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.5211995527355939                                                                    \n",
      "model:                                                                                \n",
      "decision_tree_entropy_sqrt_random.csv                                                 \n",
      "{'predictioncsv': 'decision_tree_entropy_sqrt_random.csv', 'model_name': 'decision_tree', 'y_pred': array([0., 0., 1., ..., 1., 0., 1.]), 'f1': 0.31229235880398676, 'accuracy': 0.7727771679473107, 'auroc': 0.5211995527355939, 'kappa': 0.17621387851385883, 'matthews_cc': 0.17622643844636973, 'confusion_matrix': array([[[  94,  210],\n",
      "        [ 204, 1314]],\n",
      "\n",
      "       [[1314,  204],\n",
      "        [ 210,   94]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8158696518965397                                                                  \n",
      "model:                                                                              \n",
      "randomforest_gini_sqrt_148.csv                                                      \n",
      "{'predictioncsv': 'randomforest_gini_sqrt_148.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.16477272727272727, 'accuracy': 0.8386388583973655, 'auroc': 0.8158696518965397, 'kappa': 0.12495426032409818, 'matthews_cc': 0.1929371756285523, 'confusion_matrix': array([[[  29,  275],\n",
      "        [  19, 1499]],\n",
      "\n",
      "       [[1499,   19],\n",
      "        [ 275,   29]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8033260956244366                                                                  \n",
      "model:                                                                              \n",
      "knn_61.csv                                                                          \n",
      "{'predictioncsv': 'knn_61.csv', 'model_name': 'knn', 'y_pred': array([0., 0., 0., ..., 0., 1., 0.]), 'f1': 0.10029498525073746, 'accuracy': 0.8326015367727772, 'auroc': 0.8033260956244366, 'kappa': 0.06819165026208207, 'matthews_cc': 0.11968889106850732, 'confusion_matrix': array([[[  17,  287],\n",
      "        [  18, 1500]],\n",
      "\n",
      "       [[1500,   18],\n",
      "        [ 287,   17]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8004721846612579                                                                  \n",
      "model:                                                                              \n",
      "logistic_regression_l2_saga.csv                                                     \n",
      "{'predictioncsv': 'logistic_regression_l2_saga.csv', 'model_name': 'logistic_regression', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.391304347826087, 'accuracy': 0.8309549945115258, 'auroc': 0.8004721846612579, 'kappa': 0.29775401819010006, 'matthews_cc': 0.3061481165814115, 'confusion_matrix': array([[[  99,  205],\n",
      "        [ 103, 1415]],\n",
      "\n",
      "       [[1415,  103],\n",
      "        [ 205,   99]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.815482846196519                                                                   \n",
      "model:                                                                              \n",
      "randomforest_entropy_log2_132.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_log2_132.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.13793103448275862, 'accuracy': 0.8353457738748628, 'auroc': 0.815482846196519, 'kappa': 0.09995652918472464, 'matthews_cc': 0.15974321447888246, 'confusion_matrix': array([[[  24,  280],\n",
      "        [  20, 1498]],\n",
      "\n",
      "       [[1498,   20],\n",
      "        [ 280,   24]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.7824180015255531                                                                  \n",
      "model:                                                                              \n",
      "SVC_1_0.001_sigmoid.csv                                                             \n",
      "{'predictioncsv': 'SVC_1_0.001_sigmoid.csv', 'model_name': 'SVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.7824180015255531, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8135455672283476                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_68.csv                                                    \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_68.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.18181818181818182, 'accuracy': 0.8369923161361141, 'auroc': 0.8135455672283476, 'kappa': 0.13489706065731544, 'matthews_cc': 0.19256825094778848, 'confusion_matrix': array([[[  33,  271],\n",
      "        [  26, 1492]],\n",
      "\n",
      "       [[1492,   26],\n",
      "        [ 271,   33]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.7926678108314263                                                                  \n",
      "model:                                                                              \n",
      "AdaBoost_SAMME.R_0.1_85.csv                                                         \n",
      "{'predictioncsv': 'AdaBoost_SAMME.R_0.1_85.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.18282548476454297, 'accuracy': 0.8380900109769485, 'auroc': 0.7926678108314263, 'kappa': 0.13737429504113385, 'matthews_cc': 0.19862824900511253, 'confusion_matrix': array([[[  33,  271],\n",
      "        [  24, 1494]],\n",
      "\n",
      "       [[1494,   24],\n",
      "        [ 271,   33]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.755785833159975                                                                   \n",
      "model:                                                                              \n",
      "naive_bayes.csv                                                                     \n",
      "{'predictioncsv': 'naive_bayes.csv', 'model_name': 'naive_bayes', 'y_pred': array([1., 0., 1., ..., 1., 1., 0.]), 'f1': 0.4318181818181818, 'accuracy': 0.6432491767288694, 'auroc': 0.755785833159975, 'kappa': 0.24741746565941036, 'matthews_cc': 0.31552944095924307, 'confusion_matrix': array([[[247,  57],\n",
      "        [593, 925]],\n",
      "\n",
      "       [[925, 593],\n",
      "        [ 57, 247]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8117708116635463                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_52.csv                                                    \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_52.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.16574585635359115, 'accuracy': 0.8342480790340285, 'auroc': 0.8117708116635463, 'kappa': 0.11862245715201036, 'matthews_cc': 0.1704096915262207, 'confusion_matrix': array([[[  30,  274],\n",
      "        [  28, 1490]],\n",
      "\n",
      "       [[1490,   28],\n",
      "        [ 274,   30]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.7167401272449899                                                                  \n",
      "model:                                                                              \n",
      "LinSVC_0.6611964147694476.csv                                                       \n",
      "{'predictioncsv': 'LinSVC_0.6611964147694476.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.3844856661045531, 'accuracy': 0.7996706915477497, 'auroc': 0.7167401272449899, 'kappa': 0.2649441714360242, 'matthews_cc': 0.26506513627799794, 'confusion_matrix': array([[[ 114,  190],\n",
      "        [ 175, 1343]],\n",
      "\n",
      "       [[1343,  175],\n",
      "        [ 190,  114]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8196293599611677                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_164.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8196293599611677                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_164.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8196293599611677                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_164.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8196293599611677                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_164.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8196293599611677                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_164.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8196293599611677                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_164.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.7750329380764163                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_log2_20.csv                                                    \n",
      "{'predictioncsv': 'randomforest_entropy_log2_20.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.15217391304347827, 'accuracy': 0.8287596048298573, 'auroc': 0.7750329380764163, 'kappa': 0.09993920048639615, 'matthews_cc': 0.1385048223535808, 'confusion_matrix': array([[[  28,  276],\n",
      "        [  36, 1482]],\n",
      "\n",
      "       [[1482,   36],\n",
      "        [ 276,   28]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.803747572983843                                                                   \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_36.csv                                                    \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_36.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.20163487738419617, 'accuracy': 0.8391877058177827, 'auroc': 0.803747572983843, 'kappa': 0.1531227691673146, 'matthews_cc': 0.21341721255169302, 'confusion_matrix': array([[[  37,  267],\n",
      "        [  26, 1492]],\n",
      "\n",
      "       [[1492,   26],\n",
      "        [ 267,   37]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8190713629429305                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_148.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_148.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.16338028169014085, 'accuracy': 0.8369923161361141, 'auroc': 0.8190713629429305, 'kappa': 0.12125325997642089, 'matthews_cc': 0.18286789970506295, 'confusion_matrix': array([[[  29,  275],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 275,   29]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8196293599611677                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_164.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8062406819915401                                                                  \n",
      "model:                                                                              \n",
      "randomforest_gini_None_132.csv                                                      \n",
      "{'predictioncsv': 'randomforest_gini_None_132.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 1., 0.]), 'f1': 0.26424870466321243, 'accuracy': 0.8441273326015367, 'auroc': 0.8062406819915401, 'kappa': 0.20811219461431574, 'matthews_cc': 0.2649819934774796, 'confusion_matrix': array([[[  51,  253],\n",
      "        [  31, 1487]],\n",
      "\n",
      "       [[1487,   31],\n",
      "        [ 253,   51]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.5447134387351779                                                                  \n",
      "model:                                                                              \n",
      "decision_tree_gini_auto_best.csv                                                    \n",
      "{'predictioncsv': 'decision_tree_gini_auto_best.csv', 'model_name': 'decision_tree', 'y_pred': array([0., 0., 0., ..., 1., 0., 0.]), 'f1': 0.3408071748878923, 'accuracy': 0.7579582875960483, 'auroc': 0.5447134387351779, 'kappa': 0.19407862402933618, 'matthews_cc': 0.1952958929571285, 'confusion_matrix': array([[[ 114,  190],\n",
      "        [ 251, 1267]],\n",
      "\n",
      "       [[1267,  251],\n",
      "        [ 190,  114]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8027648481381319                                                                  \n",
      "model:                                                                              \n",
      "knn_91.csv                                                                          \n",
      "{'predictioncsv': 'knn_91.csv', 'model_name': 'knn', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.031249999999999993, 'accuracy': 0.8298572996706916, 'auroc': 0.8027648481381319, 'kappa': 0.014812179057825281, 'matthews_cc': 0.036769561268232005, 'confusion_matrix': array([[[   5,  299],\n",
      "        [  11, 1507]],\n",
      "\n",
      "       [[1507,   11],\n",
      "        [ 299,    5]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.7979801591429166                                                                  \n",
      "model:                                                                              \n",
      "logistic_regression_l2_sag.csv                                                      \n",
      "{'predictioncsv': 'logistic_regression_l2_sag.csv', 'model_name': 'logistic_regression', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.3937007874015748, 'accuracy': 0.8309549945115258, 'auroc': 0.7979801591429166, 'kappa': 0.29988122922759086, 'matthews_cc': 0.30794250217983793, 'confusion_matrix': array([[[ 100,  204],\n",
      "        [ 104, 1414]],\n",
      "\n",
      "       [[1414,  104],\n",
      "        [ 204,  100]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.737140064836003                                                                   \n",
      "model:                                                                              \n",
      "SVC_0.1_0.0001_rbf.csv                                                              \n",
      "{'predictioncsv': 'SVC_0.1_0.0001_rbf.csv', 'model_name': 'SVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.737140064836003, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8196293599611677                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_164.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8115551972817417                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_log2_100.csv                                                   \n",
      "{'predictioncsv': 'randomforest_entropy_log2_100.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.12138728323699424, 'accuracy': 0.8331503841931943, 'auroc': 0.8115551972817417, 'kappa': 0.08429496293455174, 'matthews_cc': 0.13725578486212625, 'confusion_matrix': array([[[  21,  283],\n",
      "        [  21, 1497]],\n",
      "\n",
      "       [[1497,   21],\n",
      "        [ 283,   21]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.755785833159975                                                                   \n",
      "model:                                                                              \n",
      "naive_bayes.csv                                                                     \n",
      "{'predictioncsv': 'naive_bayes.csv', 'model_name': 'naive_bayes', 'y_pred': array([1., 0., 1., ..., 1., 1., 0.]), 'f1': 0.4318181818181818, 'accuracy': 0.6432491767288694, 'auroc': 0.755785833159975, 'kappa': 0.24741746565941036, 'matthews_cc': 0.31552944095924307, 'confusion_matrix': array([[[247,  57],\n",
      "        [593, 925]],\n",
      "\n",
      "       [[925, 593],\n",
      "        [ 57, 247]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.5299909853685597                                                                  \n",
      "model:                                                                              \n",
      "AdaBoost_SAMME_10_30.csv                                                            \n",
      "{'predictioncsv': 'AdaBoost_SAMME_10_30.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.5299909853685597, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.8157428836419113                                                                  \n",
      "model:                                                                              \n",
      "randomforest_entropy_sqrt_84.csv                                                    \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_84.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.1680672268907563, 'accuracy': 0.8369923161361141, 'auroc': 0.8157428836419113, 'kappa': 0.12470439803956457, 'matthews_cc': 0.18532214636421004, 'confusion_matrix': array([[[  30,  274],\n",
      "        [  23, 1495]],\n",
      "\n",
      "       [[1495,   23],\n",
      "        [ 274,   30]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.6868314870674711                                                                  \n",
      "model:                                                                              \n",
      "LinSVC_1.908674724773784.csv                                                        \n",
      "{'predictioncsv': 'LinSVC_1.908674724773784.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.37133550488599354, 'accuracy': 0.7881448957189902, 'auroc': 0.6868314870674711, 'kappa': 0.2439573953912374, 'matthews_cc': 0.24397424343223395, 'confusion_matrix': array([[[ 114,  190],\n",
      "        [ 196, 1322]],\n",
      "\n",
      "       [[1322,  196],\n",
      "        [ 190,  114]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                             \n",
      "0.49405597739407814                                                                 \n",
      "model:                                                                              \n",
      "decision_tree_gini_log2_best.csv                                                    \n",
      "{'predictioncsv': 'decision_tree_gini_log2_best.csv', 'model_name': 'decision_tree', 'y_pred': array([1., 0., 0., ..., 0., 0., 0.]), 'f1': 0.2728785357737105, 'accuracy': 0.7601536772777168, 'auroc': 0.49405597739407814, 'kappa': 0.129293583218692, 'matthews_cc': 0.12930616050765115, 'confusion_matrix': array([[[  82,  222],\n",
      "        [ 215, 1303]],\n",
      "\n",
      "       [[1303,  215],\n",
      "        [ 222,   82]]], dtype=int64)}\n",
      "(1822,)                                                                             \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.8196293599611677                                                                    \n",
      "model:                                                                                \n",
      "randomforest_entropy_sqrt_164.csv                                                     \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.8117708116635463                                                                    \n",
      "model:                                                                                \n",
      "randomforest_entropy_sqrt_52.csv                                                      \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_52.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.16574585635359115, 'accuracy': 0.8342480790340285, 'auroc': 0.8117708116635463, 'kappa': 0.11862245715201036, 'matthews_cc': 0.1704096915262207, 'confusion_matrix': array([[[  30,  274],\n",
      "        [  28, 1490]],\n",
      "\n",
      "       [[1490,   28],\n",
      "        [ 274,   30]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.8000301210040912                                                                    \n",
      "model:                                                                                \n",
      "knn_81.csv                                                                            \n",
      "{'predictioncsv': 'knn_81.csv', 'model_name': 'knn', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.037267080745341616, 'accuracy': 0.8298572996706916, 'auroc': 0.8000301210040912, 'kappa': 0.01896689477889324, 'matthews_cc': 0.044603141277682674, 'confusion_matrix': array([[[   6,  298],\n",
      "        [  12, 1506]],\n",
      "\n",
      "       [[1506,   12],\n",
      "        [ 298,    6]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.7925930500658761                                                                    \n",
      "model:                                                                                \n",
      "logistic_regression_none_saga.csv                                                     \n",
      "{'predictioncsv': 'logistic_regression_none_saga.csv', 'model_name': 'logistic_regression', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.40377358490566045, 'accuracy': 0.8265642151481888, 'auroc': 0.7925930500658761, 'kappa': 0.30485890767544177, 'matthews_cc': 0.30944826077596155, 'confusion_matrix': array([[[ 107,  197],\n",
      "        [ 119, 1399]],\n",
      "\n",
      "       [[1399,  119],\n",
      "        [ 197,  107]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.4260085118923792                                                                    \n",
      "model:                                                                                \n",
      "SVC_100_1_sigmoid.csv                                                                 \n",
      "{'predictioncsv': 'SVC_100_1_sigmoid.csv', 'model_name': 'SVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.4260085118923792, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.8097620223978919                                                                    \n",
      "model:                                                                                \n",
      "randomforest_gini_sqrt_68.csv                                                         \n",
      "{'predictioncsv': 'randomforest_gini_sqrt_68.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.1899441340782123, 'accuracy': 0.8408342480790341, 'auroc': 0.8097620223978919, 'kappa': 0.14700925345955396, 'matthews_cc': 0.21692321844260867, 'confusion_matrix': array([[[  34,  270],\n",
      "        [  20, 1498]],\n",
      "\n",
      "       [[1498,   20],\n",
      "        [ 270,   34]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.755785833159975                                                                     \n",
      "model:                                                                                \n",
      "naive_bayes.csv                                                                       \n",
      "{'predictioncsv': 'naive_bayes.csv', 'model_name': 'naive_bayes', 'y_pred': array([1., 0., 1., ..., 1., 1., 0.]), 'f1': 0.4318181818181818, 'accuracy': 0.6432491767288694, 'auroc': 0.755785833159975, 'kappa': 0.24741746565941036, 'matthews_cc': 0.31552944095924307, 'confusion_matrix': array([[[247,  57],\n",
      "        [593, 925]],\n",
      "\n",
      "       [[925, 593],\n",
      "        [ 57, 247]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.7847149989598502                                                                    \n",
      "model:                                                                                \n",
      "AdaBoost_SAMME_0.1_41.csv                                                             \n",
      "{'predictioncsv': 'AdaBoost_SAMME_0.1_41.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.7847149989598502, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.8196293599611677                                                                    \n",
      "model:                                                                                \n",
      "randomforest_entropy_sqrt_164.csv                                                     \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.5211995527355939                                                                    \n",
      "model:                                                                                \n",
      "decision_tree_entropy_sqrt_random.csv                                                 \n",
      "{'predictioncsv': 'decision_tree_entropy_sqrt_random.csv', 'model_name': 'decision_tree', 'y_pred': array([0., 0., 1., ..., 1., 0., 1.]), 'f1': 0.31229235880398676, 'accuracy': 0.7727771679473107, 'auroc': 0.5211995527355939, 'kappa': 0.17621387851385883, 'matthews_cc': 0.17622643844636973, 'confusion_matrix': array([[[  94,  210],\n",
      "        [ 204, 1314]],\n",
      "\n",
      "       [[1314,  204],\n",
      "        [ 210,   94]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.6947842989390471                                                                    \n",
      "model:                                                                                \n",
      "LinSVC_1.2981107404048402.csv                                                         \n",
      "{'predictioncsv': 'LinSVC_1.2981107404048402.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 1., ..., 0., 0., 0.]), 'f1': 0.3786407766990291, 'accuracy': 0.7892425905598244, 'auroc': 0.6947842989390471, 'kappa': 0.2517805886957749, 'matthews_cc': 0.25182839789033884, 'confusion_matrix': array([[[ 117,  187],\n",
      "        [ 197, 1321]],\n",
      "\n",
      "       [[1321,  197],\n",
      "        [ 187,  117]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.8154384231329311                                                                    \n",
      "model:                                                                                \n",
      "randomforest_entropy_None_164.csv                                                     \n",
      "{'predictioncsv': 'randomforest_entropy_None_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.25906735751295334, 'accuracy': 0.8430296377607025, 'auroc': 0.8154384231329311, 'kappa': 0.20253551992850105, 'matthews_cc': 0.25788140824766564, 'confusion_matrix': array([[[  50,  254],\n",
      "        [  32, 1486]],\n",
      "\n",
      "       [[1486,   32],\n",
      "        [ 254,   50]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.788127990430622                                                                     \n",
      "model:                                                                                \n",
      "randomforest_entropy_sqrt_20.csv                                                      \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_20.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.22857142857142856, 'accuracy': 0.8369923161361141, 'auroc': 0.788127990430622, 'kappa': 0.17032237489689106, 'matthews_cc': 0.2177321593370539, 'confusion_matrix': array([[[  44,  260],\n",
      "        [  37, 1481]],\n",
      "\n",
      "       [[1481,   37],\n",
      "        [ 260,   44]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.8029663771583108                                                                    \n",
      "model:                                                                                \n",
      "knn_141.csv                                                                           \n",
      "{'predictioncsv': 'knn_141.csv', 'model_name': 'knn', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.006557377049180327, 'accuracy': 0.8336992316136114, 'auroc': 0.8029663771583108, 'kappa': 0.005469265108034027, 'matthews_cc': 0.05236536331842251, 'confusion_matrix': array([[[   1,  303],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 303,    1]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.7967189775327647                                                                    \n",
      "model:                                                                                \n",
      "logistic_regression_l2_newton-cg.csv                                                  \n",
      "{'predictioncsv': 'logistic_regression_l2_newton-cg.csv', 'model_name': 'logistic_regression', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.3968871595330739, 'accuracy': 0.8298572996706916, 'auroc': 0.7967189775327647, 'kappa': 0.3016809507089271, 'matthews_cc': 0.3086805219421984, 'confusion_matrix': array([[[ 102,  202],\n",
      "        [ 108, 1410]],\n",
      "\n",
      "       [[1410,  108],\n",
      "        [ 202,  102]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.8178892760557519                                                                    \n",
      "model:                                                                                \n",
      "randomforest_entropy_log2_164.csv                                                     \n",
      "{'predictioncsv': 'randomforest_entropy_log2_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.10059171597633136, 'accuracy': 0.8331503841931943, 'auroc': 0.8178892760557519, 'kappa': 0.06935231297591937, 'matthews_cc': 0.12321730757576992, 'confusion_matrix': array([[[  17,  287],\n",
      "        [  17, 1501]],\n",
      "\n",
      "       [[1501,   17],\n",
      "        [ 287,   17]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.8190713629429305                                                                    \n",
      "model:                                                                                \n",
      "randomforest_entropy_sqrt_148.csv                                                     \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_148.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.16338028169014085, 'accuracy': 0.8369923161361141, 'auroc': 0.8190713629429305, 'kappa': 0.12125325997642089, 'matthews_cc': 0.18286789970506295, 'confusion_matrix': array([[[  29,  275],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 275,   29]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.7113530181679496                                                                    \n",
      "model:                                                                                \n",
      "SVC_100_0.01_rbf.csv                                                                  \n",
      "{'predictioncsv': 'SVC_100_0.01_rbf.csv', 'model_name': 'SVC', 'y_pred': array([0., 0., 1., ..., 0., 1., 0.]), 'f1': 0.34848484848484845, 'accuracy': 0.8111964873765093, 'auroc': 0.7113530181679496, 'kappa': 0.24103925291587547, 'matthews_cc': 0.24488388288914942, 'confusion_matrix': array([[[  92,  212],\n",
      "        [ 132, 1386]],\n",
      "\n",
      "       [[1386,  132],\n",
      "        [ 212,   92]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.755785833159975                                                                     \n",
      "model:                                                                                \n",
      "naive_bayes.csv                                                                       \n",
      "{'predictioncsv': 'naive_bayes.csv', 'model_name': 'naive_bayes', 'y_pred': array([1., 0., 1., ..., 1., 1., 0.]), 'f1': 0.4318181818181818, 'accuracy': 0.6432491767288694, 'auroc': 0.755785833159975, 'kappa': 0.24741746565941036, 'matthews_cc': 0.31552944095924307, 'confusion_matrix': array([[[247,  57],\n",
      "        [593, 925]],\n",
      "\n",
      "       [[925, 593],\n",
      "        [ 57, 247]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.8145022883295194                                                                    \n",
      "model:                                                                                \n",
      "randomforest_gini_sqrt_132.csv                                                        \n",
      "{'predictioncsv': 'randomforest_gini_sqrt_132.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17415730337078653, 'accuracy': 0.8386388583973655, 'auroc': 0.8145022883295194, 'kappa': 0.13184098953673817, 'matthews_cc': 0.1973585300019816, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  21, 1497]],\n",
      "\n",
      "       [[1497,   21],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.7417221413216837                                                                    \n",
      "model:                                                                                \n",
      "AdaBoost_SAMME.R_0.001_74.csv                                                         \n",
      "{'predictioncsv': 'AdaBoost_SAMME.R_0.001_74.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.7417221413216837, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.6862897423895707                                                                    \n",
      "model:                                                                                \n",
      "LinSVC_2.1135396728599365.csv                                                         \n",
      "{'predictioncsv': 'LinSVC_2.1135396728599365.csv', 'model_name': 'LinSVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.35153583617747447, 'accuracy': 0.7914379802414928, 'auroc': 0.6862897423895707, 'kappa': 0.22748026189530435, 'matthews_cc': 0.22770811932933263, 'confusion_matrix': array([[[ 103,  201],\n",
      "        [ 179, 1339]],\n",
      "\n",
      "       [[1339,  179],\n",
      "        [ 201,  103]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.803747572983843                                                                     \n",
      "model:                                                                                \n",
      "randomforest_entropy_sqrt_36.csv                                                      \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_36.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.20163487738419617, 'accuracy': 0.8391877058177827, 'auroc': 0.803747572983843, 'kappa': 0.1531227691673146, 'matthews_cc': 0.21341721255169302, 'confusion_matrix': array([[[  37,  267],\n",
      "        [  26, 1492]],\n",
      "\n",
      "       [[1492,   26],\n",
      "        [ 267,   37]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.8117155537064005                                                                    \n",
      "model:                                                                                \n",
      "randomforest_entropy_None_116.csv                                                     \n",
      "{'predictioncsv': 'randomforest_entropy_None_116.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.23896103896103896, 'accuracy': 0.8391877058177827, 'auroc': 0.8117155537064005, 'kappa': 0.18149648432588916, 'matthews_cc': 0.23201661829975417, 'confusion_matrix': array([[[  46,  258],\n",
      "        [  35, 1483]],\n",
      "\n",
      "       [[1483,   35],\n",
      "        [ 258,   46]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.49405597739407814                                                                   \n",
      "model:                                                                                \n",
      "decision_tree_gini_log2_best.csv                                                      \n",
      "{'predictioncsv': 'decision_tree_gini_log2_best.csv', 'model_name': 'decision_tree', 'y_pred': array([1., 0., 0., ..., 0., 0., 0.]), 'f1': 0.2728785357737105, 'accuracy': 0.7601536772777168, 'auroc': 0.49405597739407814, 'kappa': 0.129293583218692, 'matthews_cc': 0.12930616050765115, 'confusion_matrix': array([[[  82,  222],\n",
      "        [ 215, 1303]],\n",
      "\n",
      "       [[1303,  215],\n",
      "        [ 222,   82]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.8196293599611677                                                                    \n",
      "model:                                                                                \n",
      "randomforest_entropy_sqrt_164.csv                                                     \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.80406828583316                                                                      \n",
      "model:                                                                                \n",
      "knn_131.csv                                                                           \n",
      "{'predictioncsv': 'knn_131.csv', 'model_name': 'knn', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.013029315960912053, 'accuracy': 0.8336992316136114, 'auroc': 0.80406828583316, 'kappa': 0.009800369486843707, 'matthews_cc': 0.05444162008313548, 'confusion_matrix': array([[[   2,  302],\n",
      "        [   1, 1517]],\n",
      "\n",
      "       [[1517,    1],\n",
      "        [ 302,    2]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.7493748266417031                                                                    \n",
      "model:                                                                                \n",
      "logistic_regression_none_lbfgs.csv                                                    \n",
      "{'predictioncsv': 'logistic_regression_none_lbfgs.csv', 'model_name': 'logistic_regression', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.372093023255814, 'accuracy': 0.7925356750823271, 'auroc': 0.7493748266417031, 'kappa': 0.24784745429526245, 'matthews_cc': 0.24786512002809344, 'confusion_matrix': array([[[ 112,  192],\n",
      "        [ 186, 1332]],\n",
      "\n",
      "       [[1332,  186],\n",
      "        [ 192,  112]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.8177462554607864                                                                    \n",
      "model:                                                                                \n",
      "randomforest_entropy_sqrt_100.csv                                                     \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_100.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.1787709497206704, 'accuracy': 0.8386388583973655, 'auroc': 0.8177462554607864, 'kappa': 0.13524386385209952, 'matthews_cc': 0.199562500529825, 'confusion_matrix': array([[[  32,  272],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 272,   32]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.7351995353997643                                                                    \n",
      "model:                                                                                \n",
      "SVC_0.1_0.0001_rbf.csv                                                                \n",
      "{'predictioncsv': 'SVC_0.1_0.0001_rbf.csv', 'model_name': 'SVC', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.0, 'accuracy': 0.8331503841931943, 'auroc': 0.7351995353997643, 'kappa': 0.0, 'matthews_cc': 0.0, 'confusion_matrix': array([[[   0,  304],\n",
      "        [   0, 1518]],\n",
      "\n",
      "       [[1518,    0],\n",
      "        [ 304,    0]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.755785833159975                                                                     \n",
      "model:                                                                                \n",
      "naive_bayes.csv                                                                       \n",
      "{'predictioncsv': 'naive_bayes.csv', 'model_name': 'naive_bayes', 'y_pred': array([1., 0., 1., ..., 1., 1., 0.]), 'f1': 0.4318181818181818, 'accuracy': 0.6432491767288694, 'auroc': 0.755785833159975, 'kappa': 0.24741746565941036, 'matthews_cc': 0.31552944095924307, 'confusion_matrix': array([[[247,  57],\n",
      "        [593, 925]],\n",
      "\n",
      "       [[925, 593],\n",
      "        [ 57, 247]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.7387696328271272                                                                    \n",
      "model:                                                                                \n",
      "AdaBoost_SAMME.R_1.0_52.csv                                                           \n",
      "{'predictioncsv': 'AdaBoost_SAMME.R_1.0_52.csv', 'model_name': 'AdaBoost', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.37847866419294995, 'accuracy': 0.8161361141602634, 'auroc': 0.7387696328271272, 'kappa': 0.2726572908250693, 'matthews_cc': 0.27576944000792, 'confusion_matrix': array([[[ 102,  202],\n",
      "        [ 133, 1385]],\n",
      "\n",
      "       [[1385,  133],\n",
      "        [ 202,  102]]], dtype=int64)}\n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "(1822,)                                                                               \n",
      "0.8196293599611677                                                                    \n",
      "model:                                                                                \n",
      "randomforest_entropy_sqrt_164.csv                                                     \n",
      "{'predictioncsv': 'randomforest_entropy_sqrt_164.csv', 'model_name': 'randomforest', 'y_pred': array([0., 0., 0., ..., 0., 0., 0.]), 'f1': 0.17366946778711484, 'accuracy': 0.8380900109769485, 'auroc': 0.8196293599611677, 'kappa': 0.13059864451741254, 'matthews_cc': 0.19408153597393274, 'confusion_matrix': array([[[  31,  273],\n",
      "        [  22, 1496]],\n",
      "\n",
      "       [[1496,   22],\n",
      "        [ 273,   31]]], dtype=int64)}\n",
      "100%|| 200/200 [1:10:01<00:00, 21.01s/trial, best loss: -0.8196293599611677]\n",
      "best:\n",
      "{'classifier_type': 6, 'criterion': 1, 'max_features': 1, 'n_estimators': 9}\n",
      "{'criterion': 'entropy', 'max_features': 'sqrt', 'n_estimators': 164, 'type': 'randomforest'}\n"
     ]
    }
   ],
   "source": [
    "best = fmin(\n",
    "            f, \n",
    "            space, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals= 50,)\n",
    "print ('best:' )\n",
    "print(best)\n",
    "print(space_eval(space, best))\n",
    "df = pd.DataFrame.from_dict(results)\n",
    "df = df.sort_values(by=guide_metric_name, ascending=False)\n",
    "df.to_csv(os.path.join(modelcsv, output_name) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
